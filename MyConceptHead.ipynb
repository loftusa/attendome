{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7044c575-94de-4b0c-94c7-417b1afa60e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zy2559/.conda/envs/attendome/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os \n",
    "import argparse \n",
    "import torch \n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "from collections import defaultdict\n",
    "\n",
    "from nnsight import LanguageModel\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05a817a6-d204-4fde-9564-aee223d4dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pile_chunk(random_len, pile, tok, shuf_pile=True):\n",
    "    sample = []\n",
    "    while len(sample) < random_len:\n",
    "        doc = pile.shuffle()[0]['text'] # sample from huggingface\n",
    "        sample = tok(doc, bos=False)[: random_len]\n",
    "        if shuf_pile:\n",
    "            random.shuffle(sample)\n",
    "    return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8015868d-a376-418b-84c3-ab8b27c796ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2_attn_weights(model, tokenized, layer, value_weighting):\n",
    "    n_heads = model.config.num_attention_heads \n",
    "    head_dim = model.config.hidden_size // n_heads\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with model.trace(tokenized):\n",
    "            # positional_embeddings (cos, sin) each shape [bsz, seq_len, head_dim]\n",
    "            position = model.model.layers[layer].self_attn.inputs[1]['position_embeddings']\n",
    "            attention_mask = model.model.layers[layer].self_attn.inputs[1]['attention_mask']\n",
    "\n",
    "            # [bsz, seq_len, model_size]\n",
    "            query_states = model.model.layers[layer].self_attn.q_proj.output\n",
    "            key_states = model.model.layers[layer].self_attn.k_proj.output \n",
    "\n",
    "            bsz = query_states.shape[0]; seq_len = query_states.shape[1] \n",
    "            if value_weighting:\n",
    "                # [bsz, seq_len, model_size] -> [bsz, seq_len, n_heads, head_dim]\n",
    "                value_states = model.model.layers[layer].self_attn.v_proj.output\n",
    "                value_states = value_states.view(bsz, seq_len, n_heads, head_dim).save()\n",
    "\n",
    "            # from modeling_llama, convert to [bsz, n_heads, seq_len, head_dim] and rotate \n",
    "            query_states = query_states.view(bsz, seq_len, -1, head_dim).transpose(1, 2)\n",
    "            key_states = key_states.view(bsz, seq_len, -1, head_dim).transpose(1, 2)\n",
    "            query_states, key_states = apply_rotary_pos_emb(query_states, key_states, position[0], position[1])\n",
    "\n",
    "            # not needed because num_key_value_heads == num_attention_heads \n",
    "            # key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
    "            attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
    "            \n",
    "            # has to be eager implementation \n",
    "            causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]\n",
    "            attn_weights = attn_weights + causal_mask\n",
    "            attn_weights = attn_weights.save()\n",
    "    \n",
    "    if not value_weighting:\n",
    "        return attn_weights.softmax(dim=-1).detach().cpu()\n",
    "    else: \n",
    "        # get l2 norm of each head value vector [bsz, seq_len, n_heads] -> [bsz, n_heads, seq_len]\n",
    "        value_norms = torch.linalg.vector_norm(value_states, dim=-1).detach().cpu().transpose(1, 2)\n",
    "\n",
    "        # attn_weights [bsz, n_heads, seq_len, seq_len]\n",
    "        attn_weights = attn_weights.softmax(dim=-1).detach().cpu()\n",
    "\n",
    "        # then multiply by softmax values and normalize \n",
    "        effective = attn_weights * value_norms.unsqueeze(2).expand(attn_weights.shape)\n",
    "        effective /= torch.sum(effective, dim=-1, keepdim=True)\n",
    "        return effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1063e0b-1710-4f23-80ff-e0d2b568e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l3_attn_weights(model, tokenized, layer, value_weighting):\n",
    "    n_heads = model.config.num_attention_heads \n",
    "    head_dim = model.config.hidden_size // n_heads\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with model.trace(tokenized):\n",
    "            # self.num_key_value_groups = config.num_attention_heads // config.num_key_value_heads\n",
    "            n_kv_groups = model.model.layers[layer].self_attn.num_key_value_groups\n",
    "\n",
    "            # positional_embeddings (cos, sin) each shape [bsz, seq_len, head_dim]\n",
    "            position = model.model.layers[layer].self_attn.inputs[1]['position_embeddings']\n",
    "            attention_mask = model.model.layers[layer].self_attn.inputs[1]['attention_mask']\n",
    "\n",
    "            # grouped query means that we have more queries than we do keys/values\n",
    "            query_states = model.model.layers[layer].self_attn.q_proj.output # [bsz, seq_len, model_size=4096]\n",
    "            key_states = model.model.layers[layer].self_attn.k_proj.output  # [bsz, seq_len, 1024]\n",
    "            bsz = query_states.shape[0]; seq_len = query_states.shape[1] \n",
    "\n",
    "            if value_weighting:\n",
    "                value_states = model.model.layers[layer].self_attn.v_proj.output # [bsz, seq_len, 1024]\n",
    "                value_states = value_states.view(bsz, seq_len, -1, head_dim).transpose(1, 2) # [bsz, seq_len, 8, head_dim] -> [bsz, 8, seq_len, head_dim]\n",
    "                value_states = repeat_kv(value_states, n_kv_groups).save()\n",
    "\n",
    "            # from modeling_llama, convert to [bsz, n_heads, seq_len, head_dim] and rotate \n",
    "            query_states = query_states.view(bsz, seq_len, -1, head_dim).transpose(1, 2)\n",
    "            key_states = key_states.view(bsz, seq_len, -1, head_dim).transpose(1, 2)\n",
    "            query_states, key_states = apply_rotary_pos_emb(query_states, key_states, position[0], position[1])\n",
    "\n",
    "            # not needed because num_key_value_heads == num_attention_heads \n",
    "            key_states = repeat_kv(key_states, n_kv_groups)\n",
    "            attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
    "            \n",
    "            # has to be eager implementation \n",
    "            causal_mask = attention_mask[:, :, :, : key_states.shape[-2]]\n",
    "            attn_weights = attn_weights + causal_mask\n",
    "            attn_weights = attn_weights.save()\n",
    "    \n",
    "    if not value_weighting:\n",
    "        return attn_weights.softmax(dim=-1).detach().cpu()\n",
    "    else: \n",
    "        # get l2 norm of each head value vector [bsz, n_heads, seq_len]\n",
    "        value_norms = torch.linalg.vector_norm(value_states, dim=-1).detach().cpu()\n",
    "\n",
    "        # attn_weights [bsz, n_heads, seq_len, seq_len]\n",
    "        attn_weights = attn_weights.softmax(dim=-1).detach().cpu()\n",
    "\n",
    "        # then multiply by softmax values and normalize \n",
    "        effective = attn_weights * value_norms.unsqueeze(2).expand(attn_weights.shape)\n",
    "        effective /= torch.sum(effective, dim=-1, keepdim=True)\n",
    "        return effective\n",
    "\n",
    "import torch \n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py#L178\n",
    "def rotate_half(x):\n",
    "    \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "# can use for llama2, llama3, and olmo2 \n",
    "def apply_rotary_pos_emb(q, k, cos, sin, position_ids=None, unsqueeze_dim=1):\n",
    "    \"\"\"Applies Rotary Position Embedding to the query and key tensors.\n",
    "\n",
    "    Args:\n",
    "        q (`torch.Tensor`): The query tensor.\n",
    "        k (`torch.Tensor`): The key tensor.\n",
    "        cos (`torch.Tensor`): The cosine part of the rotary embedding.\n",
    "        sin (`torch.Tensor`): The sine part of the rotary embedding.\n",
    "        position_ids (`torch.Tensor`, *optional*):\n",
    "            Deprecated and unused.\n",
    "        unsqueeze_dim (`int`, *optional*, defaults to 1):\n",
    "            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and\n",
    "            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note\n",
    "            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and\n",
    "            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes\n",
    "            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have\n",
    "            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.\n",
    "    Returns:\n",
    "        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.\n",
    "    \"\"\"\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    return q_embed, k_embed\n",
    "\n",
    "\n",
    "def repeat_kv(hidden_states: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\n",
    "    num_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)\n",
    "    \"\"\"\n",
    "    # print(hidden_states)\n",
    "    # batch, num_key_value_heads, slen, head_dim = hidden_states.shape\n",
    "    batch = hidden_states.shape[0]\n",
    "    num_key_value_heads = hidden_states.shape[1] \n",
    "    slen = hidden_states.shape[2]\n",
    "    head_dim = hidden_states.shape[3]\n",
    "    \n",
    "    if n_rep == 1:\n",
    "        return hidden_states\n",
    "    hidden_states = hidden_states[:, :, None, :, :].expand(batch, num_key_value_heads, n_rep, slen, head_dim)\n",
    "    return hidden_states.reshape(batch, num_key_value_heads * n_rep, slen, head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91081baf-d75a-4df4-894b-b45c3c018ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def get_qwen3_attn_weights(model, tokenized, layer, value_weighting=False):\n",
    "    \"\"\"\n",
    "    Extract attention weights from a specific layer of a Qwen3 model.\n",
    "    \n",
    "    Args:\n",
    "        model: Qwen3 model with tracing capability\n",
    "        tokenized: Tokenized input\n",
    "        layer: Layer index to extract attention from\n",
    "        value_weighting: If True, weight attention by value vector magnitudes\n",
    "    \n",
    "    Returns:\n",
    "        Attention weights tensor of shape [bsz, n_heads, seq_len, seq_len]\n",
    "    \"\"\"\n",
    "    # Get model configuration\n",
    "    config = model.config\n",
    "    n_heads = config.num_attention_heads\n",
    "    head_dim = config.hidden_size // n_heads\n",
    "    \n",
    "    # Qwen3 might use different config names, adjust as needed\n",
    "    n_kv_heads = getattr(config, 'num_key_value_heads', n_heads)\n",
    "    n_kv_groups = n_heads // n_kv_heads\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with model.trace(tokenized):\n",
    "            # Access the transformer layer - Qwen3 typically uses 'model.layers'\n",
    "            layer_module = model.model.layers[layer]\n",
    "            \n",
    "            # Access self-attention module\n",
    "            attn_module = layer_module.self_attn\n",
    "            \n",
    "            # Get query, key, value projections\n",
    "            # Qwen3 typically uses q_proj, k_proj, v_proj naming\n",
    "            query_states = attn_module.q_proj.output\n",
    "            key_states = attn_module.k_proj.output\n",
    "            \n",
    "            if value_weighting:\n",
    "                value_states = attn_module.v_proj.output\n",
    "            \n",
    "            # Get batch size and sequence length\n",
    "            bsz, seq_len = query_states.shape[:2]\n",
    "            \n",
    "            # Reshape for multi-head attention\n",
    "            # [bsz, seq_len, hidden_size] -> [bsz, seq_len, n_heads, head_dim] -> [bsz, n_heads, seq_len, head_dim]\n",
    "            query_states = query_states.view(bsz, seq_len, n_heads, head_dim).transpose(1, 2)\n",
    "            key_states = key_states.view(bsz, seq_len, n_kv_heads, head_dim).transpose(1, 2)\n",
    "            \n",
    "            if value_weighting:\n",
    "                value_states = value_states.view(bsz, seq_len, n_kv_heads, head_dim).transpose(1, 2)\n",
    "            \n",
    "            # Apply rotary positional embeddings if used\n",
    "            # Qwen3 typically uses RoPE, but the implementation might vary\n",
    "            try:\n",
    "                # Try to get position embeddings - this might need adjustment based on Qwen3's implementation\n",
    "                if hasattr(attn_module, 'rotary_emb'):\n",
    "                    cos, sin = attn_module.rotary_emb(value_states, seq_len=seq_len)\n",
    "                    query_states, key_states = apply_qwen3_rotary_pos_emb(query_states, key_states, cos, sin)\n",
    "                elif hasattr(layer_module, 'rotary_emb'):\n",
    "                    cos, sin = layer_module.rotary_emb(value_states, seq_len=seq_len)\n",
    "                    query_states, key_states = apply_qwen3_rotary_pos_emb(query_states, key_states, cos, sin)\n",
    "            except:\n",
    "                # If rotary embeddings fail, continue without them\n",
    "                # This might happen if the model structure is different\n",
    "                pass\n",
    "            \n",
    "            # Handle grouped query attention - repeat key/value states if needed\n",
    "            if n_kv_groups > 1:\n",
    "                key_states = repeat_kv(key_states, n_kv_groups)\n",
    "                if value_weighting:\n",
    "                    value_states = repeat_kv(value_states, n_kv_groups)\n",
    "            \n",
    "            # Compute attention scores\n",
    "            attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) / math.sqrt(head_dim)\n",
    "            \n",
    "            # Apply causal mask\n",
    "            # Create causal mask for autoregressive attention\n",
    "            causal_mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool), diagonal=1)\n",
    "            causal_mask = causal_mask.to(attn_weights.device)\n",
    "            attn_weights = attn_weights.masked_fill(causal_mask, float('-inf'))\n",
    "            \n",
    "            # Save attention weights for extraction\n",
    "            attn_weights = attn_weights.save()\n",
    "            \n",
    "            if value_weighting:\n",
    "                value_states = value_states.save()\n",
    "    \n",
    "    # Apply softmax to get attention probabilities\n",
    "    attn_probs = attn_weights.softmax(dim=-1).detach().cpu()\n",
    "    \n",
    "    if not value_weighting:\n",
    "        return attn_probs\n",
    "    else:\n",
    "        # Compute value weighting\n",
    "        value_states_cpu = value_states.detach().cpu()\n",
    "        \n",
    "        # Get L2 norm of each head value vector [bsz, n_heads, seq_len]\n",
    "        value_norms = torch.linalg.vector_norm(value_states_cpu, dim=-1)\n",
    "        \n",
    "        # Weight attention by value magnitudes\n",
    "        # attn_probs: [bsz, n_heads, seq_len, seq_len]\n",
    "        # value_norms: [bsz, n_heads, seq_len]\n",
    "        effective = attn_probs * value_norms.unsqueeze(2).expand(attn_probs.shape)\n",
    "        \n",
    "        # Renormalize\n",
    "        effective = effective / (torch.sum(effective, dim=-1, keepdim=True) + 1e-8)\n",
    "        \n",
    "        return effective\n",
    "\n",
    "\n",
    "def apply_qwen3_rotary_pos_emb(q, k, cos, sin, position_ids=None):\n",
    "    \"\"\"\n",
    "    Apply rotary positional embeddings to query and key tensors.\n",
    "    This is a simplified version - you might need to adjust based on Qwen3's exact implementation.\n",
    "    \n",
    "    Args:\n",
    "        q: Query tensor [batch, n_heads, seq_len, head_dim]\n",
    "        k: Key tensor [batch, n_heads, seq_len, head_dim]\n",
    "        cos: Cosine values for rotary embedding\n",
    "        sin: Sine values for rotary embedding\n",
    "        position_ids: Position indices (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Rotated query and key tensors\n",
    "    \"\"\"\n",
    "    # This is a simplified implementation\n",
    "    # The actual Qwen3 implementation might be more complex\n",
    "    \n",
    "    def rotate_half(x):\n",
    "        \"\"\"Rotates half the hidden dims of the input.\"\"\"\n",
    "        x1 = x[..., : x.shape[-1] // 2]\n",
    "        x2 = x[..., x.shape[-1] // 2 :]\n",
    "        return torch.cat((-x2, x1), dim=-1)\n",
    "    \n",
    "    # Apply rotation\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "    \n",
    "    return q_embed, k_embed\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# attn_weights = get_qwen3_attn_weights(model, tokenized_input, layer=12, value_weighting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea10d43-1251-4391-80f7-61c2fd02981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def generate_ragged_batch(batch_ents, pile, tok, seq_len):\n",
    "    assert len({len(e) for e in batch_ents}) == 1\n",
    "\n",
    "    newline = tok('\\n', bos=False)[-1]\n",
    "    bos = tok('', bos=True)[0]\n",
    "\n",
    "    sequences = []\n",
    "    start_idxs, end_idxs = [], []\n",
    "    for ent in batch_ents:\n",
    "        position = random.choice(range(seq_len // 2, seq_len - len(ent) + 1))\n",
    "        rand1 = pile_chunk(position, pile, tok)\n",
    "        rand2 = pile_chunk(seq_len - position - len(ent), pile, tok)\n",
    "\n",
    "        start_idxs.append(position + 1)\n",
    "        end_idxs.append(position + len(ent))\n",
    "        sequences.append(\n",
    "            [bos] + rand1 + ent + rand2 + [newline] + rand1 \n",
    "        )\n",
    "\n",
    "    # since batches have ragged ends by design, save padding offsets \n",
    "    flipped_masks = [m - 1 for m in tok(sequences, pad_mask=True)]\n",
    "    pad_offsets = [-sum(f).item() for f in flipped_masks]\n",
    "\n",
    "    return sequences, torch.tensor(start_idxs), torch.tensor(end_idxs), torch.tensor(pad_offsets)\n",
    "\n",
    "def retrieve_attention(model, tokenized, layer, value_weighting=True):\n",
    "    func = {\n",
    "        'Qwen/Qwen3-4B' : get_qwen3_attn_weights,\n",
    "        'meta-llama/Llama-3.2-3B-Instruct' : get_l3_attn_weights,\n",
    "        'meta-llama/Llama-3.1-8B-Instruct' : get_l3_attn_weights,\n",
    "        'meta-llama/Meta-Llama-3-8B' : get_l3_attn_weights,\n",
    "        'meta-llama/Llama-2-7b-hf': get_l2_attn_weights\n",
    "    }[model.config._name_or_path]\n",
    "\n",
    "    return func(model, tokenized, layer, value_weighting)\n",
    "\n",
    "def normalize(d, total):\n",
    "    for k in d.keys():\n",
    "        d[k] /= total \n",
    "    return d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5f98df-d730-45f6-be93-51ef43215f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', default='meta-llama/Llama-2-7b-hf')\n",
    "parser.add_argument('--ckpt', default=None, type=str)\n",
    "parser.add_argument('--n', default=2048, type=int)\n",
    "parser.add_argument('--bsz', default=128, type=int, help='may have bugs with bsz=1.')\n",
    "parser.add_argument('--sequence_len', default=30)\n",
    "parser.add_argument('--random_tok_entities', action='store_true')\n",
    "parser.set_defaults(random_tok_entities=False)\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a478d668-346e-4233-a06b-5ea50265b028",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(8)\n",
    "torch.manual_seed(8)\n",
    "np.random.seed(8)\n",
    "\n",
    "# args.model = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "# args.model = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# args.model = 'meta-llama/Llama-2-7b-hf'\n",
    "args.model = 'Qwen/Qwen3-4B'\n",
    "model = LanguageModel(args.model, device_map='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15eec4c7-e9d9-4c8a-994b-380241461e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = args.model.split('/')[-1]\n",
    "d = model.tokenizer.decode\n",
    "\n",
    "assert args.bsz <= args.n // 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed1398b-5c17-4c8f-af59-7003c6b73744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok(s, bos=False, model=model, pad_mask=False):\n",
    "    if pad_mask:\n",
    "        assert type(s) == list and type(s[0]) == list and type(s[0][0]) == int\n",
    "        return model.tokenizer.pad({'input_ids' : s}, return_tensors='pt')['attention_mask']\n",
    "\n",
    "    # otherwise get actual tokens \n",
    "    if 'llama' in model.config._name_or_path:\n",
    "        if not bos: \n",
    "            return model.tokenizer(s)['input_ids'][1:]\n",
    "        else:\n",
    "            return model.tokenizer(s)['input_ids']\n",
    "    elif 'qwen' in model.config._name_or_path.lower():\n",
    "        # qwen models don't have a BOS token, so just return the tokens as-is\n",
    "        return model.tokenizer(s)['input_ids']\n",
    "    elif model.config._name_or_path in ['allenai/OLMo-2-1124-7B', 'EleutherAI/pythia-6.9b']:\n",
    "        if not bos:\n",
    "            return model.tokenizer(s)['input_ids']\n",
    "        else:\n",
    "            return [model.tokenizer.bos_token_id] + model.tokenizer(s)['input_ids']\n",
    "\n",
    "# load in pile sample to use as basic material that we shuffle around \n",
    "# pile = load_dataset('NeelNanda/pile-10k')['train']\n",
    "pile = load_dataset('JeanKaddour/minipile')['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3cf364-d37d-4c00-aa05-d09d1d0f06a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([14990, 0, 1128, 594, 705, 30], [574, 374, 14264])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer(\"hello! what's up?\")['input_ids'], model.tokenizer(\"this is crazy\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f9629e-360d-4042-8dd8-ae6d70469b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e625236a-56f2-431e-b7a1-2dc325855b9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m str_entities:\n\u001b[32m     23\u001b[39m     toks = tok(ent)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(toks) == \u001b[32m2\u001b[39m:\n\u001b[32m     25\u001b[39m         sorted_entities[\u001b[33m'\u001b[39m\u001b[33mbigram\u001b[39m\u001b[33m'\u001b[39m].append(toks)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(toks) == \u001b[32m3\u001b[39m: \n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# dummy entities for comparison \n",
    "sorted_entities = defaultdict(list)\n",
    "if args.random_tok_entities:\n",
    "    for i in range(args.n):\n",
    "        doc_toks = []\n",
    "        while len(doc_toks) < 5:\n",
    "            doc = pile.shuffle()[0]['text']\n",
    "            doc_toks = tok(doc)\n",
    "\n",
    "        random.shuffle(doc_toks)\n",
    "        if i % 4 == 0: \n",
    "            sorted_entities['bigram'].append(doc_toks[:2])\n",
    "        elif i % 4 == 1: \n",
    "            sorted_entities['trigram'].append(doc_toks[:3])\n",
    "        elif i % 4 == 2:\n",
    "            sorted_entities['fourgram'].append(doc_toks[:4])\n",
    "        elif i % 4 == 3: \n",
    "            sorted_entities['fivegram'].append(doc_toks[:5])\n",
    "# load and sort entities of different token lengths\n",
    "else:\n",
    "    str_entities = list(pd.read_csv('./dataset_files/counterfact_expanded.csv')['subject'])\n",
    "    for ent in str_entities:\n",
    "        toks = tok(ent)\n",
    "        if len(toks) == 2:\n",
    "            sorted_entities['bigram'].append(toks)\n",
    "        elif len(toks) == 3: \n",
    "            sorted_entities['trigram'].append(toks)\n",
    "        elif len(toks) == 4: \n",
    "            sorted_entities['fourgram'].append(toks)\n",
    "        elif len(toks) == 5: \n",
    "            sorted_entities['fivegram'].append(toks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "885e0cbb-3b51-470a-a989-635b36bda27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention for fivegram Danielle Darrieux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> anim save\\n the = Create animation and objectvar  Step // Win1: result the Danielle Darrieux Change Ven’ue NASAs For\\n anim save\\n the = Create animation and objectvar  Step // Win1: result the'\n",
      "19 23 Daniel ux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[Aching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Fetching 2 files: 100%|██████████| 2/2 [08:38<00:00, 259.02s/it]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "\u001b[Ading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[Ading checkpoint shards:  50%|█████     | 1/2 [01:41<01:41, 101.93s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:29<00:00, 74.90s/it] \n",
      " 25%|██▌       | 1/4 [13:39<40:57, 819.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>31 Minn25.119  \\n6 (63 Germaine Greer FrameFrameurk XhardLB\\n\\n\\n31 Minn25.119  \\n6 (63'\n",
      "17 21 Ger er\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [16:16<14:19, 429.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> to below for on find the details a to project the go you looking picture easy make click To pattern to are it Long-Term Capital Management interactions Exchange\\n to below for on find the details a to project the go you looking picture easy make click To pattern to are it'\n",
      "24 28 Long Management\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [18:54<05:05, 305.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> use\\n Town project is Center Centeron MM\\nequ aonequ Town lux mixed featuring Isabelle AutissierAccess Q\\n:\\n to\\n use\\n Town project is Center Centeron MM\\nequ aonequ Town lux mixed featuring'\n",
      "20 24 Isabel ier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [21:33<00:00, 323.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention for trigram Apple A5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0. \\xa0\\xa0\\xa0\\xa0\\nNO\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 Apple A5 Video\\n\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0. \\xa0\\xa0\\xa0\\xa0\\nNO\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0'\n",
      "27 29 Apple 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [02:49<08:28, 169.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> The\\n K\\nCharium\\nie Spring Gpes -icken love ReI Jams\\n Rollciates byitchen Sarah Waters\\n: Q\\n The\\n K\\nCharium\\nie Spring Gpes -icken love ReI Jams\\n Rollciates byitchen'\n",
      "25 27 Sarah aters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [05:38<05:38, 169.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> acrossined Canada researchers conference who of This assign together will haveday thousands bring- writing one exam from Sky Sports News the of ) Field1\\n acrossined Canada researchers conference who of This assign together will haveday thousands bring- writing one exam from'\n",
      "22 24 Sky News\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [08:27<02:49, 169.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>\\nber if\\n feet shook I off thoughtwithout you he stven less is the dust...raw no yourEries. Mount Fosterif N\\n\\nber if\\n feet shook I off thoughtwithout you he stven less is the dust...raw no yourEries.'\n",
      "26 28 Mount oster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [11:18<00:00, 169.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention for bigram Wellington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>ple topo help element matchet:books\\n fatal error\\n\\n Q:\\n throw NSArrayase failed. Wellingtonaking withLT B ME\\nple topo help element matchet:books\\n fatal error\\n\\n Q:\\n throw NSArrayase failed.'\n",
      "24 25 Well ington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [02:52<08:36, 172.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>leman Murwin’ Gentnings and Musical, Theder A Guide Best to- Love Award Tony, Areva\\n options:\\nBuild Q\\nleman Murwin’ Gentnings and Musical, Theder A Guide Best to- Love Award Tony,'\n",
      "23 24 Are va\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [05:44<05:44, 172.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>\\npressed wasHow com an I NSString decom thatlib\\nI with Q\\n: NSString have z do ( an have\\n Ipress table tennis Q\\n\\npressed wasHow com an I NSString decom thatlib\\nI with Q\\n: NSString have z do ( an have\\n Ipress'\n",
      "28 29 table tennis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [08:38<02:52, 172.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>] Sub, X subject ImagedcMPMP- [jectX, - George Duke55-51\\n1-0A0\\n J\\n] Sub, X subject ImagedcMPMP- [jectX, -'\n",
      "16 17 George Duke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [11:31<00:00, 172.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention for fourgram Michel Denisot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>vDmanmanitiliashz (\\n Dav ()\\nashitavviliborn Modz Mod  Michel Denisot Fire badly dam\\nvDmanmanitiliashz (\\n Dav ()\\nashitavviliborn Modz Mod '\n",
      "24 27 Michel ot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [02:47<08:22, 167.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s>{3\\n\\n Eation Reuclidean Ouriter Appro Ofvest Qment Inach Margit Sandemo:S QLT to\\n\\n flatX\\n{3\\n\\n Eation Reuclidean Ouriter Appro Ofvest Qment Inach'\n",
      "18 21 Mar demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [05:34<05:34, 167.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> caused Se and inous diseaselisvere central nerv by humans system Bay fatal HMAS Sydney, proved Carer herrie Through Fish lifeout time\\n caused Se and inous diseaselisvere central nerv by humans system Bay fatal'\n",
      "16 19 H Sydney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [08:20<02:46, 166.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<s> India of to02 water,8 Uputed to poll 5 a surface1 is according’ %s0 Nam June Paik Rap Wisconsin\\n India of to02 water,8 Uputed to poll 5 a surface1 is according’ %s0'\n",
      "25 28 Nam ik\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [11:09<00:00, 167.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# For each head, save the stuff \n",
    "total_examples = 0 \n",
    "next_tok_attn = defaultdict(int)\n",
    "end_tok_attn = defaultdict(int)\n",
    "\n",
    "# I guess we're doing each batch is the same length entity \n",
    "for l, ents in sorted_entities.items():\n",
    "    selected_ents = ents[ : args.n // 4]\n",
    "    n_batches = len(selected_ents) // args.bsz\n",
    "    print('attention for', l, model.tokenizer.decode(selected_ents[0]))\n",
    "\n",
    "    for batch_idx in tqdm(range(n_batches)):\n",
    "        batch_ents = selected_ents[batch_idx * args.bsz : (batch_idx + 1) * args.bsz]\n",
    "        batch_seqs, start_idxs, end_idxs, pad_offsets = generate_ragged_batch(batch_ents, pile, tok, args.sequence_len)\n",
    "\n",
    "        print(repr(model.tokenizer.decode(batch_seqs[0])))\n",
    "        print(start_idxs[0].item(), end_idxs[0].item(), model.tokenizer.decode(batch_seqs[0][start_idxs[0]]), model.tokenizer.decode(batch_seqs[0][end_idxs[0]]))\n",
    "\n",
    "        # get attention patterns for each head and example \n",
    "        for layer in range(model.config.num_hidden_layers):\n",
    "            # [bsz, n_heads, seq_from, seq_to]\n",
    "            attns = retrieve_attention(model, batch_seqs, layer)\n",
    "\n",
    "            # index in and save beginnings, ends \n",
    "            for head in range(model.config.num_attention_heads):\n",
    "                next_tok_attn[(layer, head)] += attns[torch.arange(len(attns)), head, -1, start_idxs + pad_offsets].sum().item()\n",
    "                end_tok_attn[(layer, head)] += attns[torch.arange(len(attns)), head, -1, end_idxs + pad_offsets].sum().item()\n",
    "        \n",
    "        total_examples += len(batch_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04405458-d235-4410-a6f1-90c76eef2ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama-2-7b-hf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57194e1c-2f0e-4e45-9309-0b453e9cb8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.random_tok_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c03a9e2-e15c-46e4-bfc7-852c50774b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/attention_scores/Llama-2-7b-hf/n2048_seqlen30.json\n"
     ]
    }
   ],
   "source": [
    "def json_tuple_keys(mapping):\n",
    "    return [{'layer':k[0], 'head_idx': k[1], 'score' : v} for k, v in mapping.items()]\n",
    "\n",
    "results = {\n",
    "    'next_tok_attn' : json_tuple_keys(normalize(next_tok_attn, total_examples)),\n",
    "    'end_tok_attn' : json_tuple_keys(normalize(end_tok_attn, total_examples))\n",
    "}\n",
    "\n",
    "path = f'./results/attention_scores/{model_name}/'\n",
    "path += f'{args.ckpt}/' if args.ckpt is not None else ''\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "fname = f'n{args.n}_seqlen{args.sequence_len}'\n",
    "fname += f'_randomtokents' if args.random_tok_entities else ''\n",
    "fname += '.json'\n",
    "print(path + fname)\n",
    "\n",
    "with open(path + fname, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55729978-d937-4217-ba44-2aee61211c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 13, head: 23, score: 0.22054247744381428\n",
      "layer: 14, head: 1, score: 0.3419952765107155\n",
      "layer: 16, head: 17, score: 0.22978569567203522\n",
      "layer: 16, head: 29, score: 0.1967000002041459\n",
      "layer: 22, head: 17, score: 0.18392631318420172\n"
     ]
    }
   ],
   "source": [
    "for r in results['end_tok_attn']:\n",
    "    if r['score'] > 0.18:\n",
    "        print(f\"layer: {r['layer']}, head: {r['head_idx']}, score: {r['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "124e7094-6b2a-4bd8-9926-74e12ca5f259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 2, head: 16, score: 0.9304505363106728\n",
      "layer: 2, head: 17, score: 0.8246364444494247\n",
      "layer: 5, head: 8, score: 0.7392003536224365\n",
      "layer: 14, head: 22, score: 0.9291573166847229\n"
     ]
    }
   ],
   "source": [
    "for r in results['next_tok_attn']:\n",
    "    if r['score'] > 0.7:\n",
    "        print(f\"layer: {r['layer']}, head: {r['head_idx']}, score: {r['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cd7b88b-1ffc-4263-bd1b-96f34103f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/attention_scores/Llama-3.1-8B-Instruct/n2048_seqlen30_randomtokents.json', 'r') as file:\n",
    "    attention_score = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85a76e8f-ca9e-41b9-9c1f-669bc069ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_induction_scores_new = []\n",
    "for r in attention_score['next_tok_attn']:\n",
    "    all_induction_scores_new.append(r['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30b228cf-33af-4ad1-af65-d31a9be199ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/induction_heads/induction_dataset.json', 'r') as file:\n",
    "    induction_scores = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6955f239-51d6-454e-b9c2-b982b13e97ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'meta-llama/Llama-3.1-8B-Instruct',\n",
       " 'model_configuration': {'num_layers': 32,\n",
       "  'num_heads': 32,\n",
       "  'hidden_size': 4096},\n",
       " 'induction_scores': [[0.002057015895843506,\n",
       "   0.004554629325866699,\n",
       "   9.041652083396912e-05,\n",
       "   0.002595454454421997,\n",
       "   0.0053444504737854,\n",
       "   0.00609821081161499,\n",
       "   0.005044519901275635,\n",
       "   0.005181789398193359,\n",
       "   0.008305668830871582,\n",
       "   0.011712074279785156,\n",
       "   0.00981128215789795,\n",
       "   0.00990152359008789,\n",
       "   0.009547591209411621,\n",
       "   0.01265108585357666,\n",
       "   0.01101827621459961,\n",
       "   0.011073112487792969,\n",
       "   0.006490349769592285,\n",
       "   0.006488025188446045,\n",
       "   0.006293296813964844,\n",
       "   0.008196592330932617,\n",
       "   0.00968468189239502,\n",
       "   0.007330358028411865,\n",
       "   0.008706450462341309,\n",
       "   0.008365869522094727,\n",
       "   0.00277063250541687,\n",
       "   0.005135774612426758,\n",
       "   0.0028919577598571777,\n",
       "   0.005359292030334473,\n",
       "   0.007312655448913574,\n",
       "   0.005748748779296875,\n",
       "   0.0039976537227630615,\n",
       "   0.012755155563354492],\n",
       "  [0.004854917526245117,\n",
       "   0.008668601512908936,\n",
       "   0.008793115615844727,\n",
       "   0.0046097636222839355,\n",
       "   0.00442737340927124,\n",
       "   0.0058133602142333984,\n",
       "   0.0077018141746521,\n",
       "   0.009098172187805176,\n",
       "   0.005564272403717041,\n",
       "   0.009806632995605469,\n",
       "   0.0019195228815078735,\n",
       "   0.0065607428550720215,\n",
       "   0.009938716888427734,\n",
       "   0.0032423585653305054,\n",
       "   0.008021533489227295,\n",
       "   0.006778359413146973,\n",
       "   0.0022999197244644165,\n",
       "   0.006731390953063965,\n",
       "   0.002500295639038086,\n",
       "   0.00628662109375,\n",
       "   0.0007409341633319855,\n",
       "   0.0017209649085998535,\n",
       "   0.013654232025146484,\n",
       "   0.01216888427734375,\n",
       "   0.008666634559631348,\n",
       "   0.005883932113647461,\n",
       "   0.002089366316795349,\n",
       "   0.0039844512939453125,\n",
       "   0.008902668952941895,\n",
       "   0.009472966194152832,\n",
       "   0.005696773529052734,\n",
       "   0.007956624031066895],\n",
       "  [0.0006507560610771179,\n",
       "   0.0009828470647335052,\n",
       "   0.0005502849817276001,\n",
       "   0.002338990569114685,\n",
       "   0.002125069499015808,\n",
       "   0.0037288665771484375,\n",
       "   0.003221064805984497,\n",
       "   0.0005273334681987762,\n",
       "   0.0004249066114425659,\n",
       "   0.0004100804217159748,\n",
       "   0.001329563558101654,\n",
       "   0.000533493235707283,\n",
       "   0.307464599609375,\n",
       "   0.021290063858032227,\n",
       "   0.16144371032714844,\n",
       "   0.00884854793548584,\n",
       "   0.0008637942373752594,\n",
       "   0.0006253905594348907,\n",
       "   0.000526992604136467,\n",
       "   0.0045667290687561035,\n",
       "   0.34928131103515625,\n",
       "   0.19169998168945312,\n",
       "   0.8215408325195312,\n",
       "   0.07705211639404297,\n",
       "   0.0020161718130111694,\n",
       "   0.38069915771484375,\n",
       "   0.028683185577392578,\n",
       "   0.0073493123054504395,\n",
       "   0.0005663260817527771,\n",
       "   0.0008347854018211365,\n",
       "   0.0003790091723203659,\n",
       "   0.00043754372745752335],\n",
       "  [0.008670449256896973,\n",
       "   0.004918038845062256,\n",
       "   0.001524314284324646,\n",
       "   0.0008086711168289185,\n",
       "   0.00011885259300470352,\n",
       "   0.00021522678434848785,\n",
       "   0.00020623020827770233,\n",
       "   0.00024427659809589386,\n",
       "   0.00021511688828468323,\n",
       "   0.0012201964855194092,\n",
       "   0.00015063956379890442,\n",
       "   0.0003188643604516983,\n",
       "   0.008030354976654053,\n",
       "   0.005454421043395996,\n",
       "   0.001190684735774994,\n",
       "   0.0019578784704208374,\n",
       "   0.00029677897691726685,\n",
       "   9.675626643002033e-05,\n",
       "   8.86301277205348e-05,\n",
       "   0.00023994222283363342,\n",
       "   0.0030278265476226807,\n",
       "   0.004798471927642822,\n",
       "   0.008512735366821289,\n",
       "   0.0017624497413635254,\n",
       "   0.0012042522430419922,\n",
       "   0.0028418898582458496,\n",
       "   0.0006659850478172302,\n",
       "   0.0038189589977264404,\n",
       "   0.0015077143907546997,\n",
       "   0.0027160048484802246,\n",
       "   0.007817327976226807,\n",
       "   0.0015529096126556396],\n",
       "  [0.0028693079948425293,\n",
       "   0.002963811159133911,\n",
       "   0.0012324899435043335,\n",
       "   0.0003590919077396393,\n",
       "   0.00031507015228271484,\n",
       "   0.0005598627030849457,\n",
       "   0.017372608184814453,\n",
       "   0.00035146623849868774,\n",
       "   0.0032927989959716797,\n",
       "   0.0005019605159759521,\n",
       "   0.0021116435527801514,\n",
       "   0.0003747977316379547,\n",
       "   4.4397893361747265e-05,\n",
       "   0.0012226253747940063,\n",
       "   9.525846689939499e-05,\n",
       "   0.013725996017456055,\n",
       "   0.004553288221359253,\n",
       "   0.0003731735050678253,\n",
       "   0.00025210902094841003,\n",
       "   0.024107933044433594,\n",
       "   0.004560291767120361,\n",
       "   0.0017968714237213135,\n",
       "   0.001769036054611206,\n",
       "   0.0035290420055389404,\n",
       "   0.00010285433381795883,\n",
       "   0.0005642920732498169,\n",
       "   0.0008732900023460388,\n",
       "   0.0002622026950120926,\n",
       "   0.003569573163986206,\n",
       "   0.005590677261352539,\n",
       "   0.001940697431564331,\n",
       "   0.002905607223510742],\n",
       "  [0.0013300180435180664,\n",
       "   0.008739948272705078,\n",
       "   0.000733301043510437,\n",
       "   0.0006593689322471619,\n",
       "   0.0015325695276260376,\n",
       "   0.010796666145324707,\n",
       "   0.005419671535491943,\n",
       "   0.009141206741333008,\n",
       "   0.6422958374023438,\n",
       "   0.2298583984375,\n",
       "   0.031533002853393555,\n",
       "   0.579925537109375,\n",
       "   0.0017907321453094482,\n",
       "   0.0002204347401857376,\n",
       "   0.00014864187687635422,\n",
       "   0.000522080808877945,\n",
       "   0.0035078823566436768,\n",
       "   0.006470739841461182,\n",
       "   0.008486568927764893,\n",
       "   0.002224057912826538,\n",
       "   0.00163935124874115,\n",
       "   0.008237361907958984,\n",
       "   0.006462752819061279,\n",
       "   0.008430838584899902,\n",
       "   0.002930760383605957,\n",
       "   0.0014417767524719238,\n",
       "   0.0007421448826789856,\n",
       "   0.0023709237575531006,\n",
       "   0.000954940915107727,\n",
       "   0.0009808838367462158,\n",
       "   0.0006900802254676819,\n",
       "   0.00033099763095378876],\n",
       "  [0.0033965706825256348,\n",
       "   0.002129495143890381,\n",
       "   0.028683185577392578,\n",
       "   0.007339894771575928,\n",
       "   0.004845857620239258,\n",
       "   0.0018923431634902954,\n",
       "   0.005248308181762695,\n",
       "   0.0032255053520202637,\n",
       "   0.00016784854233264923,\n",
       "   0.0034643709659576416,\n",
       "   0.00015414319932460785,\n",
       "   0.000368267297744751,\n",
       "   0.0005832388997077942,\n",
       "   0.00026174262166023254,\n",
       "   0.0033141374588012695,\n",
       "   0.00039372220635414124,\n",
       "   0.0002866927534341812,\n",
       "   0.005685031414031982,\n",
       "   0.0011844635009765625,\n",
       "   0.0006823241710662842,\n",
       "   0.007182180881500244,\n",
       "   0.007233858108520508,\n",
       "   0.010957837104797363,\n",
       "   0.00209181010723114,\n",
       "   0.01113581657409668,\n",
       "   0.014973878860473633,\n",
       "   0.012030839920043945,\n",
       "   0.01636195182800293,\n",
       "   0.02301478385925293,\n",
       "   0.02539372444152832,\n",
       "   0.0003818795084953308,\n",
       "   0.14146995544433594],\n",
       "  [0.0003318954259157181,\n",
       "   0.0001958981156349182,\n",
       "   0.00035502389073371887,\n",
       "   0.011603593826293945,\n",
       "   0.001461029052734375,\n",
       "   7.336627459153533e-05,\n",
       "   0.007306873798370361,\n",
       "   0.007454633712768555,\n",
       "   0.002338618040084839,\n",
       "   0.0038338303565979004,\n",
       "   0.0031603574752807617,\n",
       "   0.0019222348928451538,\n",
       "   0.0019011497497558594,\n",
       "   0.00468522310256958,\n",
       "   0.0034096837043762207,\n",
       "   0.004228949546813965,\n",
       "   0.005521237850189209,\n",
       "   0.007024288177490234,\n",
       "   0.0057141780853271484,\n",
       "   0.005247175693511963,\n",
       "   0.00359991192817688,\n",
       "   0.008772134780883789,\n",
       "   0.007380545139312744,\n",
       "   0.021292448043823242,\n",
       "   0.0199887752532959,\n",
       "   0.00530010461807251,\n",
       "   0.007009923458099365,\n",
       "   0.001787632703781128,\n",
       "   0.002818495035171509,\n",
       "   0.0033216476440429688,\n",
       "   0.005456030368804932,\n",
       "   0.00325128436088562],\n",
       "  [0.09600448608398438,\n",
       "   0.8407974243164062,\n",
       "   0.008002758026123047,\n",
       "   0.05248737335205078,\n",
       "   0.0012949258089065552,\n",
       "   0.005047619342803955,\n",
       "   0.001956269145011902,\n",
       "   0.0046425461769104,\n",
       "   0.008896946907043457,\n",
       "   0.03629016876220703,\n",
       "   0.002746760845184326,\n",
       "   0.018218994140625,\n",
       "   0.001106366515159607,\n",
       "   0.002424955368041992,\n",
       "   0.0015578866004943848,\n",
       "   0.0017648041248321533,\n",
       "   0.01067495346069336,\n",
       "   0.004087716341018677,\n",
       "   0.004140257835388184,\n",
       "   0.010856866836547852,\n",
       "   0.0024068355560302734,\n",
       "   0.0018393993377685547,\n",
       "   0.0006301775574684143,\n",
       "   0.0023981332778930664,\n",
       "   0.00961315631866455,\n",
       "   0.012511610984802246,\n",
       "   0.004600107669830322,\n",
       "   0.0033613741397857666,\n",
       "   0.0036465227603912354,\n",
       "   0.005264997482299805,\n",
       "   0.006245732307434082,\n",
       "   0.010967612266540527],\n",
       "  [0.010255932807922363,\n",
       "   0.008772850036621094,\n",
       "   0.01717686653137207,\n",
       "   0.011189699172973633,\n",
       "   0.0062177181243896484,\n",
       "   0.0021905899047851562,\n",
       "   0.004320383071899414,\n",
       "   0.0015306025743484497,\n",
       "   0.0009698420763015747,\n",
       "   0.0012390762567520142,\n",
       "   0.000959545373916626,\n",
       "   9.735347703099251e-05,\n",
       "   0.032643795013427734,\n",
       "   0.036052703857421875,\n",
       "   0.009528398513793945,\n",
       "   0.005608797073364258,\n",
       "   0.0055890679359436035,\n",
       "   0.004892230033874512,\n",
       "   0.00694805383682251,\n",
       "   0.006093740463256836,\n",
       "   0.021619319915771484,\n",
       "   0.0030989348888397217,\n",
       "   0.008476614952087402,\n",
       "   0.0026130080223083496,\n",
       "   0.00286257266998291,\n",
       "   0.01656949520111084,\n",
       "   0.0015527904033660889,\n",
       "   0.15631866455078125,\n",
       "   0.02317070960998535,\n",
       "   0.018871784210205078,\n",
       "   0.003049910068511963,\n",
       "   0.11959266662597656],\n",
       "  [0.005898714065551758,\n",
       "   0.016865968704223633,\n",
       "   0.0029581189155578613,\n",
       "   0.025792837142944336,\n",
       "   0.0037142932415008545,\n",
       "   0.02458643913269043,\n",
       "   0.009508252143859863,\n",
       "   0.012740731239318848,\n",
       "   0.003542274236679077,\n",
       "   0.002964913845062256,\n",
       "   0.003299415111541748,\n",
       "   0.001055493950843811,\n",
       "   0.06698179244995117,\n",
       "   0.2827873229980469,\n",
       "   0.5748367309570312,\n",
       "   0.009138226509094238,\n",
       "   0.0022204816341400146,\n",
       "   0.008969902992248535,\n",
       "   0.02584385871887207,\n",
       "   0.012923598289489746,\n",
       "   0.004476428031921387,\n",
       "   0.003046661615371704,\n",
       "   0.004280030727386475,\n",
       "   0.0018892735242843628,\n",
       "   0.0059986114501953125,\n",
       "   0.00788193941116333,\n",
       "   0.003933370113372803,\n",
       "   0.0110548734664917,\n",
       "   0.011041641235351562,\n",
       "   0.024181127548217773,\n",
       "   0.0020342618227005005,\n",
       "   0.014281511306762695],\n",
       "  [0.004343152046203613,\n",
       "   0.006942451000213623,\n",
       "   0.008610248565673828,\n",
       "   0.0077391862869262695,\n",
       "   0.010100603103637695,\n",
       "   0.08565807342529297,\n",
       "   0.030494213104248047,\n",
       "   0.01968526840209961,\n",
       "   0.0023980438709259033,\n",
       "   0.005248963832855225,\n",
       "   0.0025724470615386963,\n",
       "   0.0027955472469329834,\n",
       "   0.01822519302368164,\n",
       "   0.006133675575256348,\n",
       "   0.004915416240692139,\n",
       "   0.013466238975524902,\n",
       "   0.0005620718002319336,\n",
       "   0.000527944415807724,\n",
       "   0.004206061363220215,\n",
       "   0.001990094780921936,\n",
       "   0.00460439920425415,\n",
       "   0.017628908157348633,\n",
       "   0.015929341316223145,\n",
       "   0.020647048950195312,\n",
       "   0.004546642303466797,\n",
       "   0.005373179912567139,\n",
       "   0.005438268184661865,\n",
       "   0.002866029739379883,\n",
       "   0.011205673217773438,\n",
       "   0.0034222304821014404,\n",
       "   0.007053077220916748,\n",
       "   0.0006240606307983398],\n",
       "  [0.0018602758646011353,\n",
       "   0.013990163803100586,\n",
       "   0.0030045807361602783,\n",
       "   0.0023908019065856934,\n",
       "   0.006051540374755859,\n",
       "   0.0035623013973236084,\n",
       "   0.006172060966491699,\n",
       "   0.0021810531616210938,\n",
       "   0.007690846920013428,\n",
       "   0.006041884422302246,\n",
       "   0.011162161827087402,\n",
       "   0.012695550918579102,\n",
       "   3.157230094075203e-05,\n",
       "   0.0016585439443588257,\n",
       "   0.013971805572509766,\n",
       "   0.0034238994121551514,\n",
       "   0.0010573193430900574,\n",
       "   0.0033609867095947266,\n",
       "   0.0019893497228622437,\n",
       "   0.0006223395466804504,\n",
       "   0.005471169948577881,\n",
       "   0.0029046237468719482,\n",
       "   0.005106449127197266,\n",
       "   0.005754292011260986,\n",
       "   0.002756834030151367,\n",
       "   0.0030871033668518066,\n",
       "   0.0020675957202911377,\n",
       "   0.0030162036418914795,\n",
       "   0.005457103252410889,\n",
       "   0.004360079765319824,\n",
       "   0.004849791526794434,\n",
       "   0.007726430892944336],\n",
       "  [0.019732236862182617,\n",
       "   0.022212743759155273,\n",
       "   0.024118900299072266,\n",
       "   0.023547887802124023,\n",
       "   0.1585540771484375,\n",
       "   0.0601506233215332,\n",
       "   0.34462738037109375,\n",
       "   0.0037299692630767822,\n",
       "   0.05561542510986328,\n",
       "   0.01952075958251953,\n",
       "   0.013364672660827637,\n",
       "   0.018924713134765625,\n",
       "   0.010988116264343262,\n",
       "   0.04751443862915039,\n",
       "   0.008849501609802246,\n",
       "   0.006269574165344238,\n",
       "   0.0460972785949707,\n",
       "   0.08600234985351562,\n",
       "   0.1688976287841797,\n",
       "   0.011560440063476562,\n",
       "   0.013762831687927246,\n",
       "   0.019974946975708008,\n",
       "   0.0029287338256835938,\n",
       "   0.0056092143058776855,\n",
       "   0.0022783875465393066,\n",
       "   0.00983583927154541,\n",
       "   0.03839921951293945,\n",
       "   0.14379119873046875,\n",
       "   0.006418824195861816,\n",
       "   0.002306342124938965,\n",
       "   0.011354923248291016,\n",
       "   0.0121307373046875],\n",
       "  [0.010957002639770508,\n",
       "   0.013270258903503418,\n",
       "   0.013355255126953125,\n",
       "   0.018725872039794922,\n",
       "   0.017594575881958008,\n",
       "   0.02471923828125,\n",
       "   0.006451725959777832,\n",
       "   0.008993744850158691,\n",
       "   0.000645078718662262,\n",
       "   0.001286432147026062,\n",
       "   0.001829683780670166,\n",
       "   0.0016338825225830078,\n",
       "   0.025093793869018555,\n",
       "   0.13360214233398438,\n",
       "   0.02489161491394043,\n",
       "   0.007409930229187012,\n",
       "   0.02456808090209961,\n",
       "   0.005529344081878662,\n",
       "   0.07637500762939453,\n",
       "   0.0009709447622299194,\n",
       "   0.142669677734375,\n",
       "   0.021915197372436523,\n",
       "   0.13854598999023438,\n",
       "   0.026110410690307617,\n",
       "   0.020902156829833984,\n",
       "   0.012700915336608887,\n",
       "   2.4798966478556395e-05,\n",
       "   0.013460040092468262,\n",
       "   0.0349578857421875,\n",
       "   0.10445594787597656,\n",
       "   0.06227254867553711,\n",
       "   0.08664608001708984],\n",
       "  [0.0009916499257087708,\n",
       "   0.684967041015625,\n",
       "   0.09985828399658203,\n",
       "   0.10583209991455078,\n",
       "   0.006044924259185791,\n",
       "   0.012433409690856934,\n",
       "   0.00404694676399231,\n",
       "   0.001387074589729309,\n",
       "   0.006627440452575684,\n",
       "   0.004677236080169678,\n",
       "   0.016525983810424805,\n",
       "   0.03541231155395508,\n",
       "   0.0008899867534637451,\n",
       "   0.027476072311401367,\n",
       "   0.04056978225708008,\n",
       "   0.00837254524230957,\n",
       "   0.010782599449157715,\n",
       "   0.011744856834411621,\n",
       "   0.01697230339050293,\n",
       "   0.0014803707599639893,\n",
       "   0.014418601989746094,\n",
       "   0.049602508544921875,\n",
       "   0.010382413864135742,\n",
       "   0.010888457298278809,\n",
       "   0.01151132583618164,\n",
       "   0.012918472290039062,\n",
       "   0.026479721069335938,\n",
       "   0.007972776889801025,\n",
       "   0.14942359924316406,\n",
       "   0.1290283203125,\n",
       "   0.9475479125976562,\n",
       "   0.0018215775489807129],\n",
       "  [0.08108234405517578,\n",
       "   0.34420013427734375,\n",
       "   0.08387374877929688,\n",
       "   0.04665422439575195,\n",
       "   0.002856522798538208,\n",
       "   0.016411423683166504,\n",
       "   0.002052709460258484,\n",
       "   0.004316985607147217,\n",
       "   0.10817813873291016,\n",
       "   0.021770477294921875,\n",
       "   0.020449399948120117,\n",
       "   0.009491324424743652,\n",
       "   0.0009135231375694275,\n",
       "   0.0041915178298950195,\n",
       "   0.002205461263656616,\n",
       "   0.002184748649597168,\n",
       "   0.005350589752197266,\n",
       "   0.006399929523468018,\n",
       "   0.022480487823486328,\n",
       "   0.15435791015625,\n",
       "   0.647491455078125,\n",
       "   0.054355621337890625,\n",
       "   0.0022246092557907104,\n",
       "   0.1742076873779297,\n",
       "   0.016875267028808594,\n",
       "   0.11979389190673828,\n",
       "   0.03902006149291992,\n",
       "   0.028381824493408203,\n",
       "   0.0016205906867980957,\n",
       "   0.00016939174383878708,\n",
       "   0.0023636221885681152,\n",
       "   0.0019370615482330322],\n",
       "  [0.010235428810119629,\n",
       "   0.0039886534214019775,\n",
       "   0.011957049369812012,\n",
       "   0.01508796215057373,\n",
       "   0.005185306072235107,\n",
       "   0.003308594226837158,\n",
       "   0.012433409690856934,\n",
       "   0.003350198268890381,\n",
       "   0.018340349197387695,\n",
       "   0.0070076584815979,\n",
       "   0.00524294376373291,\n",
       "   0.0011162906885147095,\n",
       "   0.00460362434387207,\n",
       "   0.0031398534774780273,\n",
       "   0.004010587930679321,\n",
       "   0.0034820735454559326,\n",
       "   0.0033501386642456055,\n",
       "   0.0013588517904281616,\n",
       "   0.005814552307128906,\n",
       "   0.004707992076873779,\n",
       "   0.0011680126190185547,\n",
       "   0.11443138122558594,\n",
       "   0.009565234184265137,\n",
       "   0.07453727722167969,\n",
       "   0.14464950561523438,\n",
       "   0.08355140686035156,\n",
       "   0.11264705657958984,\n",
       "   0.10984039306640625,\n",
       "   0.03459453582763672,\n",
       "   0.12208938598632812,\n",
       "   0.0013572871685028076,\n",
       "   0.06943893432617188],\n",
       "  [0.0089874267578125,\n",
       "   0.0022244155406951904,\n",
       "   0.013051509857177734,\n",
       "   0.0019554048776626587,\n",
       "   0.025284290313720703,\n",
       "   0.023639440536499023,\n",
       "   0.0023546814918518066,\n",
       "   0.0006335712969303131,\n",
       "   0.05719327926635742,\n",
       "   0.03505849838256836,\n",
       "   0.0013447850942611694,\n",
       "   0.004507958889007568,\n",
       "   0.002424091100692749,\n",
       "   0.0009180903434753418,\n",
       "   0.006650269031524658,\n",
       "   0.0012952983379364014,\n",
       "   0.03796577453613281,\n",
       "   0.0011314749717712402,\n",
       "   0.012500524520874023,\n",
       "   0.005665779113769531,\n",
       "   0.0477752685546875,\n",
       "   0.00725787878036499,\n",
       "   0.053540706634521484,\n",
       "   0.022668123245239258,\n",
       "   0.003542482852935791,\n",
       "   0.0005499757826328278,\n",
       "   0.00039687380194664,\n",
       "   0.0012238174676895142,\n",
       "   0.05323600769042969,\n",
       "   0.030111312866210938,\n",
       "   0.022946834564208984,\n",
       "   0.002277284860610962],\n",
       "  [0.15135574340820312,\n",
       "   0.032495737075805664,\n",
       "   0.09119129180908203,\n",
       "   0.4110450744628906,\n",
       "   0.006082773208618164,\n",
       "   0.0013625025749206543,\n",
       "   0.0033144354820251465,\n",
       "   0.0009982138872146606,\n",
       "   0.0030942559242248535,\n",
       "   0.04516172409057617,\n",
       "   0.002106994390487671,\n",
       "   0.004834890365600586,\n",
       "   0.029271602630615234,\n",
       "   0.06836223602294922,\n",
       "   0.04942178726196289,\n",
       "   0.021956920623779297,\n",
       "   0.004001617431640625,\n",
       "   0.0016954094171524048,\n",
       "   0.0018076300621032715,\n",
       "   0.002877563238143921,\n",
       "   0.003561466932296753,\n",
       "   0.007271230220794678,\n",
       "   0.004290968179702759,\n",
       "   0.04871511459350586,\n",
       "   0.001054033637046814,\n",
       "   0.011893630027770996,\n",
       "   0.0003740042448043823,\n",
       "   0.01210486888885498,\n",
       "   0.0013623982667922974,\n",
       "   0.0012933313846588135,\n",
       "   0.004225492477416992,\n",
       "   0.0009846091270446777],\n",
       "  [0.04309415817260742,\n",
       "   0.4908790588378906,\n",
       "   0.026110410690307617,\n",
       "   0.02140355110168457,\n",
       "   0.0009972453117370605,\n",
       "   0.0012193024158477783,\n",
       "   0.0008734911680221558,\n",
       "   0.000542372465133667,\n",
       "   0.002783268690109253,\n",
       "   0.06640768051147461,\n",
       "   0.019162654876708984,\n",
       "   0.007900476455688477,\n",
       "   0.004265159368515015,\n",
       "   0.24176597595214844,\n",
       "   0.5614013671875,\n",
       "   0.1547069549560547,\n",
       "   0.003658384084701538,\n",
       "   0.0019767284393310547,\n",
       "   0.0018579661846160889,\n",
       "   0.0018348246812820435,\n",
       "   0.09081172943115234,\n",
       "   0.0009861290454864502,\n",
       "   0.0019090771675109863,\n",
       "   0.17084503173828125,\n",
       "   0.02443861961364746,\n",
       "   0.1081991195678711,\n",
       "   0.1376209259033203,\n",
       "   0.023464441299438477,\n",
       "   0.000893227756023407,\n",
       "   0.001353919506072998,\n",
       "   0.00871807336807251,\n",
       "   0.0016880184412002563],\n",
       "  [0.0032114386558532715,\n",
       "   0.06038475036621094,\n",
       "   0.03760528564453125,\n",
       "   0.011637091636657715,\n",
       "   0.00013291090726852417,\n",
       "   0.00041607022285461426,\n",
       "   0.0003467835485935211,\n",
       "   0.0002716127783060074,\n",
       "   0.09734249114990234,\n",
       "   0.0005657635629177094,\n",
       "   0.0005663856863975525,\n",
       "   0.03252863883972168,\n",
       "   0.01996588706970215,\n",
       "   0.016564369201660156,\n",
       "   0.08688068389892578,\n",
       "   0.02942824363708496,\n",
       "   0.0011799782514572144,\n",
       "   0.0010888874530792236,\n",
       "   0.001849845051765442,\n",
       "   0.0009313970804214478,\n",
       "   0.0043253302574157715,\n",
       "   0.030785322189331055,\n",
       "   0.03586387634277344,\n",
       "   0.0073430538177490234,\n",
       "   0.01632559299468994,\n",
       "   0.009577631950378418,\n",
       "   0.08245849609375,\n",
       "   0.006125152111053467,\n",
       "   0.010887861251831055,\n",
       "   0.029104948043823242,\n",
       "   0.017778873443603516,\n",
       "   0.07887840270996094],\n",
       "  [0.122955322265625,\n",
       "   0.09197235107421875,\n",
       "   0.12093448638916016,\n",
       "   0.002731829881668091,\n",
       "   0.005501687526702881,\n",
       "   0.005116760730743408,\n",
       "   0.004320770502090454,\n",
       "   0.002164199948310852,\n",
       "   0.08819293975830078,\n",
       "   0.007355153560638428,\n",
       "   0.02107548713684082,\n",
       "   0.05554342269897461,\n",
       "   0.17603492736816406,\n",
       "   0.17609214782714844,\n",
       "   0.32834625244140625,\n",
       "   0.15461349487304688,\n",
       "   0.00094623863697052,\n",
       "   0.0011748969554901123,\n",
       "   0.001712903380393982,\n",
       "   0.0022131800651550293,\n",
       "   0.0039021074771881104,\n",
       "   0.0011392086744308472,\n",
       "   0.0006709396839141846,\n",
       "   0.0025836825370788574,\n",
       "   0.005994856357574463,\n",
       "   0.002663731575012207,\n",
       "   0.002306699752807617,\n",
       "   0.061087608337402344,\n",
       "   0.1111898422241211,\n",
       "   0.12859630584716797,\n",
       "   0.013618826866149902,\n",
       "   0.0914602279663086],\n",
       "  [0.0021130740642547607,\n",
       "   0.0019286423921585083,\n",
       "   0.002950429916381836,\n",
       "   0.002260178327560425,\n",
       "   0.0031486451625823975,\n",
       "   0.10373306274414062,\n",
       "   0.08487606048583984,\n",
       "   0.010957121849060059,\n",
       "   0.0037517547607421875,\n",
       "   0.004419267177581787,\n",
       "   0.0028625428676605225,\n",
       "   0.0017709732055664062,\n",
       "   0.08372783660888672,\n",
       "   0.08665180206298828,\n",
       "   0.07437419891357422,\n",
       "   0.000997982919216156,\n",
       "   0.00029408931732177734,\n",
       "   0.0006665140390396118,\n",
       "   0.003380030393600464,\n",
       "   0.0007874146103858948,\n",
       "   0.11893653869628906,\n",
       "   0.0033584535121917725,\n",
       "   0.13576889038085938,\n",
       "   0.0016051381826400757,\n",
       "   0.0046648383140563965,\n",
       "   0.12990951538085938,\n",
       "   0.004259288311004639,\n",
       "   0.11981964111328125,\n",
       "   0.0011676996946334839,\n",
       "   0.00017618294805288315,\n",
       "   0.0001538274809718132,\n",
       "   0.0002520177513360977],\n",
       "  [0.0033877193927764893,\n",
       "   0.0247347354888916,\n",
       "   0.003007739782333374,\n",
       "   0.035748958587646484,\n",
       "   0.0012325048446655273,\n",
       "   0.000553131103515625,\n",
       "   0.0013207793235778809,\n",
       "   0.003979146480560303,\n",
       "   0.0003350377082824707,\n",
       "   0.00031758472323417664,\n",
       "   0.000293167307972908,\n",
       "   0.0004919432103633881,\n",
       "   0.004029572010040283,\n",
       "   0.001033499836921692,\n",
       "   0.005192875862121582,\n",
       "   0.0007487311959266663,\n",
       "   0.12156867980957031,\n",
       "   0.11663341522216797,\n",
       "   0.11602783203125,\n",
       "   0.003042161464691162,\n",
       "   0.1141500473022461,\n",
       "   0.0009660795331001282,\n",
       "   0.13032245635986328,\n",
       "   0.1747283935546875,\n",
       "   0.10401344299316406,\n",
       "   0.12723350524902344,\n",
       "   0.030057191848754883,\n",
       "   0.4481010437011719,\n",
       "   0.0009713694453239441,\n",
       "   0.0009054094552993774,\n",
       "   0.0004982948303222656,\n",
       "   0.0012294873595237732],\n",
       "  [0.0019403398036956787,\n",
       "   0.0045424699783325195,\n",
       "   0.009369969367980957,\n",
       "   0.007052063941955566,\n",
       "   0.091644287109375,\n",
       "   0.15472030639648438,\n",
       "   0.1455821990966797,\n",
       "   0.11577129364013672,\n",
       "   0.0008865892887115479,\n",
       "   0.0006508752703666687,\n",
       "   0.0013628751039505005,\n",
       "   0.0004355907440185547,\n",
       "   0.123992919921875,\n",
       "   0.1236572265625,\n",
       "   0.08546066284179688,\n",
       "   0.0930185317993164,\n",
       "   0.0036381781101226807,\n",
       "   0.019688129425048828,\n",
       "   0.035982608795166016,\n",
       "   0.0015893131494522095,\n",
       "   4.020764026790857e-05,\n",
       "   0.00017601530998945236,\n",
       "   4.371555405668914e-05,\n",
       "   6.495951674878597e-05,\n",
       "   0.0002593863755464554,\n",
       "   0.00041546672582626343,\n",
       "   0.000653587281703949,\n",
       "   0.0006296411156654358,\n",
       "   0.0005074925720691681,\n",
       "   0.0004536285996437073,\n",
       "   0.00010266341269016266,\n",
       "   0.00018176063895225525],\n",
       "  [0.0247802734375,\n",
       "   0.00446707010269165,\n",
       "   0.031068086624145508,\n",
       "   0.026364564895629883,\n",
       "   0.015517711639404297,\n",
       "   0.005053460597991943,\n",
       "   0.010562419891357422,\n",
       "   0.011898994445800781,\n",
       "   0.0016775131225585938,\n",
       "   0.0006157532334327698,\n",
       "   0.00271645188331604,\n",
       "   0.0007196739315986633,\n",
       "   0.145965576171875,\n",
       "   0.47086334228515625,\n",
       "   0.13152217864990234,\n",
       "   0.4880180358886719,\n",
       "   0.002325296401977539,\n",
       "   0.00204254686832428,\n",
       "   0.004594683647155762,\n",
       "   0.013116836547851562,\n",
       "   0.0012910515069961548,\n",
       "   0.004001796245574951,\n",
       "   0.002793222665786743,\n",
       "   0.004794478416442871,\n",
       "   0.0005732178688049316,\n",
       "   0.0010703951120376587,\n",
       "   0.0007338449358940125,\n",
       "   0.046654701232910156,\n",
       "   0.00372922420501709,\n",
       "   0.11305809020996094,\n",
       "   0.03745412826538086,\n",
       "   0.08283424377441406],\n",
       "  [0.0004745200276374817,\n",
       "   0.0009226202964782715,\n",
       "   0.0005035586655139923,\n",
       "   0.0006826594471931458,\n",
       "   0.20409011840820312,\n",
       "   0.22083282470703125,\n",
       "   0.4636344909667969,\n",
       "   0.20166778564453125,\n",
       "   0.00396496057510376,\n",
       "   0.000234188511967659,\n",
       "   0.0007820278406143188,\n",
       "   0.0006830096244812012,\n",
       "   0.0016665756702423096,\n",
       "   0.0030635297298431396,\n",
       "   0.0007540062069892883,\n",
       "   0.003625333309173584,\n",
       "   0.044116973876953125,\n",
       "   0.0036934614181518555,\n",
       "   0.002661079168319702,\n",
       "   0.002367675304412842,\n",
       "   0.20514297485351562,\n",
       "   0.0230867862701416,\n",
       "   0.1433696746826172,\n",
       "   0.11404705047607422,\n",
       "   0.004517018795013428,\n",
       "   0.0006135031580924988,\n",
       "   0.000569559633731842,\n",
       "   0.00040679052472114563,\n",
       "   0.013806939125061035,\n",
       "   0.0004481896758079529,\n",
       "   0.010320901870727539,\n",
       "   0.005196213722229004],\n",
       "  [0.043521881103515625,\n",
       "   0.0008893385529518127,\n",
       "   0.0013580918312072754,\n",
       "   0.0027939975261688232,\n",
       "   0.00015606451779603958,\n",
       "   7.929932326078415e-05,\n",
       "   0.0006527528166770935,\n",
       "   6.233016029000282e-05,\n",
       "   0.0010631829500198364,\n",
       "   0.0006367862224578857,\n",
       "   0.0132676362991333,\n",
       "   0.0033592283725738525,\n",
       "   0.0018773376941680908,\n",
       "   0.05351066589355469,\n",
       "   0.005023300647735596,\n",
       "   0.2396068572998047,\n",
       "   0.0034460127353668213,\n",
       "   0.0021308064460754395,\n",
       "   0.036504268646240234,\n",
       "   0.003265082836151123,\n",
       "   0.029542922973632812,\n",
       "   0.0030496716499328613,\n",
       "   0.0013176798820495605,\n",
       "   0.030483245849609375,\n",
       "   0.012317538261413574,\n",
       "   0.002192944288253784,\n",
       "   6.127078086137772e-05,\n",
       "   0.05384397506713867,\n",
       "   0.0032651126384735107,\n",
       "   0.0033074021339416504,\n",
       "   0.012325286865234375,\n",
       "   0.0011634975671768188],\n",
       "  [0.0017247051000595093,\n",
       "   0.0018402636051177979,\n",
       "   0.006564736366271973,\n",
       "   0.0020161867141723633,\n",
       "   0.0020656436681747437,\n",
       "   0.001828029751777649,\n",
       "   0.000989668071269989,\n",
       "   0.0006357580423355103,\n",
       "   0.00560528039932251,\n",
       "   0.0317080020904541,\n",
       "   0.012161850929260254,\n",
       "   0.02662348747253418,\n",
       "   0.0013329237699508667,\n",
       "   0.001597866415977478,\n",
       "   0.0017536580562591553,\n",
       "   0.0017881393432617188,\n",
       "   0.003716200590133667,\n",
       "   0.003451436758041382,\n",
       "   0.0019237250089645386,\n",
       "   0.004147857427597046,\n",
       "   0.032094478607177734,\n",
       "   0.055536746978759766,\n",
       "   0.11271953582763672,\n",
       "   0.03192567825317383,\n",
       "   0.00017060525715351105,\n",
       "   0.00017988216131925583,\n",
       "   5.309289554134011e-05,\n",
       "   6.634998135268688e-05,\n",
       "   0.00863558053970337,\n",
       "   0.008344054222106934,\n",
       "   0.01880931854248047,\n",
       "   0.02283620834350586],\n",
       "  [0.004162490367889404,\n",
       "   0.02197742462158203,\n",
       "   0.034589290618896484,\n",
       "   0.016393423080444336,\n",
       "   0.001761108636856079,\n",
       "   0.002541571855545044,\n",
       "   0.01134192943572998,\n",
       "   0.002333015203475952,\n",
       "   0.0033053457736968994,\n",
       "   0.02115654945373535,\n",
       "   0.0061844587326049805,\n",
       "   0.039371490478515625,\n",
       "   0.13472366333007812,\n",
       "   0.023426055908203125,\n",
       "   0.060335636138916016,\n",
       "   0.08271503448486328,\n",
       "   0.012342572212219238,\n",
       "   0.009190678596496582,\n",
       "   0.016353249549865723,\n",
       "   0.006096780300140381,\n",
       "   0.07361602783203125,\n",
       "   0.1591663360595703,\n",
       "   0.003948867321014404,\n",
       "   0.004451185464859009,\n",
       "   0.018459558486938477,\n",
       "   0.007246196269989014,\n",
       "   0.06091022491455078,\n",
       "   0.03741121292114258,\n",
       "   0.001764446496963501,\n",
       "   0.12729740142822266,\n",
       "   0.09840106964111328,\n",
       "   0.019389629364013672],\n",
       "  [0.0015778839588165283,\n",
       "   0.0008608400821685791,\n",
       "   0.0011158883571624756,\n",
       "   0.0006743520498275757,\n",
       "   0.003975778818130493,\n",
       "   7.698126137256622e-05,\n",
       "   0.005549490451812744,\n",
       "   0.007354855537414551,\n",
       "   0.0008134916424751282,\n",
       "   0.0007102265954017639,\n",
       "   0.00036317482590675354,\n",
       "   0.007427871227264404,\n",
       "   0.0009790882468223572,\n",
       "   0.007376730442047119,\n",
       "   7.73346982896328e-06,\n",
       "   0.000647909939289093,\n",
       "   0.007666289806365967,\n",
       "   0.004063814878463745,\n",
       "   0.0002075694501399994,\n",
       "   0.005715668201446533,\n",
       "   0.027730226516723633,\n",
       "   0.030253887176513672,\n",
       "   0.008527159690856934,\n",
       "   3.448501229286194e-05,\n",
       "   0.0013695210218429565,\n",
       "   6.997678428888321e-05,\n",
       "   0.0039140284061431885,\n",
       "   0.0027012228965759277,\n",
       "   0.006678462028503418,\n",
       "   0.013282418251037598,\n",
       "   0.017415523529052734,\n",
       "   0.002204716205596924]],\n",
       " 'classified_heads': {'high_induction': [{'layer': 2,\n",
       "    'head': 22,\n",
       "    'score': 0.8215408325195312},\n",
       "   {'layer': 8, 'head': 1, 'score': 0.8407974243164062},\n",
       "   {'layer': 15, 'head': 30, 'score': 0.9475479125976562}],\n",
       "  'medium_induction': [{'layer': 2, 'head': 25, 'score': 0.38069915771484375},\n",
       "   {'layer': 5, 'head': 8, 'score': 0.6422958374023438},\n",
       "   {'layer': 5, 'head': 11, 'score': 0.579925537109375},\n",
       "   {'layer': 10, 'head': 14, 'score': 0.5748367309570312},\n",
       "   {'layer': 15, 'head': 1, 'score': 0.684967041015625},\n",
       "   {'layer': 16, 'head': 20, 'score': 0.647491455078125},\n",
       "   {'layer': 19, 'head': 3, 'score': 0.4110450744628906},\n",
       "   {'layer': 20, 'head': 1, 'score': 0.4908790588378906},\n",
       "   {'layer': 20, 'head': 14, 'score': 0.5614013671875},\n",
       "   {'layer': 24, 'head': 27, 'score': 0.4481010437011719},\n",
       "   {'layer': 26, 'head': 13, 'score': 0.47086334228515625},\n",
       "   {'layer': 26, 'head': 15, 'score': 0.4880180358886719},\n",
       "   {'layer': 27, 'head': 6, 'score': 0.4636344909667969}],\n",
       "  'low_induction': [{'layer': 0, 'head': 0, 'score': 0.002057015895843506},\n",
       "   {'layer': 0, 'head': 1, 'score': 0.004554629325866699},\n",
       "   {'layer': 0, 'head': 2, 'score': 9.041652083396912e-05},\n",
       "   {'layer': 0, 'head': 3, 'score': 0.002595454454421997},\n",
       "   {'layer': 0, 'head': 4, 'score': 0.0053444504737854},\n",
       "   {'layer': 0, 'head': 5, 'score': 0.00609821081161499},\n",
       "   {'layer': 0, 'head': 6, 'score': 0.005044519901275635},\n",
       "   {'layer': 0, 'head': 7, 'score': 0.005181789398193359},\n",
       "   {'layer': 0, 'head': 8, 'score': 0.008305668830871582},\n",
       "   {'layer': 0, 'head': 9, 'score': 0.011712074279785156},\n",
       "   {'layer': 0, 'head': 10, 'score': 0.00981128215789795},\n",
       "   {'layer': 0, 'head': 11, 'score': 0.00990152359008789},\n",
       "   {'layer': 0, 'head': 12, 'score': 0.009547591209411621},\n",
       "   {'layer': 0, 'head': 13, 'score': 0.01265108585357666},\n",
       "   {'layer': 0, 'head': 14, 'score': 0.01101827621459961},\n",
       "   {'layer': 0, 'head': 15, 'score': 0.011073112487792969},\n",
       "   {'layer': 0, 'head': 16, 'score': 0.006490349769592285},\n",
       "   {'layer': 0, 'head': 17, 'score': 0.006488025188446045},\n",
       "   {'layer': 0, 'head': 18, 'score': 0.006293296813964844},\n",
       "   {'layer': 0, 'head': 19, 'score': 0.008196592330932617},\n",
       "   {'layer': 0, 'head': 20, 'score': 0.00968468189239502},\n",
       "   {'layer': 0, 'head': 21, 'score': 0.007330358028411865},\n",
       "   {'layer': 0, 'head': 22, 'score': 0.008706450462341309},\n",
       "   {'layer': 0, 'head': 23, 'score': 0.008365869522094727},\n",
       "   {'layer': 0, 'head': 24, 'score': 0.00277063250541687},\n",
       "   {'layer': 0, 'head': 25, 'score': 0.005135774612426758},\n",
       "   {'layer': 0, 'head': 26, 'score': 0.0028919577598571777},\n",
       "   {'layer': 0, 'head': 27, 'score': 0.005359292030334473},\n",
       "   {'layer': 0, 'head': 28, 'score': 0.007312655448913574},\n",
       "   {'layer': 0, 'head': 29, 'score': 0.005748748779296875},\n",
       "   {'layer': 0, 'head': 30, 'score': 0.0039976537227630615},\n",
       "   {'layer': 0, 'head': 31, 'score': 0.012755155563354492},\n",
       "   {'layer': 1, 'head': 0, 'score': 0.004854917526245117},\n",
       "   {'layer': 1, 'head': 1, 'score': 0.008668601512908936},\n",
       "   {'layer': 1, 'head': 2, 'score': 0.008793115615844727},\n",
       "   {'layer': 1, 'head': 3, 'score': 0.0046097636222839355},\n",
       "   {'layer': 1, 'head': 4, 'score': 0.00442737340927124},\n",
       "   {'layer': 1, 'head': 5, 'score': 0.0058133602142333984},\n",
       "   {'layer': 1, 'head': 6, 'score': 0.0077018141746521},\n",
       "   {'layer': 1, 'head': 7, 'score': 0.009098172187805176},\n",
       "   {'layer': 1, 'head': 8, 'score': 0.005564272403717041},\n",
       "   {'layer': 1, 'head': 9, 'score': 0.009806632995605469},\n",
       "   {'layer': 1, 'head': 10, 'score': 0.0019195228815078735},\n",
       "   {'layer': 1, 'head': 11, 'score': 0.0065607428550720215},\n",
       "   {'layer': 1, 'head': 12, 'score': 0.009938716888427734},\n",
       "   {'layer': 1, 'head': 13, 'score': 0.0032423585653305054},\n",
       "   {'layer': 1, 'head': 14, 'score': 0.008021533489227295},\n",
       "   {'layer': 1, 'head': 15, 'score': 0.006778359413146973},\n",
       "   {'layer': 1, 'head': 16, 'score': 0.0022999197244644165},\n",
       "   {'layer': 1, 'head': 17, 'score': 0.006731390953063965},\n",
       "   {'layer': 1, 'head': 18, 'score': 0.002500295639038086},\n",
       "   {'layer': 1, 'head': 19, 'score': 0.00628662109375},\n",
       "   {'layer': 1, 'head': 20, 'score': 0.0007409341633319855},\n",
       "   {'layer': 1, 'head': 21, 'score': 0.0017209649085998535},\n",
       "   {'layer': 1, 'head': 22, 'score': 0.013654232025146484},\n",
       "   {'layer': 1, 'head': 23, 'score': 0.01216888427734375},\n",
       "   {'layer': 1, 'head': 24, 'score': 0.008666634559631348},\n",
       "   {'layer': 1, 'head': 25, 'score': 0.005883932113647461},\n",
       "   {'layer': 1, 'head': 26, 'score': 0.002089366316795349},\n",
       "   {'layer': 1, 'head': 27, 'score': 0.0039844512939453125},\n",
       "   {'layer': 1, 'head': 28, 'score': 0.008902668952941895},\n",
       "   {'layer': 1, 'head': 29, 'score': 0.009472966194152832},\n",
       "   {'layer': 1, 'head': 30, 'score': 0.005696773529052734},\n",
       "   {'layer': 1, 'head': 31, 'score': 0.007956624031066895},\n",
       "   {'layer': 2, 'head': 0, 'score': 0.0006507560610771179},\n",
       "   {'layer': 2, 'head': 1, 'score': 0.0009828470647335052},\n",
       "   {'layer': 2, 'head': 2, 'score': 0.0005502849817276001},\n",
       "   {'layer': 2, 'head': 3, 'score': 0.002338990569114685},\n",
       "   {'layer': 2, 'head': 4, 'score': 0.002125069499015808},\n",
       "   {'layer': 2, 'head': 5, 'score': 0.0037288665771484375},\n",
       "   {'layer': 2, 'head': 6, 'score': 0.003221064805984497},\n",
       "   {'layer': 2, 'head': 7, 'score': 0.0005273334681987762},\n",
       "   {'layer': 2, 'head': 8, 'score': 0.0004249066114425659},\n",
       "   {'layer': 2, 'head': 9, 'score': 0.0004100804217159748},\n",
       "   {'layer': 2, 'head': 10, 'score': 0.001329563558101654},\n",
       "   {'layer': 2, 'head': 11, 'score': 0.000533493235707283},\n",
       "   {'layer': 2, 'head': 12, 'score': 0.307464599609375},\n",
       "   {'layer': 2, 'head': 13, 'score': 0.021290063858032227},\n",
       "   {'layer': 2, 'head': 14, 'score': 0.16144371032714844},\n",
       "   {'layer': 2, 'head': 15, 'score': 0.00884854793548584},\n",
       "   {'layer': 2, 'head': 16, 'score': 0.0008637942373752594},\n",
       "   {'layer': 2, 'head': 17, 'score': 0.0006253905594348907},\n",
       "   {'layer': 2, 'head': 18, 'score': 0.000526992604136467},\n",
       "   {'layer': 2, 'head': 19, 'score': 0.0045667290687561035},\n",
       "   {'layer': 2, 'head': 20, 'score': 0.34928131103515625},\n",
       "   {'layer': 2, 'head': 21, 'score': 0.19169998168945312},\n",
       "   {'layer': 2, 'head': 23, 'score': 0.07705211639404297},\n",
       "   {'layer': 2, 'head': 24, 'score': 0.0020161718130111694},\n",
       "   {'layer': 2, 'head': 26, 'score': 0.028683185577392578},\n",
       "   {'layer': 2, 'head': 27, 'score': 0.0073493123054504395},\n",
       "   {'layer': 2, 'head': 28, 'score': 0.0005663260817527771},\n",
       "   {'layer': 2, 'head': 29, 'score': 0.0008347854018211365},\n",
       "   {'layer': 2, 'head': 30, 'score': 0.0003790091723203659},\n",
       "   {'layer': 2, 'head': 31, 'score': 0.00043754372745752335},\n",
       "   {'layer': 3, 'head': 0, 'score': 0.008670449256896973},\n",
       "   {'layer': 3, 'head': 1, 'score': 0.004918038845062256},\n",
       "   {'layer': 3, 'head': 2, 'score': 0.001524314284324646},\n",
       "   {'layer': 3, 'head': 3, 'score': 0.0008086711168289185},\n",
       "   {'layer': 3, 'head': 4, 'score': 0.00011885259300470352},\n",
       "   {'layer': 3, 'head': 5, 'score': 0.00021522678434848785},\n",
       "   {'layer': 3, 'head': 6, 'score': 0.00020623020827770233},\n",
       "   {'layer': 3, 'head': 7, 'score': 0.00024427659809589386},\n",
       "   {'layer': 3, 'head': 8, 'score': 0.00021511688828468323},\n",
       "   {'layer': 3, 'head': 9, 'score': 0.0012201964855194092},\n",
       "   {'layer': 3, 'head': 10, 'score': 0.00015063956379890442},\n",
       "   {'layer': 3, 'head': 11, 'score': 0.0003188643604516983},\n",
       "   {'layer': 3, 'head': 12, 'score': 0.008030354976654053},\n",
       "   {'layer': 3, 'head': 13, 'score': 0.005454421043395996},\n",
       "   {'layer': 3, 'head': 14, 'score': 0.001190684735774994},\n",
       "   {'layer': 3, 'head': 15, 'score': 0.0019578784704208374},\n",
       "   {'layer': 3, 'head': 16, 'score': 0.00029677897691726685},\n",
       "   {'layer': 3, 'head': 17, 'score': 9.675626643002033e-05},\n",
       "   {'layer': 3, 'head': 18, 'score': 8.86301277205348e-05},\n",
       "   {'layer': 3, 'head': 19, 'score': 0.00023994222283363342},\n",
       "   {'layer': 3, 'head': 20, 'score': 0.0030278265476226807},\n",
       "   {'layer': 3, 'head': 21, 'score': 0.004798471927642822},\n",
       "   {'layer': 3, 'head': 22, 'score': 0.008512735366821289},\n",
       "   {'layer': 3, 'head': 23, 'score': 0.0017624497413635254},\n",
       "   {'layer': 3, 'head': 24, 'score': 0.0012042522430419922},\n",
       "   {'layer': 3, 'head': 25, 'score': 0.0028418898582458496},\n",
       "   {'layer': 3, 'head': 26, 'score': 0.0006659850478172302},\n",
       "   {'layer': 3, 'head': 27, 'score': 0.0038189589977264404},\n",
       "   {'layer': 3, 'head': 28, 'score': 0.0015077143907546997},\n",
       "   {'layer': 3, 'head': 29, 'score': 0.0027160048484802246},\n",
       "   {'layer': 3, 'head': 30, 'score': 0.007817327976226807},\n",
       "   {'layer': 3, 'head': 31, 'score': 0.0015529096126556396},\n",
       "   {'layer': 4, 'head': 0, 'score': 0.0028693079948425293},\n",
       "   {'layer': 4, 'head': 1, 'score': 0.002963811159133911},\n",
       "   {'layer': 4, 'head': 2, 'score': 0.0012324899435043335},\n",
       "   {'layer': 4, 'head': 3, 'score': 0.0003590919077396393},\n",
       "   {'layer': 4, 'head': 4, 'score': 0.00031507015228271484},\n",
       "   {'layer': 4, 'head': 5, 'score': 0.0005598627030849457},\n",
       "   {'layer': 4, 'head': 6, 'score': 0.017372608184814453},\n",
       "   {'layer': 4, 'head': 7, 'score': 0.00035146623849868774},\n",
       "   {'layer': 4, 'head': 8, 'score': 0.0032927989959716797},\n",
       "   {'layer': 4, 'head': 9, 'score': 0.0005019605159759521},\n",
       "   {'layer': 4, 'head': 10, 'score': 0.0021116435527801514},\n",
       "   {'layer': 4, 'head': 11, 'score': 0.0003747977316379547},\n",
       "   {'layer': 4, 'head': 12, 'score': 4.4397893361747265e-05},\n",
       "   {'layer': 4, 'head': 13, 'score': 0.0012226253747940063},\n",
       "   {'layer': 4, 'head': 14, 'score': 9.525846689939499e-05},\n",
       "   {'layer': 4, 'head': 15, 'score': 0.013725996017456055},\n",
       "   {'layer': 4, 'head': 16, 'score': 0.004553288221359253},\n",
       "   {'layer': 4, 'head': 17, 'score': 0.0003731735050678253},\n",
       "   {'layer': 4, 'head': 18, 'score': 0.00025210902094841003},\n",
       "   {'layer': 4, 'head': 19, 'score': 0.024107933044433594},\n",
       "   {'layer': 4, 'head': 20, 'score': 0.004560291767120361},\n",
       "   {'layer': 4, 'head': 21, 'score': 0.0017968714237213135},\n",
       "   {'layer': 4, 'head': 22, 'score': 0.001769036054611206},\n",
       "   {'layer': 4, 'head': 23, 'score': 0.0035290420055389404},\n",
       "   {'layer': 4, 'head': 24, 'score': 0.00010285433381795883},\n",
       "   {'layer': 4, 'head': 25, 'score': 0.0005642920732498169},\n",
       "   {'layer': 4, 'head': 26, 'score': 0.0008732900023460388},\n",
       "   {'layer': 4, 'head': 27, 'score': 0.0002622026950120926},\n",
       "   {'layer': 4, 'head': 28, 'score': 0.003569573163986206},\n",
       "   {'layer': 4, 'head': 29, 'score': 0.005590677261352539},\n",
       "   {'layer': 4, 'head': 30, 'score': 0.001940697431564331},\n",
       "   {'layer': 4, 'head': 31, 'score': 0.002905607223510742},\n",
       "   {'layer': 5, 'head': 0, 'score': 0.0013300180435180664},\n",
       "   {'layer': 5, 'head': 1, 'score': 0.008739948272705078},\n",
       "   {'layer': 5, 'head': 2, 'score': 0.000733301043510437},\n",
       "   {'layer': 5, 'head': 3, 'score': 0.0006593689322471619},\n",
       "   {'layer': 5, 'head': 4, 'score': 0.0015325695276260376},\n",
       "   {'layer': 5, 'head': 5, 'score': 0.010796666145324707},\n",
       "   {'layer': 5, 'head': 6, 'score': 0.005419671535491943},\n",
       "   {'layer': 5, 'head': 7, 'score': 0.009141206741333008},\n",
       "   {'layer': 5, 'head': 9, 'score': 0.2298583984375},\n",
       "   {'layer': 5, 'head': 10, 'score': 0.031533002853393555},\n",
       "   {'layer': 5, 'head': 12, 'score': 0.0017907321453094482},\n",
       "   {'layer': 5, 'head': 13, 'score': 0.0002204347401857376},\n",
       "   {'layer': 5, 'head': 14, 'score': 0.00014864187687635422},\n",
       "   {'layer': 5, 'head': 15, 'score': 0.000522080808877945},\n",
       "   {'layer': 5, 'head': 16, 'score': 0.0035078823566436768},\n",
       "   {'layer': 5, 'head': 17, 'score': 0.006470739841461182},\n",
       "   {'layer': 5, 'head': 18, 'score': 0.008486568927764893},\n",
       "   {'layer': 5, 'head': 19, 'score': 0.002224057912826538},\n",
       "   {'layer': 5, 'head': 20, 'score': 0.00163935124874115},\n",
       "   {'layer': 5, 'head': 21, 'score': 0.008237361907958984},\n",
       "   {'layer': 5, 'head': 22, 'score': 0.006462752819061279},\n",
       "   {'layer': 5, 'head': 23, 'score': 0.008430838584899902},\n",
       "   {'layer': 5, 'head': 24, 'score': 0.002930760383605957},\n",
       "   {'layer': 5, 'head': 25, 'score': 0.0014417767524719238},\n",
       "   {'layer': 5, 'head': 26, 'score': 0.0007421448826789856},\n",
       "   {'layer': 5, 'head': 27, 'score': 0.0023709237575531006},\n",
       "   {'layer': 5, 'head': 28, 'score': 0.000954940915107727},\n",
       "   {'layer': 5, 'head': 29, 'score': 0.0009808838367462158},\n",
       "   {'layer': 5, 'head': 30, 'score': 0.0006900802254676819},\n",
       "   {'layer': 5, 'head': 31, 'score': 0.00033099763095378876},\n",
       "   {'layer': 6, 'head': 0, 'score': 0.0033965706825256348},\n",
       "   {'layer': 6, 'head': 1, 'score': 0.002129495143890381},\n",
       "   {'layer': 6, 'head': 2, 'score': 0.028683185577392578},\n",
       "   {'layer': 6, 'head': 3, 'score': 0.007339894771575928},\n",
       "   {'layer': 6, 'head': 4, 'score': 0.004845857620239258},\n",
       "   {'layer': 6, 'head': 5, 'score': 0.0018923431634902954},\n",
       "   {'layer': 6, 'head': 6, 'score': 0.005248308181762695},\n",
       "   {'layer': 6, 'head': 7, 'score': 0.0032255053520202637},\n",
       "   {'layer': 6, 'head': 8, 'score': 0.00016784854233264923},\n",
       "   {'layer': 6, 'head': 9, 'score': 0.0034643709659576416},\n",
       "   {'layer': 6, 'head': 10, 'score': 0.00015414319932460785},\n",
       "   {'layer': 6, 'head': 11, 'score': 0.000368267297744751},\n",
       "   {'layer': 6, 'head': 12, 'score': 0.0005832388997077942},\n",
       "   {'layer': 6, 'head': 13, 'score': 0.00026174262166023254},\n",
       "   {'layer': 6, 'head': 14, 'score': 0.0033141374588012695},\n",
       "   {'layer': 6, 'head': 15, 'score': 0.00039372220635414124},\n",
       "   {'layer': 6, 'head': 16, 'score': 0.0002866927534341812},\n",
       "   {'layer': 6, 'head': 17, 'score': 0.005685031414031982},\n",
       "   {'layer': 6, 'head': 18, 'score': 0.0011844635009765625},\n",
       "   {'layer': 6, 'head': 19, 'score': 0.0006823241710662842},\n",
       "   {'layer': 6, 'head': 20, 'score': 0.007182180881500244},\n",
       "   {'layer': 6, 'head': 21, 'score': 0.007233858108520508},\n",
       "   {'layer': 6, 'head': 22, 'score': 0.010957837104797363},\n",
       "   {'layer': 6, 'head': 23, 'score': 0.00209181010723114},\n",
       "   {'layer': 6, 'head': 24, 'score': 0.01113581657409668},\n",
       "   {'layer': 6, 'head': 25, 'score': 0.014973878860473633},\n",
       "   {'layer': 6, 'head': 26, 'score': 0.012030839920043945},\n",
       "   {'layer': 6, 'head': 27, 'score': 0.01636195182800293},\n",
       "   {'layer': 6, 'head': 28, 'score': 0.02301478385925293},\n",
       "   {'layer': 6, 'head': 29, 'score': 0.02539372444152832},\n",
       "   {'layer': 6, 'head': 30, 'score': 0.0003818795084953308},\n",
       "   {'layer': 6, 'head': 31, 'score': 0.14146995544433594},\n",
       "   {'layer': 7, 'head': 0, 'score': 0.0003318954259157181},\n",
       "   {'layer': 7, 'head': 1, 'score': 0.0001958981156349182},\n",
       "   {'layer': 7, 'head': 2, 'score': 0.00035502389073371887},\n",
       "   {'layer': 7, 'head': 3, 'score': 0.011603593826293945},\n",
       "   {'layer': 7, 'head': 4, 'score': 0.001461029052734375},\n",
       "   {'layer': 7, 'head': 5, 'score': 7.336627459153533e-05},\n",
       "   {'layer': 7, 'head': 6, 'score': 0.007306873798370361},\n",
       "   {'layer': 7, 'head': 7, 'score': 0.007454633712768555},\n",
       "   {'layer': 7, 'head': 8, 'score': 0.002338618040084839},\n",
       "   {'layer': 7, 'head': 9, 'score': 0.0038338303565979004},\n",
       "   {'layer': 7, 'head': 10, 'score': 0.0031603574752807617},\n",
       "   {'layer': 7, 'head': 11, 'score': 0.0019222348928451538},\n",
       "   {'layer': 7, 'head': 12, 'score': 0.0019011497497558594},\n",
       "   {'layer': 7, 'head': 13, 'score': 0.00468522310256958},\n",
       "   {'layer': 7, 'head': 14, 'score': 0.0034096837043762207},\n",
       "   {'layer': 7, 'head': 15, 'score': 0.004228949546813965},\n",
       "   {'layer': 7, 'head': 16, 'score': 0.005521237850189209},\n",
       "   {'layer': 7, 'head': 17, 'score': 0.007024288177490234},\n",
       "   {'layer': 7, 'head': 18, 'score': 0.0057141780853271484},\n",
       "   {'layer': 7, 'head': 19, 'score': 0.005247175693511963},\n",
       "   {'layer': 7, 'head': 20, 'score': 0.00359991192817688},\n",
       "   {'layer': 7, 'head': 21, 'score': 0.008772134780883789},\n",
       "   {'layer': 7, 'head': 22, 'score': 0.007380545139312744},\n",
       "   {'layer': 7, 'head': 23, 'score': 0.021292448043823242},\n",
       "   {'layer': 7, 'head': 24, 'score': 0.0199887752532959},\n",
       "   {'layer': 7, 'head': 25, 'score': 0.00530010461807251},\n",
       "   {'layer': 7, 'head': 26, 'score': 0.007009923458099365},\n",
       "   {'layer': 7, 'head': 27, 'score': 0.001787632703781128},\n",
       "   {'layer': 7, 'head': 28, 'score': 0.002818495035171509},\n",
       "   {'layer': 7, 'head': 29, 'score': 0.0033216476440429688},\n",
       "   {'layer': 7, 'head': 30, 'score': 0.005456030368804932},\n",
       "   {'layer': 7, 'head': 31, 'score': 0.00325128436088562},\n",
       "   {'layer': 8, 'head': 0, 'score': 0.09600448608398438},\n",
       "   {'layer': 8, 'head': 2, 'score': 0.008002758026123047},\n",
       "   {'layer': 8, 'head': 3, 'score': 0.05248737335205078},\n",
       "   {'layer': 8, 'head': 4, 'score': 0.0012949258089065552},\n",
       "   {'layer': 8, 'head': 5, 'score': 0.005047619342803955},\n",
       "   {'layer': 8, 'head': 6, 'score': 0.001956269145011902},\n",
       "   {'layer': 8, 'head': 7, 'score': 0.0046425461769104},\n",
       "   {'layer': 8, 'head': 8, 'score': 0.008896946907043457},\n",
       "   {'layer': 8, 'head': 9, 'score': 0.03629016876220703},\n",
       "   {'layer': 8, 'head': 10, 'score': 0.002746760845184326},\n",
       "   {'layer': 8, 'head': 11, 'score': 0.018218994140625},\n",
       "   {'layer': 8, 'head': 12, 'score': 0.001106366515159607},\n",
       "   {'layer': 8, 'head': 13, 'score': 0.002424955368041992},\n",
       "   {'layer': 8, 'head': 14, 'score': 0.0015578866004943848},\n",
       "   {'layer': 8, 'head': 15, 'score': 0.0017648041248321533},\n",
       "   {'layer': 8, 'head': 16, 'score': 0.01067495346069336},\n",
       "   {'layer': 8, 'head': 17, 'score': 0.004087716341018677},\n",
       "   {'layer': 8, 'head': 18, 'score': 0.004140257835388184},\n",
       "   {'layer': 8, 'head': 19, 'score': 0.010856866836547852},\n",
       "   {'layer': 8, 'head': 20, 'score': 0.0024068355560302734},\n",
       "   {'layer': 8, 'head': 21, 'score': 0.0018393993377685547},\n",
       "   {'layer': 8, 'head': 22, 'score': 0.0006301775574684143},\n",
       "   {'layer': 8, 'head': 23, 'score': 0.0023981332778930664},\n",
       "   {'layer': 8, 'head': 24, 'score': 0.00961315631866455},\n",
       "   {'layer': 8, 'head': 25, 'score': 0.012511610984802246},\n",
       "   {'layer': 8, 'head': 26, 'score': 0.004600107669830322},\n",
       "   {'layer': 8, 'head': 27, 'score': 0.0033613741397857666},\n",
       "   {'layer': 8, 'head': 28, 'score': 0.0036465227603912354},\n",
       "   {'layer': 8, 'head': 29, 'score': 0.005264997482299805},\n",
       "   {'layer': 8, 'head': 30, 'score': 0.006245732307434082},\n",
       "   {'layer': 8, 'head': 31, 'score': 0.010967612266540527},\n",
       "   {'layer': 9, 'head': 0, 'score': 0.010255932807922363},\n",
       "   {'layer': 9, 'head': 1, 'score': 0.008772850036621094},\n",
       "   {'layer': 9, 'head': 2, 'score': 0.01717686653137207},\n",
       "   {'layer': 9, 'head': 3, 'score': 0.011189699172973633},\n",
       "   {'layer': 9, 'head': 4, 'score': 0.0062177181243896484},\n",
       "   {'layer': 9, 'head': 5, 'score': 0.0021905899047851562},\n",
       "   {'layer': 9, 'head': 6, 'score': 0.004320383071899414},\n",
       "   {'layer': 9, 'head': 7, 'score': 0.0015306025743484497},\n",
       "   {'layer': 9, 'head': 8, 'score': 0.0009698420763015747},\n",
       "   {'layer': 9, 'head': 9, 'score': 0.0012390762567520142},\n",
       "   {'layer': 9, 'head': 10, 'score': 0.000959545373916626},\n",
       "   {'layer': 9, 'head': 11, 'score': 9.735347703099251e-05},\n",
       "   {'layer': 9, 'head': 12, 'score': 0.032643795013427734},\n",
       "   {'layer': 9, 'head': 13, 'score': 0.036052703857421875},\n",
       "   {'layer': 9, 'head': 14, 'score': 0.009528398513793945},\n",
       "   {'layer': 9, 'head': 15, 'score': 0.005608797073364258},\n",
       "   {'layer': 9, 'head': 16, 'score': 0.0055890679359436035},\n",
       "   {'layer': 9, 'head': 17, 'score': 0.004892230033874512},\n",
       "   {'layer': 9, 'head': 18, 'score': 0.00694805383682251},\n",
       "   {'layer': 9, 'head': 19, 'score': 0.006093740463256836},\n",
       "   {'layer': 9, 'head': 20, 'score': 0.021619319915771484},\n",
       "   {'layer': 9, 'head': 21, 'score': 0.0030989348888397217},\n",
       "   {'layer': 9, 'head': 22, 'score': 0.008476614952087402},\n",
       "   {'layer': 9, 'head': 23, 'score': 0.0026130080223083496},\n",
       "   {'layer': 9, 'head': 24, 'score': 0.00286257266998291},\n",
       "   {'layer': 9, 'head': 25, 'score': 0.01656949520111084},\n",
       "   {'layer': 9, 'head': 26, 'score': 0.0015527904033660889},\n",
       "   {'layer': 9, 'head': 27, 'score': 0.15631866455078125},\n",
       "   {'layer': 9, 'head': 28, 'score': 0.02317070960998535},\n",
       "   {'layer': 9, 'head': 29, 'score': 0.018871784210205078},\n",
       "   {'layer': 9, 'head': 30, 'score': 0.003049910068511963},\n",
       "   {'layer': 9, 'head': 31, 'score': 0.11959266662597656},\n",
       "   {'layer': 10, 'head': 0, 'score': 0.005898714065551758},\n",
       "   {'layer': 10, 'head': 1, 'score': 0.016865968704223633},\n",
       "   {'layer': 10, 'head': 2, 'score': 0.0029581189155578613},\n",
       "   {'layer': 10, 'head': 3, 'score': 0.025792837142944336},\n",
       "   {'layer': 10, 'head': 4, 'score': 0.0037142932415008545},\n",
       "   {'layer': 10, 'head': 5, 'score': 0.02458643913269043},\n",
       "   {'layer': 10, 'head': 6, 'score': 0.009508252143859863},\n",
       "   {'layer': 10, 'head': 7, 'score': 0.012740731239318848},\n",
       "   {'layer': 10, 'head': 8, 'score': 0.003542274236679077},\n",
       "   {'layer': 10, 'head': 9, 'score': 0.002964913845062256},\n",
       "   {'layer': 10, 'head': 10, 'score': 0.003299415111541748},\n",
       "   {'layer': 10, 'head': 11, 'score': 0.001055493950843811},\n",
       "   {'layer': 10, 'head': 12, 'score': 0.06698179244995117},\n",
       "   {'layer': 10, 'head': 13, 'score': 0.2827873229980469},\n",
       "   {'layer': 10, 'head': 15, 'score': 0.009138226509094238},\n",
       "   {'layer': 10, 'head': 16, 'score': 0.0022204816341400146},\n",
       "   {'layer': 10, 'head': 17, 'score': 0.008969902992248535},\n",
       "   {'layer': 10, 'head': 18, 'score': 0.02584385871887207},\n",
       "   {'layer': 10, 'head': 19, 'score': 0.012923598289489746},\n",
       "   {'layer': 10, 'head': 20, 'score': 0.004476428031921387},\n",
       "   {'layer': 10, 'head': 21, 'score': 0.003046661615371704},\n",
       "   {'layer': 10, 'head': 22, 'score': 0.004280030727386475},\n",
       "   {'layer': 10, 'head': 23, 'score': 0.0018892735242843628},\n",
       "   {'layer': 10, 'head': 24, 'score': 0.0059986114501953125},\n",
       "   {'layer': 10, 'head': 25, 'score': 0.00788193941116333},\n",
       "   {'layer': 10, 'head': 26, 'score': 0.003933370113372803},\n",
       "   {'layer': 10, 'head': 27, 'score': 0.0110548734664917},\n",
       "   {'layer': 10, 'head': 28, 'score': 0.011041641235351562},\n",
       "   {'layer': 10, 'head': 29, 'score': 0.024181127548217773},\n",
       "   {'layer': 10, 'head': 30, 'score': 0.0020342618227005005},\n",
       "   {'layer': 10, 'head': 31, 'score': 0.014281511306762695},\n",
       "   {'layer': 11, 'head': 0, 'score': 0.004343152046203613},\n",
       "   {'layer': 11, 'head': 1, 'score': 0.006942451000213623},\n",
       "   {'layer': 11, 'head': 2, 'score': 0.008610248565673828},\n",
       "   {'layer': 11, 'head': 3, 'score': 0.0077391862869262695},\n",
       "   {'layer': 11, 'head': 4, 'score': 0.010100603103637695},\n",
       "   {'layer': 11, 'head': 5, 'score': 0.08565807342529297},\n",
       "   {'layer': 11, 'head': 6, 'score': 0.030494213104248047},\n",
       "   {'layer': 11, 'head': 7, 'score': 0.01968526840209961},\n",
       "   {'layer': 11, 'head': 8, 'score': 0.0023980438709259033},\n",
       "   {'layer': 11, 'head': 9, 'score': 0.005248963832855225},\n",
       "   {'layer': 11, 'head': 10, 'score': 0.0025724470615386963},\n",
       "   {'layer': 11, 'head': 11, 'score': 0.0027955472469329834},\n",
       "   {'layer': 11, 'head': 12, 'score': 0.01822519302368164},\n",
       "   {'layer': 11, 'head': 13, 'score': 0.006133675575256348},\n",
       "   {'layer': 11, 'head': 14, 'score': 0.004915416240692139},\n",
       "   {'layer': 11, 'head': 15, 'score': 0.013466238975524902},\n",
       "   {'layer': 11, 'head': 16, 'score': 0.0005620718002319336},\n",
       "   {'layer': 11, 'head': 17, 'score': 0.000527944415807724},\n",
       "   {'layer': 11, 'head': 18, 'score': 0.004206061363220215},\n",
       "   {'layer': 11, 'head': 19, 'score': 0.001990094780921936},\n",
       "   {'layer': 11, 'head': 20, 'score': 0.00460439920425415},\n",
       "   {'layer': 11, 'head': 21, 'score': 0.017628908157348633},\n",
       "   {'layer': 11, 'head': 22, 'score': 0.015929341316223145},\n",
       "   {'layer': 11, 'head': 23, 'score': 0.020647048950195312},\n",
       "   {'layer': 11, 'head': 24, 'score': 0.004546642303466797},\n",
       "   {'layer': 11, 'head': 25, 'score': 0.005373179912567139},\n",
       "   {'layer': 11, 'head': 26, 'score': 0.005438268184661865},\n",
       "   {'layer': 11, 'head': 27, 'score': 0.002866029739379883},\n",
       "   {'layer': 11, 'head': 28, 'score': 0.011205673217773438},\n",
       "   {'layer': 11, 'head': 29, 'score': 0.0034222304821014404},\n",
       "   {'layer': 11, 'head': 30, 'score': 0.007053077220916748},\n",
       "   {'layer': 11, 'head': 31, 'score': 0.0006240606307983398},\n",
       "   {'layer': 12, 'head': 0, 'score': 0.0018602758646011353},\n",
       "   {'layer': 12, 'head': 1, 'score': 0.013990163803100586},\n",
       "   {'layer': 12, 'head': 2, 'score': 0.0030045807361602783},\n",
       "   {'layer': 12, 'head': 3, 'score': 0.0023908019065856934},\n",
       "   {'layer': 12, 'head': 4, 'score': 0.006051540374755859},\n",
       "   {'layer': 12, 'head': 5, 'score': 0.0035623013973236084},\n",
       "   {'layer': 12, 'head': 6, 'score': 0.006172060966491699},\n",
       "   {'layer': 12, 'head': 7, 'score': 0.0021810531616210938},\n",
       "   {'layer': 12, 'head': 8, 'score': 0.007690846920013428},\n",
       "   {'layer': 12, 'head': 9, 'score': 0.006041884422302246},\n",
       "   {'layer': 12, 'head': 10, 'score': 0.011162161827087402},\n",
       "   {'layer': 12, 'head': 11, 'score': 0.012695550918579102},\n",
       "   {'layer': 12, 'head': 12, 'score': 3.157230094075203e-05},\n",
       "   {'layer': 12, 'head': 13, 'score': 0.0016585439443588257},\n",
       "   {'layer': 12, 'head': 14, 'score': 0.013971805572509766},\n",
       "   {'layer': 12, 'head': 15, 'score': 0.0034238994121551514},\n",
       "   {'layer': 12, 'head': 16, 'score': 0.0010573193430900574},\n",
       "   {'layer': 12, 'head': 17, 'score': 0.0033609867095947266},\n",
       "   {'layer': 12, 'head': 18, 'score': 0.0019893497228622437},\n",
       "   {'layer': 12, 'head': 19, 'score': 0.0006223395466804504},\n",
       "   {'layer': 12, 'head': 20, 'score': 0.005471169948577881},\n",
       "   {'layer': 12, 'head': 21, 'score': 0.0029046237468719482},\n",
       "   {'layer': 12, 'head': 22, 'score': 0.005106449127197266},\n",
       "   {'layer': 12, 'head': 23, 'score': 0.005754292011260986},\n",
       "   {'layer': 12, 'head': 24, 'score': 0.002756834030151367},\n",
       "   {'layer': 12, 'head': 25, 'score': 0.0030871033668518066},\n",
       "   {'layer': 12, 'head': 26, 'score': 0.0020675957202911377},\n",
       "   {'layer': 12, 'head': 27, 'score': 0.0030162036418914795},\n",
       "   {'layer': 12, 'head': 28, 'score': 0.005457103252410889},\n",
       "   {'layer': 12, 'head': 29, 'score': 0.004360079765319824},\n",
       "   {'layer': 12, 'head': 30, 'score': 0.004849791526794434},\n",
       "   {'layer': 12, 'head': 31, 'score': 0.007726430892944336},\n",
       "   {'layer': 13, 'head': 0, 'score': 0.019732236862182617},\n",
       "   {'layer': 13, 'head': 1, 'score': 0.022212743759155273},\n",
       "   {'layer': 13, 'head': 2, 'score': 0.024118900299072266},\n",
       "   {'layer': 13, 'head': 3, 'score': 0.023547887802124023},\n",
       "   {'layer': 13, 'head': 4, 'score': 0.1585540771484375},\n",
       "   {'layer': 13, 'head': 5, 'score': 0.0601506233215332},\n",
       "   {'layer': 13, 'head': 6, 'score': 0.34462738037109375},\n",
       "   {'layer': 13, 'head': 7, 'score': 0.0037299692630767822},\n",
       "   {'layer': 13, 'head': 8, 'score': 0.05561542510986328},\n",
       "   {'layer': 13, 'head': 9, 'score': 0.01952075958251953},\n",
       "   {'layer': 13, 'head': 10, 'score': 0.013364672660827637},\n",
       "   {'layer': 13, 'head': 11, 'score': 0.018924713134765625},\n",
       "   {'layer': 13, 'head': 12, 'score': 0.010988116264343262},\n",
       "   {'layer': 13, 'head': 13, 'score': 0.04751443862915039},\n",
       "   {'layer': 13, 'head': 14, 'score': 0.008849501609802246},\n",
       "   {'layer': 13, 'head': 15, 'score': 0.006269574165344238},\n",
       "   {'layer': 13, 'head': 16, 'score': 0.0460972785949707},\n",
       "   {'layer': 13, 'head': 17, 'score': 0.08600234985351562},\n",
       "   {'layer': 13, 'head': 18, 'score': 0.1688976287841797},\n",
       "   {'layer': 13, 'head': 19, 'score': 0.011560440063476562},\n",
       "   {'layer': 13, 'head': 20, 'score': 0.013762831687927246},\n",
       "   {'layer': 13, 'head': 21, 'score': 0.019974946975708008},\n",
       "   {'layer': 13, 'head': 22, 'score': 0.0029287338256835938},\n",
       "   {'layer': 13, 'head': 23, 'score': 0.0056092143058776855},\n",
       "   {'layer': 13, 'head': 24, 'score': 0.0022783875465393066},\n",
       "   {'layer': 13, 'head': 25, 'score': 0.00983583927154541},\n",
       "   {'layer': 13, 'head': 26, 'score': 0.03839921951293945},\n",
       "   {'layer': 13, 'head': 27, 'score': 0.14379119873046875},\n",
       "   {'layer': 13, 'head': 28, 'score': 0.006418824195861816},\n",
       "   {'layer': 13, 'head': 29, 'score': 0.002306342124938965},\n",
       "   {'layer': 13, 'head': 30, 'score': 0.011354923248291016},\n",
       "   {'layer': 13, 'head': 31, 'score': 0.0121307373046875},\n",
       "   {'layer': 14, 'head': 0, 'score': 0.010957002639770508},\n",
       "   {'layer': 14, 'head': 1, 'score': 0.013270258903503418},\n",
       "   {'layer': 14, 'head': 2, 'score': 0.013355255126953125},\n",
       "   {'layer': 14, 'head': 3, 'score': 0.018725872039794922},\n",
       "   {'layer': 14, 'head': 4, 'score': 0.017594575881958008},\n",
       "   {'layer': 14, 'head': 5, 'score': 0.02471923828125},\n",
       "   {'layer': 14, 'head': 6, 'score': 0.006451725959777832},\n",
       "   {'layer': 14, 'head': 7, 'score': 0.008993744850158691},\n",
       "   {'layer': 14, 'head': 8, 'score': 0.000645078718662262},\n",
       "   {'layer': 14, 'head': 9, 'score': 0.001286432147026062},\n",
       "   {'layer': 14, 'head': 10, 'score': 0.001829683780670166},\n",
       "   {'layer': 14, 'head': 11, 'score': 0.0016338825225830078},\n",
       "   {'layer': 14, 'head': 12, 'score': 0.025093793869018555},\n",
       "   {'layer': 14, 'head': 13, 'score': 0.13360214233398438},\n",
       "   {'layer': 14, 'head': 14, 'score': 0.02489161491394043},\n",
       "   {'layer': 14, 'head': 15, 'score': 0.007409930229187012},\n",
       "   {'layer': 14, 'head': 16, 'score': 0.02456808090209961},\n",
       "   {'layer': 14, 'head': 17, 'score': 0.005529344081878662},\n",
       "   {'layer': 14, 'head': 18, 'score': 0.07637500762939453},\n",
       "   {'layer': 14, 'head': 19, 'score': 0.0009709447622299194},\n",
       "   {'layer': 14, 'head': 20, 'score': 0.142669677734375},\n",
       "   {'layer': 14, 'head': 21, 'score': 0.021915197372436523},\n",
       "   {'layer': 14, 'head': 22, 'score': 0.13854598999023438},\n",
       "   {'layer': 14, 'head': 23, 'score': 0.026110410690307617},\n",
       "   {'layer': 14, 'head': 24, 'score': 0.020902156829833984},\n",
       "   {'layer': 14, 'head': 25, 'score': 0.012700915336608887},\n",
       "   {'layer': 14, 'head': 26, 'score': 2.4798966478556395e-05},\n",
       "   {'layer': 14, 'head': 27, 'score': 0.013460040092468262},\n",
       "   {'layer': 14, 'head': 28, 'score': 0.0349578857421875},\n",
       "   {'layer': 14, 'head': 29, 'score': 0.10445594787597656},\n",
       "   {'layer': 14, 'head': 30, 'score': 0.06227254867553711},\n",
       "   {'layer': 14, 'head': 31, 'score': 0.08664608001708984},\n",
       "   {'layer': 15, 'head': 0, 'score': 0.0009916499257087708},\n",
       "   {'layer': 15, 'head': 2, 'score': 0.09985828399658203},\n",
       "   {'layer': 15, 'head': 3, 'score': 0.10583209991455078},\n",
       "   {'layer': 15, 'head': 4, 'score': 0.006044924259185791},\n",
       "   {'layer': 15, 'head': 5, 'score': 0.012433409690856934},\n",
       "   {'layer': 15, 'head': 6, 'score': 0.00404694676399231},\n",
       "   {'layer': 15, 'head': 7, 'score': 0.001387074589729309},\n",
       "   {'layer': 15, 'head': 8, 'score': 0.006627440452575684},\n",
       "   {'layer': 15, 'head': 9, 'score': 0.004677236080169678},\n",
       "   {'layer': 15, 'head': 10, 'score': 0.016525983810424805},\n",
       "   {'layer': 15, 'head': 11, 'score': 0.03541231155395508},\n",
       "   {'layer': 15, 'head': 12, 'score': 0.0008899867534637451},\n",
       "   {'layer': 15, 'head': 13, 'score': 0.027476072311401367},\n",
       "   {'layer': 15, 'head': 14, 'score': 0.04056978225708008},\n",
       "   {'layer': 15, 'head': 15, 'score': 0.00837254524230957},\n",
       "   {'layer': 15, 'head': 16, 'score': 0.010782599449157715},\n",
       "   {'layer': 15, 'head': 17, 'score': 0.011744856834411621},\n",
       "   {'layer': 15, 'head': 18, 'score': 0.01697230339050293},\n",
       "   {'layer': 15, 'head': 19, 'score': 0.0014803707599639893},\n",
       "   {'layer': 15, 'head': 20, 'score': 0.014418601989746094},\n",
       "   {'layer': 15, 'head': 21, 'score': 0.049602508544921875},\n",
       "   {'layer': 15, 'head': 22, 'score': 0.010382413864135742},\n",
       "   {'layer': 15, 'head': 23, 'score': 0.010888457298278809},\n",
       "   {'layer': 15, 'head': 24, 'score': 0.01151132583618164},\n",
       "   {'layer': 15, 'head': 25, 'score': 0.012918472290039062},\n",
       "   {'layer': 15, 'head': 26, 'score': 0.026479721069335938},\n",
       "   {'layer': 15, 'head': 27, 'score': 0.007972776889801025},\n",
       "   {'layer': 15, 'head': 28, 'score': 0.14942359924316406},\n",
       "   {'layer': 15, 'head': 29, 'score': 0.1290283203125},\n",
       "   {'layer': 15, 'head': 31, 'score': 0.0018215775489807129},\n",
       "   {'layer': 16, 'head': 0, 'score': 0.08108234405517578},\n",
       "   {'layer': 16, 'head': 1, 'score': 0.34420013427734375},\n",
       "   {'layer': 16, 'head': 2, 'score': 0.08387374877929688},\n",
       "   {'layer': 16, 'head': 3, 'score': 0.04665422439575195},\n",
       "   {'layer': 16, 'head': 4, 'score': 0.002856522798538208},\n",
       "   {'layer': 16, 'head': 5, 'score': 0.016411423683166504},\n",
       "   {'layer': 16, 'head': 6, 'score': 0.002052709460258484},\n",
       "   {'layer': 16, 'head': 7, 'score': 0.004316985607147217},\n",
       "   {'layer': 16, 'head': 8, 'score': 0.10817813873291016},\n",
       "   {'layer': 16, 'head': 9, 'score': 0.021770477294921875},\n",
       "   {'layer': 16, 'head': 10, 'score': 0.020449399948120117},\n",
       "   {'layer': 16, 'head': 11, 'score': 0.009491324424743652},\n",
       "   {'layer': 16, 'head': 12, 'score': 0.0009135231375694275},\n",
       "   {'layer': 16, 'head': 13, 'score': 0.0041915178298950195},\n",
       "   {'layer': 16, 'head': 14, 'score': 0.002205461263656616},\n",
       "   {'layer': 16, 'head': 15, 'score': 0.002184748649597168},\n",
       "   {'layer': 16, 'head': 16, 'score': 0.005350589752197266},\n",
       "   {'layer': 16, 'head': 17, 'score': 0.006399929523468018},\n",
       "   {'layer': 16, 'head': 18, 'score': 0.022480487823486328},\n",
       "   {'layer': 16, 'head': 19, 'score': 0.15435791015625},\n",
       "   {'layer': 16, 'head': 21, 'score': 0.054355621337890625},\n",
       "   {'layer': 16, 'head': 22, 'score': 0.0022246092557907104},\n",
       "   {'layer': 16, 'head': 23, 'score': 0.1742076873779297},\n",
       "   {'layer': 16, 'head': 24, 'score': 0.016875267028808594},\n",
       "   {'layer': 16, 'head': 25, 'score': 0.11979389190673828},\n",
       "   {'layer': 16, 'head': 26, 'score': 0.03902006149291992},\n",
       "   {'layer': 16, 'head': 27, 'score': 0.028381824493408203},\n",
       "   {'layer': 16, 'head': 28, 'score': 0.0016205906867980957},\n",
       "   {'layer': 16, 'head': 29, 'score': 0.00016939174383878708},\n",
       "   {'layer': 16, 'head': 30, 'score': 0.0023636221885681152},\n",
       "   {'layer': 16, 'head': 31, 'score': 0.0019370615482330322},\n",
       "   {'layer': 17, 'head': 0, 'score': 0.010235428810119629},\n",
       "   {'layer': 17, 'head': 1, 'score': 0.0039886534214019775},\n",
       "   {'layer': 17, 'head': 2, 'score': 0.011957049369812012},\n",
       "   {'layer': 17, 'head': 3, 'score': 0.01508796215057373},\n",
       "   {'layer': 17, 'head': 4, 'score': 0.005185306072235107},\n",
       "   {'layer': 17, 'head': 5, 'score': 0.003308594226837158},\n",
       "   {'layer': 17, 'head': 6, 'score': 0.012433409690856934},\n",
       "   {'layer': 17, 'head': 7, 'score': 0.003350198268890381},\n",
       "   {'layer': 17, 'head': 8, 'score': 0.018340349197387695},\n",
       "   {'layer': 17, 'head': 9, 'score': 0.0070076584815979},\n",
       "   {'layer': 17, 'head': 10, 'score': 0.00524294376373291},\n",
       "   {'layer': 17, 'head': 11, 'score': 0.0011162906885147095},\n",
       "   {'layer': 17, 'head': 12, 'score': 0.00460362434387207},\n",
       "   {'layer': 17, 'head': 13, 'score': 0.0031398534774780273},\n",
       "   {'layer': 17, 'head': 14, 'score': 0.004010587930679321},\n",
       "   {'layer': 17, 'head': 15, 'score': 0.0034820735454559326},\n",
       "   {'layer': 17, 'head': 16, 'score': 0.0033501386642456055},\n",
       "   {'layer': 17, 'head': 17, 'score': 0.0013588517904281616},\n",
       "   {'layer': 17, 'head': 18, 'score': 0.005814552307128906},\n",
       "   {'layer': 17, 'head': 19, 'score': 0.004707992076873779},\n",
       "   {'layer': 17, 'head': 20, 'score': 0.0011680126190185547},\n",
       "   {'layer': 17, 'head': 21, 'score': 0.11443138122558594},\n",
       "   {'layer': 17, 'head': 22, 'score': 0.009565234184265137},\n",
       "   {'layer': 17, 'head': 23, 'score': 0.07453727722167969},\n",
       "   {'layer': 17, 'head': 24, 'score': 0.14464950561523438},\n",
       "   {'layer': 17, 'head': 25, 'score': 0.08355140686035156},\n",
       "   {'layer': 17, 'head': 26, 'score': 0.11264705657958984},\n",
       "   {'layer': 17, 'head': 27, 'score': 0.10984039306640625},\n",
       "   {'layer': 17, 'head': 28, 'score': 0.03459453582763672},\n",
       "   {'layer': 17, 'head': 29, 'score': 0.12208938598632812},\n",
       "   {'layer': 17, 'head': 30, 'score': 0.0013572871685028076},\n",
       "   {'layer': 17, 'head': 31, 'score': 0.06943893432617188},\n",
       "   {'layer': 18, 'head': 0, 'score': 0.0089874267578125},\n",
       "   {'layer': 18, 'head': 1, 'score': 0.0022244155406951904},\n",
       "   {'layer': 18, 'head': 2, 'score': 0.013051509857177734},\n",
       "   {'layer': 18, 'head': 3, 'score': 0.0019554048776626587},\n",
       "   {'layer': 18, 'head': 4, 'score': 0.025284290313720703},\n",
       "   {'layer': 18, 'head': 5, 'score': 0.023639440536499023},\n",
       "   {'layer': 18, 'head': 6, 'score': 0.0023546814918518066},\n",
       "   {'layer': 18, 'head': 7, 'score': 0.0006335712969303131},\n",
       "   {'layer': 18, 'head': 8, 'score': 0.05719327926635742},\n",
       "   {'layer': 18, 'head': 9, 'score': 0.03505849838256836},\n",
       "   {'layer': 18, 'head': 10, 'score': 0.0013447850942611694},\n",
       "   {'layer': 18, 'head': 11, 'score': 0.004507958889007568},\n",
       "   {'layer': 18, 'head': 12, 'score': 0.002424091100692749},\n",
       "   {'layer': 18, 'head': 13, 'score': 0.0009180903434753418},\n",
       "   {'layer': 18, 'head': 14, 'score': 0.006650269031524658},\n",
       "   {'layer': 18, 'head': 15, 'score': 0.0012952983379364014},\n",
       "   {'layer': 18, 'head': 16, 'score': 0.03796577453613281},\n",
       "   {'layer': 18, 'head': 17, 'score': 0.0011314749717712402},\n",
       "   {'layer': 18, 'head': 18, 'score': 0.012500524520874023},\n",
       "   {'layer': 18, 'head': 19, 'score': 0.005665779113769531},\n",
       "   {'layer': 18, 'head': 20, 'score': 0.0477752685546875},\n",
       "   {'layer': 18, 'head': 21, 'score': 0.00725787878036499},\n",
       "   {'layer': 18, 'head': 22, 'score': 0.053540706634521484},\n",
       "   {'layer': 18, 'head': 23, 'score': 0.022668123245239258},\n",
       "   {'layer': 18, 'head': 24, 'score': 0.003542482852935791},\n",
       "   {'layer': 18, 'head': 25, 'score': 0.0005499757826328278},\n",
       "   {'layer': 18, 'head': 26, 'score': 0.00039687380194664},\n",
       "   {'layer': 18, 'head': 27, 'score': 0.0012238174676895142},\n",
       "   {'layer': 18, 'head': 28, 'score': 0.05323600769042969},\n",
       "   {'layer': 18, 'head': 29, 'score': 0.030111312866210938},\n",
       "   {'layer': 18, 'head': 30, 'score': 0.022946834564208984},\n",
       "   {'layer': 18, 'head': 31, 'score': 0.002277284860610962},\n",
       "   {'layer': 19, 'head': 0, 'score': 0.15135574340820312},\n",
       "   {'layer': 19, 'head': 1, 'score': 0.032495737075805664},\n",
       "   {'layer': 19, 'head': 2, 'score': 0.09119129180908203},\n",
       "   {'layer': 19, 'head': 4, 'score': 0.006082773208618164},\n",
       "   {'layer': 19, 'head': 5, 'score': 0.0013625025749206543},\n",
       "   {'layer': 19, 'head': 6, 'score': 0.0033144354820251465},\n",
       "   {'layer': 19, 'head': 7, 'score': 0.0009982138872146606},\n",
       "   {'layer': 19, 'head': 8, 'score': 0.0030942559242248535},\n",
       "   {'layer': 19, 'head': 9, 'score': 0.04516172409057617},\n",
       "   {'layer': 19, 'head': 10, 'score': 0.002106994390487671},\n",
       "   {'layer': 19, 'head': 11, 'score': 0.004834890365600586},\n",
       "   {'layer': 19, 'head': 12, 'score': 0.029271602630615234},\n",
       "   {'layer': 19, 'head': 13, 'score': 0.06836223602294922},\n",
       "   {'layer': 19, 'head': 14, 'score': 0.04942178726196289},\n",
       "   {'layer': 19, 'head': 15, 'score': 0.021956920623779297},\n",
       "   {'layer': 19, 'head': 16, 'score': 0.004001617431640625},\n",
       "   {'layer': 19, 'head': 17, 'score': 0.0016954094171524048},\n",
       "   {'layer': 19, 'head': 18, 'score': 0.0018076300621032715},\n",
       "   {'layer': 19, 'head': 19, 'score': 0.002877563238143921},\n",
       "   {'layer': 19, 'head': 20, 'score': 0.003561466932296753},\n",
       "   {'layer': 19, 'head': 21, 'score': 0.007271230220794678},\n",
       "   {'layer': 19, 'head': 22, 'score': 0.004290968179702759},\n",
       "   {'layer': 19, 'head': 23, 'score': 0.04871511459350586},\n",
       "   {'layer': 19, 'head': 24, 'score': 0.001054033637046814},\n",
       "   {'layer': 19, 'head': 25, 'score': 0.011893630027770996},\n",
       "   {'layer': 19, 'head': 26, 'score': 0.0003740042448043823},\n",
       "   {'layer': 19, 'head': 27, 'score': 0.01210486888885498},\n",
       "   {'layer': 19, 'head': 28, 'score': 0.0013623982667922974},\n",
       "   {'layer': 19, 'head': 29, 'score': 0.0012933313846588135},\n",
       "   {'layer': 19, 'head': 30, 'score': 0.004225492477416992},\n",
       "   {'layer': 19, 'head': 31, 'score': 0.0009846091270446777},\n",
       "   {'layer': 20, 'head': 0, 'score': 0.04309415817260742},\n",
       "   {'layer': 20, 'head': 2, 'score': 0.026110410690307617},\n",
       "   {'layer': 20, 'head': 3, 'score': 0.02140355110168457},\n",
       "   {'layer': 20, 'head': 4, 'score': 0.0009972453117370605},\n",
       "   {'layer': 20, 'head': 5, 'score': 0.0012193024158477783},\n",
       "   {'layer': 20, 'head': 6, 'score': 0.0008734911680221558},\n",
       "   {'layer': 20, 'head': 7, 'score': 0.000542372465133667},\n",
       "   {'layer': 20, 'head': 8, 'score': 0.002783268690109253},\n",
       "   {'layer': 20, 'head': 9, 'score': 0.06640768051147461},\n",
       "   {'layer': 20, 'head': 10, 'score': 0.019162654876708984},\n",
       "   {'layer': 20, 'head': 11, 'score': 0.007900476455688477},\n",
       "   {'layer': 20, 'head': 12, 'score': 0.004265159368515015},\n",
       "   {'layer': 20, 'head': 13, 'score': 0.24176597595214844},\n",
       "   {'layer': 20, 'head': 15, 'score': 0.1547069549560547},\n",
       "   {'layer': 20, 'head': 16, 'score': 0.003658384084701538},\n",
       "   {'layer': 20, 'head': 17, 'score': 0.0019767284393310547},\n",
       "   {'layer': 20, 'head': 18, 'score': 0.0018579661846160889},\n",
       "   {'layer': 20, 'head': 19, 'score': 0.0018348246812820435},\n",
       "   {'layer': 20, 'head': 20, 'score': 0.09081172943115234},\n",
       "   {'layer': 20, 'head': 21, 'score': 0.0009861290454864502},\n",
       "   {'layer': 20, 'head': 22, 'score': 0.0019090771675109863},\n",
       "   {'layer': 20, 'head': 23, 'score': 0.17084503173828125},\n",
       "   {'layer': 20, 'head': 24, 'score': 0.02443861961364746},\n",
       "   {'layer': 20, 'head': 25, 'score': 0.1081991195678711},\n",
       "   {'layer': 20, 'head': 26, 'score': 0.1376209259033203},\n",
       "   {'layer': 20, 'head': 27, 'score': 0.023464441299438477},\n",
       "   {'layer': 20, 'head': 28, 'score': 0.000893227756023407},\n",
       "   {'layer': 20, 'head': 29, 'score': 0.001353919506072998},\n",
       "   {'layer': 20, 'head': 30, 'score': 0.00871807336807251},\n",
       "   {'layer': 20, 'head': 31, 'score': 0.0016880184412002563},\n",
       "   {'layer': 21, 'head': 0, 'score': 0.0032114386558532715},\n",
       "   {'layer': 21, 'head': 1, 'score': 0.06038475036621094},\n",
       "   {'layer': 21, 'head': 2, 'score': 0.03760528564453125},\n",
       "   {'layer': 21, 'head': 3, 'score': 0.011637091636657715},\n",
       "   {'layer': 21, 'head': 4, 'score': 0.00013291090726852417},\n",
       "   {'layer': 21, 'head': 5, 'score': 0.00041607022285461426},\n",
       "   {'layer': 21, 'head': 6, 'score': 0.0003467835485935211},\n",
       "   {'layer': 21, 'head': 7, 'score': 0.0002716127783060074},\n",
       "   {'layer': 21, 'head': 8, 'score': 0.09734249114990234},\n",
       "   {'layer': 21, 'head': 9, 'score': 0.0005657635629177094},\n",
       "   {'layer': 21, 'head': 10, 'score': 0.0005663856863975525},\n",
       "   {'layer': 21, 'head': 11, 'score': 0.03252863883972168},\n",
       "   {'layer': 21, 'head': 12, 'score': 0.01996588706970215},\n",
       "   {'layer': 21, 'head': 13, 'score': 0.016564369201660156},\n",
       "   {'layer': 21, 'head': 14, 'score': 0.08688068389892578},\n",
       "   {'layer': 21, 'head': 15, 'score': 0.02942824363708496},\n",
       "   {'layer': 21, 'head': 16, 'score': 0.0011799782514572144},\n",
       "   {'layer': 21, 'head': 17, 'score': 0.0010888874530792236},\n",
       "   {'layer': 21, 'head': 18, 'score': 0.001849845051765442},\n",
       "   {'layer': 21, 'head': 19, 'score': 0.0009313970804214478},\n",
       "   {'layer': 21, 'head': 20, 'score': 0.0043253302574157715},\n",
       "   {'layer': 21, 'head': 21, 'score': 0.030785322189331055},\n",
       "   {'layer': 21, 'head': 22, 'score': 0.03586387634277344},\n",
       "   {'layer': 21, 'head': 23, 'score': 0.0073430538177490234},\n",
       "   {'layer': 21, 'head': 24, 'score': 0.01632559299468994},\n",
       "   {'layer': 21, 'head': 25, 'score': 0.009577631950378418},\n",
       "   {'layer': 21, 'head': 26, 'score': 0.08245849609375},\n",
       "   {'layer': 21, 'head': 27, 'score': 0.006125152111053467},\n",
       "   {'layer': 21, 'head': 28, 'score': 0.010887861251831055},\n",
       "   {'layer': 21, 'head': 29, 'score': 0.029104948043823242},\n",
       "   {'layer': 21, 'head': 30, 'score': 0.017778873443603516},\n",
       "   {'layer': 21, 'head': 31, 'score': 0.07887840270996094},\n",
       "   {'layer': 22, 'head': 0, 'score': 0.122955322265625},\n",
       "   {'layer': 22, 'head': 1, 'score': 0.09197235107421875},\n",
       "   {'layer': 22, 'head': 2, 'score': 0.12093448638916016},\n",
       "   {'layer': 22, 'head': 3, 'score': 0.002731829881668091},\n",
       "   {'layer': 22, 'head': 4, 'score': 0.005501687526702881},\n",
       "   {'layer': 22, 'head': 5, 'score': 0.005116760730743408},\n",
       "   {'layer': 22, 'head': 6, 'score': 0.004320770502090454},\n",
       "   {'layer': 22, 'head': 7, 'score': 0.002164199948310852},\n",
       "   {'layer': 22, 'head': 8, 'score': 0.08819293975830078},\n",
       "   {'layer': 22, 'head': 9, 'score': 0.007355153560638428},\n",
       "   {'layer': 22, 'head': 10, 'score': 0.02107548713684082},\n",
       "   {'layer': 22, 'head': 11, 'score': 0.05554342269897461},\n",
       "   {'layer': 22, 'head': 12, 'score': 0.17603492736816406},\n",
       "   {'layer': 22, 'head': 13, 'score': 0.17609214782714844},\n",
       "   {'layer': 22, 'head': 14, 'score': 0.32834625244140625},\n",
       "   {'layer': 22, 'head': 15, 'score': 0.15461349487304688},\n",
       "   {'layer': 22, 'head': 16, 'score': 0.00094623863697052},\n",
       "   {'layer': 22, 'head': 17, 'score': 0.0011748969554901123},\n",
       "   {'layer': 22, 'head': 18, 'score': 0.001712903380393982},\n",
       "   {'layer': 22, 'head': 19, 'score': 0.0022131800651550293},\n",
       "   {'layer': 22, 'head': 20, 'score': 0.0039021074771881104},\n",
       "   {'layer': 22, 'head': 21, 'score': 0.0011392086744308472},\n",
       "   {'layer': 22, 'head': 22, 'score': 0.0006709396839141846},\n",
       "   {'layer': 22, 'head': 23, 'score': 0.0025836825370788574},\n",
       "   {'layer': 22, 'head': 24, 'score': 0.005994856357574463},\n",
       "   {'layer': 22, 'head': 25, 'score': 0.002663731575012207},\n",
       "   {'layer': 22, 'head': 26, 'score': 0.002306699752807617},\n",
       "   {'layer': 22, 'head': 27, 'score': 0.061087608337402344},\n",
       "   {'layer': 22, 'head': 28, 'score': 0.1111898422241211},\n",
       "   {'layer': 22, 'head': 29, 'score': 0.12859630584716797},\n",
       "   {'layer': 22, 'head': 30, 'score': 0.013618826866149902},\n",
       "   {'layer': 22, 'head': 31, 'score': 0.0914602279663086},\n",
       "   {'layer': 23, 'head': 0, 'score': 0.0021130740642547607},\n",
       "   {'layer': 23, 'head': 1, 'score': 0.0019286423921585083},\n",
       "   {'layer': 23, 'head': 2, 'score': 0.002950429916381836},\n",
       "   {'layer': 23, 'head': 3, 'score': 0.002260178327560425},\n",
       "   {'layer': 23, 'head': 4, 'score': 0.0031486451625823975},\n",
       "   {'layer': 23, 'head': 5, 'score': 0.10373306274414062},\n",
       "   {'layer': 23, 'head': 6, 'score': 0.08487606048583984},\n",
       "   {'layer': 23, 'head': 7, 'score': 0.010957121849060059},\n",
       "   {'layer': 23, 'head': 8, 'score': 0.0037517547607421875},\n",
       "   {'layer': 23, 'head': 9, 'score': 0.004419267177581787},\n",
       "   {'layer': 23, 'head': 10, 'score': 0.0028625428676605225},\n",
       "   {'layer': 23, 'head': 11, 'score': 0.0017709732055664062},\n",
       "   {'layer': 23, 'head': 12, 'score': 0.08372783660888672},\n",
       "   {'layer': 23, 'head': 13, 'score': 0.08665180206298828},\n",
       "   {'layer': 23, 'head': 14, 'score': 0.07437419891357422},\n",
       "   {'layer': 23, 'head': 15, 'score': 0.000997982919216156},\n",
       "   {'layer': 23, 'head': 16, 'score': 0.00029408931732177734},\n",
       "   {'layer': 23, 'head': 17, 'score': 0.0006665140390396118},\n",
       "   {'layer': 23, 'head': 18, 'score': 0.003380030393600464},\n",
       "   {'layer': 23, 'head': 19, 'score': 0.0007874146103858948},\n",
       "   {'layer': 23, 'head': 20, 'score': 0.11893653869628906},\n",
       "   {'layer': 23, 'head': 21, 'score': 0.0033584535121917725},\n",
       "   {'layer': 23, 'head': 22, 'score': 0.13576889038085938},\n",
       "   {'layer': 23, 'head': 23, 'score': 0.0016051381826400757},\n",
       "   {'layer': 23, 'head': 24, 'score': 0.0046648383140563965},\n",
       "   {'layer': 23, 'head': 25, 'score': 0.12990951538085938},\n",
       "   {'layer': 23, 'head': 26, 'score': 0.004259288311004639},\n",
       "   {'layer': 23, 'head': 27, 'score': 0.11981964111328125},\n",
       "   {'layer': 23, 'head': 28, 'score': 0.0011676996946334839},\n",
       "   {'layer': 23, 'head': 29, 'score': 0.00017618294805288315},\n",
       "   {'layer': 23, 'head': 30, 'score': 0.0001538274809718132},\n",
       "   {'layer': 23, 'head': 31, 'score': 0.0002520177513360977},\n",
       "   {'layer': 24, 'head': 0, 'score': 0.0033877193927764893},\n",
       "   {'layer': 24, 'head': 1, 'score': 0.0247347354888916},\n",
       "   {'layer': 24, 'head': 2, 'score': 0.003007739782333374},\n",
       "   {'layer': 24, 'head': 3, 'score': 0.035748958587646484},\n",
       "   {'layer': 24, 'head': 4, 'score': 0.0012325048446655273},\n",
       "   {'layer': 24, 'head': 5, 'score': 0.000553131103515625},\n",
       "   {'layer': 24, 'head': 6, 'score': 0.0013207793235778809},\n",
       "   {'layer': 24, 'head': 7, 'score': 0.003979146480560303},\n",
       "   {'layer': 24, 'head': 8, 'score': 0.0003350377082824707},\n",
       "   {'layer': 24, 'head': 9, 'score': 0.00031758472323417664},\n",
       "   {'layer': 24, 'head': 10, 'score': 0.000293167307972908},\n",
       "   {'layer': 24, 'head': 11, 'score': 0.0004919432103633881},\n",
       "   {'layer': 24, 'head': 12, 'score': 0.004029572010040283},\n",
       "   {'layer': 24, 'head': 13, 'score': 0.001033499836921692},\n",
       "   {'layer': 24, 'head': 14, 'score': 0.005192875862121582},\n",
       "   {'layer': 24, 'head': 15, 'score': 0.0007487311959266663},\n",
       "   {'layer': 24, 'head': 16, 'score': 0.12156867980957031},\n",
       "   {'layer': 24, 'head': 17, 'score': 0.11663341522216797},\n",
       "   {'layer': 24, 'head': 18, 'score': 0.11602783203125},\n",
       "   {'layer': 24, 'head': 19, 'score': 0.003042161464691162},\n",
       "   {'layer': 24, 'head': 20, 'score': 0.1141500473022461},\n",
       "   {'layer': 24, 'head': 21, 'score': 0.0009660795331001282},\n",
       "   {'layer': 24, 'head': 22, 'score': 0.13032245635986328},\n",
       "   {'layer': 24, 'head': 23, 'score': 0.1747283935546875},\n",
       "   {'layer': 24, 'head': 24, 'score': 0.10401344299316406},\n",
       "   {'layer': 24, 'head': 25, 'score': 0.12723350524902344},\n",
       "   {'layer': 24, 'head': 26, 'score': 0.030057191848754883},\n",
       "   {'layer': 24, 'head': 28, 'score': 0.0009713694453239441},\n",
       "   {'layer': 24, 'head': 29, 'score': 0.0009054094552993774},\n",
       "   {'layer': 24, 'head': 30, 'score': 0.0004982948303222656},\n",
       "   {'layer': 24, 'head': 31, 'score': 0.0012294873595237732},\n",
       "   {'layer': 25, 'head': 0, 'score': 0.0019403398036956787},\n",
       "   {'layer': 25, 'head': 1, 'score': 0.0045424699783325195},\n",
       "   {'layer': 25, 'head': 2, 'score': 0.009369969367980957},\n",
       "   {'layer': 25, 'head': 3, 'score': 0.007052063941955566},\n",
       "   {'layer': 25, 'head': 4, 'score': 0.091644287109375},\n",
       "   {'layer': 25, 'head': 5, 'score': 0.15472030639648438},\n",
       "   {'layer': 25, 'head': 6, 'score': 0.1455821990966797},\n",
       "   {'layer': 25, 'head': 7, 'score': 0.11577129364013672},\n",
       "   {'layer': 25, 'head': 8, 'score': 0.0008865892887115479},\n",
       "   {'layer': 25, 'head': 9, 'score': 0.0006508752703666687},\n",
       "   {'layer': 25, 'head': 10, 'score': 0.0013628751039505005},\n",
       "   {'layer': 25, 'head': 11, 'score': 0.0004355907440185547},\n",
       "   {'layer': 25, 'head': 12, 'score': 0.123992919921875},\n",
       "   {'layer': 25, 'head': 13, 'score': 0.1236572265625},\n",
       "   {'layer': 25, 'head': 14, 'score': 0.08546066284179688},\n",
       "   {'layer': 25, 'head': 15, 'score': 0.0930185317993164},\n",
       "   {'layer': 25, 'head': 16, 'score': 0.0036381781101226807},\n",
       "   {'layer': 25, 'head': 17, 'score': 0.019688129425048828},\n",
       "   {'layer': 25, 'head': 18, 'score': 0.035982608795166016},\n",
       "   {'layer': 25, 'head': 19, 'score': 0.0015893131494522095},\n",
       "   {'layer': 25, 'head': 20, 'score': 4.020764026790857e-05},\n",
       "   {'layer': 25, 'head': 21, 'score': 0.00017601530998945236},\n",
       "   {'layer': 25, 'head': 22, 'score': 4.371555405668914e-05},\n",
       "   {'layer': 25, 'head': 23, 'score': 6.495951674878597e-05},\n",
       "   {'layer': 25, 'head': 24, 'score': 0.0002593863755464554},\n",
       "   {'layer': 25, 'head': 25, 'score': 0.00041546672582626343},\n",
       "   {'layer': 25, 'head': 26, 'score': 0.000653587281703949},\n",
       "   {'layer': 25, 'head': 27, 'score': 0.0006296411156654358},\n",
       "   {'layer': 25, 'head': 28, 'score': 0.0005074925720691681},\n",
       "   {'layer': 25, 'head': 29, 'score': 0.0004536285996437073},\n",
       "   {'layer': 25, 'head': 30, 'score': 0.00010266341269016266},\n",
       "   {'layer': 25, 'head': 31, 'score': 0.00018176063895225525},\n",
       "   {'layer': 26, 'head': 0, 'score': 0.0247802734375},\n",
       "   {'layer': 26, 'head': 1, 'score': 0.00446707010269165},\n",
       "   {'layer': 26, 'head': 2, 'score': 0.031068086624145508},\n",
       "   {'layer': 26, 'head': 3, 'score': 0.026364564895629883},\n",
       "   {'layer': 26, 'head': 4, 'score': 0.015517711639404297},\n",
       "   {'layer': 26, 'head': 5, 'score': 0.005053460597991943},\n",
       "   {'layer': 26, 'head': 6, 'score': 0.010562419891357422},\n",
       "   {'layer': 26, 'head': 7, 'score': 0.011898994445800781},\n",
       "   {'layer': 26, 'head': 8, 'score': 0.0016775131225585938},\n",
       "   {'layer': 26, 'head': 9, 'score': 0.0006157532334327698},\n",
       "   {'layer': 26, 'head': 10, 'score': 0.00271645188331604},\n",
       "   {'layer': 26, 'head': 11, 'score': 0.0007196739315986633},\n",
       "   {'layer': 26, 'head': 12, 'score': 0.145965576171875},\n",
       "   {'layer': 26, 'head': 14, 'score': 0.13152217864990234},\n",
       "   {'layer': 26, 'head': 16, 'score': 0.002325296401977539},\n",
       "   {'layer': 26, 'head': 17, 'score': 0.00204254686832428},\n",
       "   {'layer': 26, 'head': 18, 'score': 0.004594683647155762},\n",
       "   {'layer': 26, 'head': 19, 'score': 0.013116836547851562},\n",
       "   {'layer': 26, 'head': 20, 'score': 0.0012910515069961548},\n",
       "   {'layer': 26, 'head': 21, 'score': 0.004001796245574951},\n",
       "   {'layer': 26, 'head': 22, 'score': 0.002793222665786743},\n",
       "   {'layer': 26, 'head': 23, 'score': 0.004794478416442871},\n",
       "   {'layer': 26, 'head': 24, 'score': 0.0005732178688049316},\n",
       "   {'layer': 26, 'head': 25, 'score': 0.0010703951120376587},\n",
       "   {'layer': 26, 'head': 26, 'score': 0.0007338449358940125},\n",
       "   {'layer': 26, 'head': 27, 'score': 0.046654701232910156},\n",
       "   {'layer': 26, 'head': 28, 'score': 0.00372922420501709},\n",
       "   {'layer': 26, 'head': 29, 'score': 0.11305809020996094},\n",
       "   {'layer': 26, 'head': 30, 'score': 0.03745412826538086},\n",
       "   {'layer': 26, 'head': 31, 'score': 0.08283424377441406},\n",
       "   {'layer': 27, 'head': 0, 'score': 0.0004745200276374817},\n",
       "   {'layer': 27, 'head': 1, 'score': 0.0009226202964782715},\n",
       "   {'layer': 27, 'head': 2, 'score': 0.0005035586655139923},\n",
       "   {'layer': 27, 'head': 3, 'score': 0.0006826594471931458},\n",
       "   {'layer': 27, 'head': 4, 'score': 0.20409011840820312},\n",
       "   {'layer': 27, 'head': 5, 'score': 0.22083282470703125},\n",
       "   {'layer': 27, 'head': 7, 'score': 0.20166778564453125},\n",
       "   {'layer': 27, 'head': 8, 'score': 0.00396496057510376},\n",
       "   {'layer': 27, 'head': 9, 'score': 0.000234188511967659},\n",
       "   {'layer': 27, 'head': 10, 'score': 0.0007820278406143188},\n",
       "   {'layer': 27, 'head': 11, 'score': 0.0006830096244812012},\n",
       "   {'layer': 27, 'head': 12, 'score': 0.0016665756702423096},\n",
       "   {'layer': 27, 'head': 13, 'score': 0.0030635297298431396},\n",
       "   {'layer': 27, 'head': 14, 'score': 0.0007540062069892883},\n",
       "   {'layer': 27, 'head': 15, 'score': 0.003625333309173584},\n",
       "   {'layer': 27, 'head': 16, 'score': 0.044116973876953125},\n",
       "   {'layer': 27, 'head': 17, 'score': 0.0036934614181518555},\n",
       "   {'layer': 27, 'head': 18, 'score': 0.002661079168319702},\n",
       "   {'layer': 27, 'head': 19, 'score': 0.002367675304412842},\n",
       "   {'layer': 27, 'head': 20, 'score': 0.20514297485351562},\n",
       "   {'layer': 27, 'head': 21, 'score': 0.0230867862701416},\n",
       "   {'layer': 27, 'head': 22, 'score': 0.1433696746826172},\n",
       "   {'layer': 27, 'head': 23, 'score': 0.11404705047607422},\n",
       "   {'layer': 27, 'head': 24, 'score': 0.004517018795013428},\n",
       "   {'layer': 27, 'head': 25, 'score': 0.0006135031580924988},\n",
       "   {'layer': 27, 'head': 26, 'score': 0.000569559633731842},\n",
       "   {'layer': 27, 'head': 27, 'score': 0.00040679052472114563},\n",
       "   {'layer': 27, 'head': 28, 'score': 0.013806939125061035},\n",
       "   {'layer': 27, 'head': 29, 'score': 0.0004481896758079529},\n",
       "   {'layer': 27, 'head': 30, 'score': 0.010320901870727539},\n",
       "   {'layer': 27, 'head': 31, 'score': 0.005196213722229004},\n",
       "   {'layer': 28, 'head': 0, 'score': 0.043521881103515625},\n",
       "   {'layer': 28, 'head': 1, 'score': 0.0008893385529518127},\n",
       "   {'layer': 28, 'head': 2, 'score': 0.0013580918312072754},\n",
       "   {'layer': 28, 'head': 3, 'score': 0.0027939975261688232},\n",
       "   {'layer': 28, 'head': 4, 'score': 0.00015606451779603958},\n",
       "   {'layer': 28, 'head': 5, 'score': 7.929932326078415e-05},\n",
       "   {'layer': 28, 'head': 6, 'score': 0.0006527528166770935},\n",
       "   {'layer': 28, 'head': 7, 'score': 6.233016029000282e-05},\n",
       "   {'layer': 28, 'head': 8, 'score': 0.0010631829500198364},\n",
       "   {'layer': 28, 'head': 9, 'score': 0.0006367862224578857},\n",
       "   {'layer': 28, 'head': 10, 'score': 0.0132676362991333},\n",
       "   {'layer': 28, 'head': 11, 'score': 0.0033592283725738525},\n",
       "   {'layer': 28, 'head': 12, 'score': 0.0018773376941680908},\n",
       "   {'layer': 28, 'head': 13, 'score': 0.05351066589355469},\n",
       "   {'layer': 28, 'head': 14, 'score': 0.005023300647735596},\n",
       "   {'layer': 28, 'head': 15, 'score': 0.2396068572998047},\n",
       "   {'layer': 28, 'head': 16, 'score': 0.0034460127353668213},\n",
       "   {'layer': 28, 'head': 17, 'score': 0.0021308064460754395},\n",
       "   {'layer': 28, 'head': 18, 'score': 0.036504268646240234},\n",
       "   {'layer': 28, 'head': 19, 'score': 0.003265082836151123},\n",
       "   {'layer': 28, 'head': 20, 'score': 0.029542922973632812},\n",
       "   {'layer': 28, 'head': 21, 'score': 0.0030496716499328613},\n",
       "   {'layer': 28, 'head': 22, 'score': 0.0013176798820495605},\n",
       "   {'layer': 28, 'head': 23, 'score': 0.030483245849609375},\n",
       "   {'layer': 28, 'head': 24, 'score': 0.012317538261413574},\n",
       "   {'layer': 28, 'head': 25, 'score': 0.002192944288253784},\n",
       "   {'layer': 28, 'head': 26, 'score': 6.127078086137772e-05},\n",
       "   {'layer': 28, 'head': 27, 'score': 0.05384397506713867},\n",
       "   {'layer': 28, 'head': 28, 'score': 0.0032651126384735107},\n",
       "   {'layer': 28, 'head': 29, 'score': 0.0033074021339416504},\n",
       "   {'layer': 28, 'head': 30, 'score': 0.012325286865234375},\n",
       "   {'layer': 28, 'head': 31, 'score': 0.0011634975671768188},\n",
       "   {'layer': 29, 'head': 0, 'score': 0.0017247051000595093},\n",
       "   {'layer': 29, 'head': 1, 'score': 0.0018402636051177979},\n",
       "   {'layer': 29, 'head': 2, 'score': 0.006564736366271973},\n",
       "   {'layer': 29, 'head': 3, 'score': 0.0020161867141723633},\n",
       "   {'layer': 29, 'head': 4, 'score': 0.0020656436681747437},\n",
       "   {'layer': 29, 'head': 5, 'score': 0.001828029751777649},\n",
       "   {'layer': 29, 'head': 6, 'score': 0.000989668071269989},\n",
       "   {'layer': 29, 'head': 7, 'score': 0.0006357580423355103},\n",
       "   {'layer': 29, 'head': 8, 'score': 0.00560528039932251},\n",
       "   {'layer': 29, 'head': 9, 'score': 0.0317080020904541},\n",
       "   {'layer': 29, 'head': 10, 'score': 0.012161850929260254},\n",
       "   {'layer': 29, 'head': 11, 'score': 0.02662348747253418},\n",
       "   {'layer': 29, 'head': 12, 'score': 0.0013329237699508667},\n",
       "   {'layer': 29, 'head': 13, 'score': 0.001597866415977478},\n",
       "   {'layer': 29, 'head': 14, 'score': 0.0017536580562591553},\n",
       "   {'layer': 29, 'head': 15, 'score': 0.0017881393432617188},\n",
       "   {'layer': 29, 'head': 16, 'score': 0.003716200590133667},\n",
       "   {'layer': 29, 'head': 17, 'score': 0.003451436758041382},\n",
       "   {'layer': 29, 'head': 18, 'score': 0.0019237250089645386},\n",
       "   {'layer': 29, 'head': 19, 'score': 0.004147857427597046},\n",
       "   {'layer': 29, 'head': 20, 'score': 0.032094478607177734},\n",
       "   {'layer': 29, 'head': 21, 'score': 0.055536746978759766},\n",
       "   {'layer': 29, 'head': 22, 'score': 0.11271953582763672},\n",
       "   {'layer': 29, 'head': 23, 'score': 0.03192567825317383},\n",
       "   {'layer': 29, 'head': 24, 'score': 0.00017060525715351105},\n",
       "   {'layer': 29, 'head': 25, 'score': 0.00017988216131925583},\n",
       "   {'layer': 29, 'head': 26, 'score': 5.309289554134011e-05},\n",
       "   {'layer': 29, 'head': 27, 'score': 6.634998135268688e-05},\n",
       "   {'layer': 29, 'head': 28, 'score': 0.00863558053970337},\n",
       "   {'layer': 29, 'head': 29, 'score': 0.008344054222106934},\n",
       "   {'layer': 29, 'head': 30, 'score': 0.01880931854248047},\n",
       "   {'layer': 29, 'head': 31, 'score': 0.02283620834350586},\n",
       "   {'layer': 30, 'head': 0, 'score': 0.004162490367889404},\n",
       "   {'layer': 30, 'head': 1, 'score': 0.02197742462158203},\n",
       "   {'layer': 30, 'head': 2, 'score': 0.034589290618896484},\n",
       "   {'layer': 30, 'head': 3, 'score': 0.016393423080444336},\n",
       "   {'layer': 30, 'head': 4, 'score': 0.001761108636856079},\n",
       "   {'layer': 30, 'head': 5, 'score': 0.002541571855545044},\n",
       "   {'layer': 30, 'head': 6, 'score': 0.01134192943572998},\n",
       "   {'layer': 30, 'head': 7, 'score': 0.002333015203475952},\n",
       "   {'layer': 30, 'head': 8, 'score': 0.0033053457736968994},\n",
       "   {'layer': 30, 'head': 9, 'score': 0.02115654945373535},\n",
       "   {'layer': 30, 'head': 10, 'score': 0.0061844587326049805},\n",
       "   {'layer': 30, 'head': 11, 'score': 0.039371490478515625},\n",
       "   {'layer': 30, 'head': 12, 'score': 0.13472366333007812},\n",
       "   {'layer': 30, 'head': 13, 'score': 0.023426055908203125},\n",
       "   {'layer': 30, 'head': 14, 'score': 0.060335636138916016},\n",
       "   {'layer': 30, 'head': 15, 'score': 0.08271503448486328},\n",
       "   {'layer': 30, 'head': 16, 'score': 0.012342572212219238},\n",
       "   {'layer': 30, 'head': 17, 'score': 0.009190678596496582},\n",
       "   {'layer': 30, 'head': 18, 'score': 0.016353249549865723},\n",
       "   {'layer': 30, 'head': 19, 'score': 0.006096780300140381},\n",
       "   {'layer': 30, 'head': 20, 'score': 0.07361602783203125},\n",
       "   {'layer': 30, 'head': 21, 'score': 0.1591663360595703},\n",
       "   {'layer': 30, 'head': 22, 'score': 0.003948867321014404},\n",
       "   {'layer': 30, 'head': 23, 'score': 0.004451185464859009},\n",
       "   {'layer': 30, 'head': 24, 'score': 0.018459558486938477},\n",
       "   {'layer': 30, 'head': 25, 'score': 0.007246196269989014},\n",
       "   {'layer': 30, 'head': 26, 'score': 0.06091022491455078},\n",
       "   {'layer': 30, 'head': 27, 'score': 0.03741121292114258},\n",
       "   {'layer': 30, 'head': 28, 'score': 0.001764446496963501},\n",
       "   {'layer': 30, 'head': 29, 'score': 0.12729740142822266},\n",
       "   {'layer': 30, 'head': 30, 'score': 0.09840106964111328},\n",
       "   {'layer': 30, 'head': 31, 'score': 0.019389629364013672},\n",
       "   {'layer': 31, 'head': 0, 'score': 0.0015778839588165283},\n",
       "   {'layer': 31, 'head': 1, 'score': 0.0008608400821685791},\n",
       "   {'layer': 31, 'head': 2, 'score': 0.0011158883571624756},\n",
       "   {'layer': 31, 'head': 3, 'score': 0.0006743520498275757},\n",
       "   {'layer': 31, 'head': 4, 'score': 0.003975778818130493},\n",
       "   {'layer': 31, 'head': 5, 'score': 7.698126137256622e-05},\n",
       "   {'layer': 31, 'head': 6, 'score': 0.005549490451812744},\n",
       "   {'layer': 31, 'head': 7, 'score': 0.007354855537414551},\n",
       "   {'layer': 31, 'head': 8, 'score': 0.0008134916424751282},\n",
       "   {'layer': 31, 'head': 9, 'score': 0.0007102265954017639},\n",
       "   {'layer': 31, 'head': 10, 'score': 0.00036317482590675354},\n",
       "   {'layer': 31, 'head': 11, 'score': 0.007427871227264404},\n",
       "   {'layer': 31, 'head': 12, 'score': 0.0009790882468223572},\n",
       "   {'layer': 31, 'head': 13, 'score': 0.007376730442047119},\n",
       "   {'layer': 31, 'head': 14, 'score': 7.73346982896328e-06},\n",
       "   {'layer': 31, 'head': 15, 'score': 0.000647909939289093},\n",
       "   {'layer': 31, 'head': 16, 'score': 0.007666289806365967},\n",
       "   {'layer': 31, 'head': 17, 'score': 0.004063814878463745},\n",
       "   {'layer': 31, 'head': 18, 'score': 0.0002075694501399994},\n",
       "   {'layer': 31, 'head': 19, 'score': 0.005715668201446533},\n",
       "   {'layer': 31, 'head': 20, 'score': 0.027730226516723633},\n",
       "   {'layer': 31, 'head': 21, 'score': 0.030253887176513672},\n",
       "   {'layer': 31, 'head': 22, 'score': 0.008527159690856934},\n",
       "   {'layer': 31, 'head': 23, 'score': 3.448501229286194e-05},\n",
       "   ...]},\n",
       " 'analysis_params': {'num_of_samples': 2048, 'seq_len': 50, 'batch_size': 32}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "induction_scores['model_results'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0506dcd8-b82b-4cb2-8fd9-703504ecbb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 22 0.8215408325195312\n",
      "5 8 0.6422958374023438\n",
      "5 11 0.579925537109375\n",
      "8 1 0.8407974243164062\n",
      "10 14 0.5748367309570312\n",
      "15 1 0.684967041015625\n",
      "15 30 0.9475479125976562\n",
      "16 20 0.647491455078125\n",
      "20 14 0.5614013671875\n"
     ]
    }
   ],
   "source": [
    "model_results = induction_scores['model_results'][5]\n",
    "\n",
    "all_induction_scores_old = []\n",
    "for layer_id in range(model_results['model_configuration']['num_layers']):\n",
    "    for head_id in range(model_results['model_configuration']['num_heads']):\n",
    "        score = model_results['induction_scores'][layer_id][head_id]\n",
    "        all_induction_scores_old.append(score)\n",
    "        if score > 0.5:\n",
    "            print(layer_id, head_id, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63bddda7-6c17-4baf-8627-c98c03a03505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=np.float64(0.9264447778716359), pvalue=np.float64(0.0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGgCAYAAAB45mdaAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU0xJREFUeJzt3Xt0XFedJ/rvedapl0qS9VbkKJZtEmLngUOMY3KhwYl7YNKd1dNDLmElwc1jAoGh4zWrSSAkpBlwmqZzPd2E9iV0Anct0gnQj2GRTB4IMj0khhAH03Fix5YfsaxHSbJU78d57fvHUZUtS7ZVsqQjVX0/a2mxXK4qbZ2YOl/tvX+/LQkhBIiIiIh8Ivs9ACIiIqptDCNERETkK4YRIiIi8hXDCBEREfmKYYSIiIh8xTBCREREvmIYISIiIl8xjBAREZGvGEaIiIjIVwwjRERE5KuKw8i//du/4aabbkJHRwckScK//uu/nvc1L774It71rnchEAhg9erV+P73vz+HoRIREVE1Uit9QTabxZVXXok/+7M/w5/8yZ+c9/lHjx7Fhz/8Ydx555344Q9/iN7eXnzyk59Ee3s7tm7dOqvv6bouBgcHEY1GIUlSpUMmIiIiHwghkE6n0dHRAVk+x/yHuAAAxL/8y7+c8zl/8Rd/IS6//PIpj91yyy1i69ats/4+/f39AgC/+MUvfvGLX/xahl/9/f3nvM9XPDNSqd27d2PLli1THtu6dSv+/M///KyvKRaLKBaL5T+LyYOF+/v7UVdXtyDjJCIiovmVSqXQ1dWFaDR6zucteBgZHh5Ga2vrlMdaW1uRSqWQz+cRDAanvWbHjh148MEHpz1eV1fHMEJERLTMnG+LxZKsprn33nuRTCbLX/39/X4PiYiIiBbIgs+MtLW1IR6PT3ksHo+jrq5uxlkRAAgEAggEAgs9NCIiIloCFnxmZNOmTejt7Z3y2AsvvIBNmzYt9LcmIiKiZaDiMJLJZLB3717s3bsXgFe6u3fvXhw/fhyAt8Ry++23l59/55134siRI/iLv/gLHDhwAN/5znfwox/9CHfffff8/ARERES0rFUcRl599VVcffXVuPrqqwEA27dvx9VXX437778fADA0NFQOJgBwySWX4Omnn8YLL7yAK6+8En/zN3+D733ve7PuMUJERETVTRKlutklLJVKIRaLIZlMspqGiIhomZjt/XtJVtMQERFR7WAYISIiIl8teGkvERERLU2uKzCQyCNr2gjrKjrrg5DlxT8DjmGEiIioBvWNpPHcvjgOj2ZQsB0YqoKe5gi2rmvF6pZzt2+fbwwjRERENaZvJI3HXzqG8ayJ9piBkB5EzrSxbzCJwWQe2zZ3L2og4Z4RIiKiGuK6As/ti2M8a2JNSwRRQ4MiS4gaGta0RDCeNfH8G3G47uIV2zKMEBER1ZCBRB6HRzNojxnTDrCTJAntMQN9IxkMJPKLNiaGESIiohqSNW0UbAchfeadGkFdQdF2kDXtRRsTwwgREVENCesqDFVB7ixhI286CKgKwmcJKwuBYYSIiKiGdNYH0dMcwVCygDObsAshMJQsYHVLBJ31wUUbE8MIERFRDZFlCVvXtaIxrOPQSAbpggXbdZEuWDg0kkFjWMeNl7cuar8RhhEiIqIas7olim2bu7GuI4ZEzsKxsSwSOQvrO2OLXtYLsM8IERFRTVrdEsWq90fYgZWIiIj8I8sSuhpDfg+DyzRERETkL4YRIiIi8hXDCBEREfmKYYSIiIh8xTBCREREvmIYISIiIl8xjBAREZGvGEaIiIjIVwwjRERE5CuGESIiIvIVwwgRERH5imGEiIiIfMUwQkRERL5iGCEiIiJfMYwQERGRrxhGiIiIyFcMI0REROQrhhEiIiLyFcMIERER+YphhIiIiHzFMEJERES+YhghIiIiXzGMEBERka8YRoiIiMhXDCNERETkK4YRIiIi8hXDCBEREfmKYYSIiIh8xTBCREREvmIYISIiIl8xjBAREZGvGEaIiIjIVwwjRERE5CuGESIiIvIVwwgRERH5SvV7AEREREuF6woMJPLImjbCuorO+iBkWfJ7WFWPYYSIiAhA30gaz+2L4/BoBgXbgaEq6GmOYOu6Vqxuifo9vKrGMEJERDWvbySNx186hvGsifaYgZAeRM60sW8wicFkHts2dzOQLCDuGSEioprmugLP7YtjPGtiTUsEUUODIkuIGhrWtEQwnjXx/BtxuK7we6hVi2GEiIhq2kAij8OjGbTHDEjS1P0hkiShPWagbySDgUTepxFWP4YRIiKqaVnTRsF2ENJn3rkQ1BUUbQdZ017kkdUOhhEiIqppYV2FoSrInSVs5E0HAVVB+CxhhS4cwwgREdW0zvogepojGEoWIMTUfSFCCAwlC1jdEkFnfdCnEVY/hhEiIqppsixh67pWNIZ1HBrJIF2wYLsu0gULh0YyaAzruPHyVvYbWUAMI0REVPNWt0SxbXM31nXEkMhZODaWRSJnYX1njGW9i2BOYeSRRx5Bd3c3DMPAxo0b8corr5zz+Tt37sQ73vEOBINBdHV14e6770ahUJjTgImIiBbC6pYoPvP+Htx9w1p8/oNrcPcNa3Hn+3oYRBZBxbtxnnrqKWzfvh27du3Cxo0bsXPnTmzduhVvvfUWWlpapj3/iSeewD333IPHHnsM1113HQ4ePIiPf/zjkCQJDz/88Lz8EERERPNBliV0NYb8HkbNqXhm5OGHH8anPvUpbNu2De985zuxa9cuhEIhPPbYYzM+/+WXX8bmzZtx6623oru7GzfeeCM++tGPnnc2hYiIiGpDRWHENE3s2bMHW7ZsOfUGsowtW7Zg9+7dM77muuuuw549e8rh48iRI3jmmWfwoQ996Kzfp1gsIpVKTfkiIiKi6lTRMs3Y2Bgcx0Fra+uUx1tbW3HgwIEZX3PrrbdibGwM733veyGEgG3buPPOO/GlL33prN9nx44dePDBBysZGhERES1TC15N8+KLL+Ib3/gGvvOd7+C1117DP//zP+Ppp5/G1772tbO+5t5770UymSx/9ff3L/QwiYiIyCcVzYw0NTVBURTE4/Epj8fjcbS1tc34mq985Su47bbb8MlPfhIAsH79emSzWXz605/Gl7/8Zcjy9DwUCAQQCAQqGRoREREtUxXNjOi6jg0bNqC3t7f8mOu66O3txaZNm2Z8TS6XmxY4FEUBgGmd7oiIiKj2VFzau337dtxxxx245pprcO2112Lnzp3IZrPYtm0bAOD2229HZ2cnduzYAQC46aab8PDDD+Pqq6/Gxo0b0dfXh6985Su46aabyqGEiIiIalfFYeSWW27B6Ogo7r//fgwPD+Oqq67Cs88+W97Uevz48SkzIffddx8kScJ9992HgYEBNDc346abbsLXv/71+fspiIiIaNmSxDJYK0mlUojFYkgmk6irq/N7OEREVMNcV2AgkUfWtBHWVXTWB3luzVnM9v7N85CJiIhmqW8kjef2xXF4NIOC7cBQFfQ0R7B1XSvbxl8AhhEiIqJZ6BtJ4/GXjmE8a6I9ZiCkB5EzbewbTGIwmeeBeheAp/YSERGdh+sKPLcvjvGsiTUtEUQNDYosIWpoWNMSwXjWxPNvxOG6S37nw5LEMEJERHQeA4k8Do9m0B4zIElT94dIkoT2mIG+kQwGEnmfRri8MYwQERGdR9a0UbAdhPSZdzcEdQVF20HWtBd5ZNWBYYSIiOg8wroKQ1WQO0vYyJsOAqqC8FnCCp0bwwgREdF5dNYH0dMcwVCyMK17uBACQ8kCVrdE0Fkf9GmEyxvDCBER0XnIsoSt61rRGNZxaCSDdMGC7bpIFywcGsmgMazjxstb2W9kjhhGiIiIZmF1SxTbNndjXUcMiZyFY2NZJHIW1nfGWNZ7gbi4RURENEurW6JY9f4IO7DOM4YRIiKiCsiyhK7GkN/DqCpcpiEiIiJfMYwQERGRrxhGiIiIyFcMI0REROQrhhEiIiLyFcMIERER+YphhIiIiHzFMEJERES+YhghIiIiXzGMEBERka8YRoiIiMhXDCNERETkK4YRIiIi8hXDCBEREfmKYYSIiIh8xTBCREREvmIYISIiIl8xjBAREZGvGEaIiIjIVwwjRERE5CuGESIiIvKV6vcAiIjowriuwEAij6xpI6yr6KwPQpYlv4dFNGsMI0REy1jfSBrP7Yvj8GgGBduBoSroaY5g67pWrG6J+j08ollhGCEiWqb6RtJ4/KVjGM+aaI8ZCOlB5Ewb+waTGEzmsW1zNwMJLQvcM0JEtAy5rsBz++IYz5pY0xJB1NCgyBKihoY1LRGMZ008/0Ycriv8HirReTGMEBEtQwOJPA6PZtAeMyBJU/eHSJKE9piBvpEMBhJ5n0ZINHsMI0REy1DWtFGwHYT0mVfbg7qCou0ga9qLPDKiyjGMEBEtQ2FdhaEqyJ0lbORNBwFVQfgsYYVoKWEYISJahjrrg+hpjmAoWYAQU/eFCCEwlCxgdUsEnfVBn0ZINHsMI0REy5AsS9i6rhWNYR2HRjJIFyzYrot0wcKhkQwawzpuvLyV/UZoWWAYISJapla3RLFtczfWdcSQyFk4NpZFImdhfWeMZb20rHAxkYhoGVvdEsWq90fYgZWWNYYRIqJlTpYldDWG/B4G0ZxxmYaIiIh8xZkRIqIL5NdBdTwgj6oFwwgR0QXw66A6HpBH1YRhhIhojvw6qI4H5FG14Z4RIqI58OugOh6QR9WIYYSIaA78OqiOB+RRNWIYISKaA78OquMBeVSNGEaIiOYgrKsIKDLiqTzGMkWk8taUM2IW6qA6HpBH1Yj/WumCsbyQalHedDCWMXF4NIOQrkBVZDSEdKxuiaAhpGEoWcD6zti8H1RXOiBv32ASkYA6ZammdEDeQnxfooXEMEIXhOWFVIv6RtL4we5jgATUBVVYtgtZAkZSBYxni2iJGli5IrQgB9WVDsgbTOZxaMTbOxLUFeRNB0PJAg/Io2WJYYTmjOWFVItOr2a5uqseEzkTh0eyGM+ZkCSBdMFBax1wx3UXL9i//9IBeaVfBOKpAgKqgvWdMdx4OX8RoOWHYYTm5MzywtJUcdTQEAmoODSSwfNvxLGqKcLf0KiqnFnN0hgOoKFbR7pgw3RcmLYL23ER1Bb243UhDsjjkiv5hWGE5qSS8kIe4EXV5FQ1y6k9GZIkoS6oAQBs18WxseyiVLPM5wF5XHIlP7GahuaE5YVUq6qxmqW05LpvMIn6kIZVTRHUhzTsG0zi8ZeOoW8k7fcQqcoxjNCcVOMHMtFslKpZhpKFKaW8wKlqltUtkWVTzcKOrrQUzCmMPPLII+ju7oZhGNi4cSNeeeWVcz4/kUjgrrvuQnt7OwKBANauXYtnnnlmTgOmpaHaPpCJZqtUzdIY1nFoJIN0wYLtukgXLBwaySy7ahZ2dKWloOIw8tRTT2H79u144IEH8Nprr+HKK6/E1q1bMTIyMuPzTdPEDTfcgGPHjuEnP/kJ3nrrLTz66KPo7Oy84MGTf6rtA5moEqVqlnUdMSRyFo6NZZHIWVjfGVt2VWRccqWlQBJn/lp7Hhs3bsS73/1ufPvb3wYAuK6Lrq4ufP7zn8c999wz7fm7du3CX//1X+PAgQPQNG1Og0ylUojFYkgmk6irq5vTe9DCOH3TW9H2lmZWt0RYXkg1oRqqT/rHc/h/XjiI+pCGqDH9MzpdsJDIWbj7hrXcjE4Vm+39u6IFfdM0sWfPHtx7773lx2RZxpYtW7B79+4ZX/PTn/4UmzZtwl133YX/+T//J5qbm3Hrrbfii1/8IhRFmfE1xWIRxWJxyg9DS9NClBcSLRfzWc3iF3Z0paWgojAyNjYGx3HQ2to65fHW1lYcOHBgxtccOXIEv/jFL/Cxj30MzzzzDPr6+vDZz34WlmXhgQcemPE1O3bswIMPPljJ0MhH5/tArobfHomqFTu60lKw4KUOruuipaUF3/3ud6EoCjZs2ICBgQH89V//9VnDyL333ovt27eX/5xKpdDV1bXQQ6UFwN4FREsfO7qS3yoKI01NTVAUBfF4fMrj8XgcbW1tM76mvb0dmqZNWZK57LLLMDw8DNM0oev6tNcEAgEEAoFKhkZLENvFEy0fXHIlP1VUTaPrOjZs2IDe3t7yY67rore3F5s2bZrxNZs3b0ZfXx9c1y0/dvDgQbS3t88YRKg6sHcB0fJTWnK9tK0OXY0hBhFaNBWX9m7fvh2PPvoofvCDH2D//v34zGc+g2w2i23btgEAbr/99ikbXD/zmc9gfHwcX/jCF3Dw4EE8/fTT+MY3voG77rpr/n4KWnLYu4CIiGar4j0jt9xyC0ZHR3H//fdjeHgYV111FZ599tnyptbjx49Dlk9lnK6uLjz33HO4++67ccUVV6CzsxNf+MIX8MUvfnH+fgpacmY6v+N0QV1BPFVg7wIiIqq8z4gf2Gdk+WHvAiIimu39m2fT0IJgu3giIpothhFaEGwXT0REs8UwQgumms7vICKihcPz3WlB1ULvAnaYJSK6MAwjtOCq4fyOs2GHWSKiC8cwQjRH7DBLRDQ/uGeEaA7YYZaIaP4wjBDNATvMEhHNH4YRojk41WF25pXOoK6gaDvsMEtENAvcM0I0B2FdhaEqyJn2jB1m86aDgKogfJawQufGCiWi2sJPSqI5KHWY3TeYRCSgTlmqKXWYXd8ZY4fZOWCFElHtYRghmoNSh9nBZB6HRry9I0FdQd50MJQssMPsHLFCiag2cc8I0Ryxw+z8YoUSUe3izAjRBaiFDrOLpZIKpWptokdUqxhGiC5QNXeYXUynKpRm3mcT1BXEUwVWKBFVIS7TENGScHqF0kxYoURUvRhGiGhJKFUoDSULEGLqvpBShdLqlggrlIiqEH/FIKIlYalWKLHnCdHCYxihafjhS34pVSiV+ozEUwUEVAXrO2O48fLF7zPCnidEi4NhhKbghy/5balUKLHnCdHiYRihMn740oWar1k1vyuUzux5Uio1jhoaIgEVh0YyeP6NOFY1RThrSDQPGEYIAD986cJV06wae54QLS5W0xCAyj58aeG4rkD/eA4HhlPoH88tm26jpVm1fYNJ1Ic0rGqKoD6kYd9gEo+/dAx9I2m/h1gRnspMtLg4M0IA2HBqKViuMwvVOKvGU5mJFhdnRggAG075bTnPLFTjrBp7nhAtLoYRAsAPXz8t9wPiFnJJw69lq1LPk8awjkMjGaQLFmzXRbpg4dBIhqcyE80z/ppLAJZuw6lasNw3Sy7Ukobfy1ZLrecJUTVjGKEyfvj6Y7nv1ynNqu0bTCISUKcEqtKs2vrOWEWzakulzHyp9DwhqnYMIzQFP3wX33LfLDnfs2pLbUOs3z1PiGrB0vx0I1/xw3dxLcTMwmKbz1m15b5sRUSVYxgh8lm17NeZr1m15b5sRUSVYxghWgKqZb/OfMyqLfdlKyKqHP/fTLREcL+OpxqWrYioMgwjREsI9+tUz7IVEc0ewwj5Yr5Od6XqVC3LVkQ0OwwjtOj8bmZFywOXrYhqB8MILaql0syKlgcuWxHVBp5NQ4tmuZ/BQkREC4NhhBZNNZ7uSkREF45hhBbNQp7uSkREyxfDCC2a05tZzYTNrIiIahPDCC2aUjOroWQBQkzdF1JqZrW6JcJmVkRENYZhhBZNqZlVY1jHoZEM0gULtusiXbBwaCTDZlZERDWKYYQWVamZ1bqOGBI5C8fGskjkLKzvjLGsl4ioRnFxnhYdm1kREdHpGEbIF2xmRUREJVymISIiIl8xjBAREZGvuExDywpP+yUiqj4MI7Rs8LTfc2NQI6LlimGElgWe9ntuFxrUGGSIyE8MI7TknXnab+mQvaihIRJQcWgkg+ffiGNVU6Qmb6AXGtQ440REfuMGVlryeNrv2Z0Z1KKGBkWWEDU0rGmJYDxr4vk34nBdMePrS0Fm32AS9SENq5oiqA9p2DeYxOMvHUPfSHqRfyIiqkUMI7Tk8bTfs7uQoHahQYaIaL4wjNCSx9N+z+5CghpnnIhoqWAYoSWPp/2e3YUENc44EdFSwTBCS14tnPbrugL94zkcGE6hfzw366WRCwlqnHEioqWCnzK0LJRO+y1VfcRTBQRUBes7Y7jx8uVd9XEh1SyloDaYzOPQiLfkEtQV5E0HQ8nCOYNaKcjsG0wiElCnLNWUgsz6zlhNzjgR0eJiGKFloxpP+52P/ilzDWoXEmSIiObTnJZpHnnkEXR3d8MwDGzcuBGvvPLKrF735JNPQpIk3HzzzXP5tlRjZlq6KJ32e2lbHboaQ8v6Rjmf1SyrW6L4zPt7cPcNa/H5D67B3TesxZ3v65l1kFnXEUMiZ+HYWBaJnIX1nbGabyRHRIun4pmRp556Ctu3b8euXbuwceNG7Ny5E1u3bsVbb72FlpaWs77u2LFj+G//7b/h+uuvv6ABU22ohUZclVSzdDWGzvt+paBWqWqccSKi5aXimZGHH34Yn/rUp7Bt2za8853vxK5duxAKhfDYY4+d9TWO4+BjH/sYHnzwQaxateqCBkzVr1YacS2lapZqmnEiouWnojBimib27NmDLVu2nHoDWcaWLVuwe/fus77uL//yL9HS0oJPfOITs/o+xWIRqVRqyhfVhlpqxMVqFiIiT0VhZGxsDI7joLW1dcrjra2tGB4envE1v/rVr/AP//APePTRR2f9fXbs2IFYLFb+6urqqmSYtIzVUiMu9k8hIvIsaJ+RdDqN2267DY8++iiamppm/bp7770XyWSy/NXf37+Ao6SlZCktXSy0WuifQkQ0GxXN/zY1NUFRFMTj8SmPx+NxtLW1TXv+4cOHcezYMdx0003lx1zX9b6xquKtt95CT0/PtNcFAgEEAoFKhkZV4vSli6ihTfv7alu6qOb+KUREs1XRJ7qu69iwYQN6e3vL5bmu66K3txef+9znpj3/0ksvxeuvvz7lsfvuuw/pdBr/43/8Dy6/0DS12IiL1SxEVOsq/vVy+/btuOOOO3DNNdfg2muvxc6dO5HNZrFt2zYAwO23347Ozk7s2LEDhmFg3bp1U15fX18PANMeJwJqtxHXXMtyiYiqQcVh5JZbbsHo6Cjuv/9+DA8P46qrrsKzzz5b3tR6/PhxyDKPvKG549IFEVFtkcSZ2/iXoFQqhVgshmQyibq6Or+HQ4vEdQWXLoiIlrHZ3r+rYxcgVSUuXRAR1QaupxAREZGvGEaIiIjIVwwjRERE5CuGESIiIvIVN7DSsseqGyKi5Y1hhJa1vpF0uR9JwXZgqAp6miPYuo79SIiIlguGEVq2+kbSePylYxjPmmiPGQjpQeRMG/sGkxhM5rFtczcDCRHRMsA9I7Qsua7Ac/viGM+aWNMSQdTQoMgSooaGNS0RjGdNPP9GHK675Hv6ERHVPIYRWpYGEnkcHvXOrjn9MD0AkCQJ7TEDfSMZDCTyPo2QiIhmi2GElqWsaaNgOwjpM680BnUFRdtB1rQXeWRERFQp7hmhZSmsqzBUBTnTRtTQpv193nQQUBWEzxJWaPGx6omIzoaf1LQsddYH0dMcwb7BJCIBdcpSjRACQ8kC1nfG0Fkf9HGUU9XyzZhVT0R0LgwjFarlG8pSIssStq5rxWAyj0Mj3t6RoK4gbzoYShbQGNZx4+WtS+a/TS3fjFn1RETnwzBSgVq+oSxFq1ui2La5u/zfJJ4qIKAqWN8Zw42XL53/JrV8Mz6z6qk0gxU1NEQCKg6NZPD8G3GsaoosmeBIRIuPYWSWavmGspStboli1fsjS3a2qtZvxpVUPXU1hnwaJRH5jWFkFmr9hrLUybK0ZG9ktX4zPlX1NPPenaCuIJ4qsOqJqMaxtHcW2NOC5qrWS5BPr3qaCaueiAhgGJmVWr+h0NzV+s24VPU0lCxAiKndcEtVT6tbIkuq6omIFh/DyCzU+g2F5q7Wb8alqqfGsI5DIxmkCxZs10W6YOHQSGbJVT0RkT8YRmah1m8oNHe8GZ+qelrXEUMiZ+HYWBaJnIX1nTFu/CYiANzAOivLracFLS3LpQR5IS31qici8pckzvxVfwlKpVKIxWJIJpOoq6vzbRyn9xkp2t7SzOqWSM3cUOjCsGEeEdWa2d6/OTNSAf52RxdiKZcgExH5iWGkQryhEBERzS9uYCUiIiJfMYwQERGRrxhGiIiIyFcMI0REROQrhhEiIiLyFcMIERER+YphhIiIiHzFMEJERES+YhghIiIiXzGMEBERka8YRoiIiMhXDCNERETkK4YRIiIi8hXDCBEREfmKYYSIiIh8pfo9ADrFdQUGEnlkTRthXUVnfRCyLHFMRERU1RhGloi+kTSe2xfH4dEMCrYDQ1XQ0xzB1nWtWN0S5ZiIiKhqMYwsAX0jaTz+0jGMZ020xwyE9CBypo19g0kMJvPYtrl70W/+S3FMVD0440ZEp2MY8ZnrCjy3L47xrIk1LRFIkveBHDU0RAIqDo1k8Pwbcaxqiizah/VSHBNVD864EdGZuIHVZwOJPA6PZtAeM8o3/RJJktAeM9A3ksFAIr8kx+S6Av3jORwYTqF/PAfXFYs2Tlp+SjNu+waTqA9pWNUUQX1Iw77BJB5/6Rj6RtJ+D5GIfMCZEZ9lTRsF20FID87490FdQTxVQNa0l9yY9g+n8NO9g/wNl2aFM25EdDacGfFZWFdhqApyZwkbedNBQFUQ1hcvN85mTEXbxdO/Hyr/hnvJijAUGdh9ZAx/94s+HIynFm28tDwsxVlAIloaGEZ81lkfRE9zBEPJAoSYusQhhMBQsoDVLRF01s88S+HHmAYTeRRtF0XbxZqWCCxH4LXjCbw+kMJwsoDfHh3H1362HweHOeVOp5yacZs5WAd1BUXbWdRZQCJaGhhGfCbLEraua0VjWMehkQzSBQu26yJdsHBoJIPGsI4bL29d1Gnr08d0MJ7GYCKHeCqPwUQOB+NpBDQFAVVGR72BiZyFvf0JjKYLMDQFDWEd9SENh0cyeOSXfdwDQGVLcRaQiJYGhpElYHVLFNs2d2NdRwyJnIVjY1kkchbWd8Z8K6Fd3RLFBy5tQbbo4NdHxvHiW6P49ZFxZE0H71pZD12VEdQU9I1kkDdtNIZ1BFQZsiQhHFAR0mWczBbx/BtxbmolAEtzFpCIlgb+CrJErG6JYtX7I0um90LfSBq/ODCCcEDFplUrIMsSXFcgVbDx2tsJmLaLkXQBEzkTEUObsgfAclyoioL2WLC8B6CrMTTte7DXRG0pzbgNJvM4NOLtHQnqCvKmg6FkwZdZQCJaGhhGlhBZlma8ac+kdCNPFy1kCjYiARVRQ5uXG/rpVQ9rWyNTgkabEDgYz6BouRhM5GE7LjTj1D8jIQQyBRstdQaaowG8fTI74x4A9pqoTaVZwNJ/+3iqgICqYH1nDDdezv/2RLWKYWQZKt3If9c/gePjOeRNB0FNwcoVIVzd1XDWG/psZyLOV/XQUW/g+HgOEmTkzBw0xYKmyCjaLgqWg6ihoqc5jII18x4AdnetbUttFpCI/McwssyUbuTHT+Ywki7AcQSihoqi5eDERA5F253xhl7JTMRs+owEVBl/dFUHxv/3ERyMpyGEgAsJuiIjrKtwXYGhTAHrO2NT9gCw1wQBlc0CElH14wbWZaR0Iz+ZKcJ2XTiuwIqIjqihYUUkANsRsB0XJzPmlI2jlXa9nG3VQ0hX0RYLwtAUSJIERfKWad4ez+Fnrw8hZ9rT9gCw18TM2MmWiGoZZ0aWkdKNPGqoOHYyN2XjqCRJiBgqJnIWLmoIlW/onfXBc85EHIxn8KNX+3Hz1Z2IBrw9J6Wqh32DSYR1BZmiA9NxoSsyIgEFQ8kC1nXU4ff9CaQKFmJBDY4r4N0+BTRJgu0KDCeLcM+omliKHWf9xv0zRFTrGEaWkdKNvM7Qpm0cBQBNkZEt2lBkCTnTRta0p81ECCGQLtgwHRe5oo2RVB5vDCZxMJ5GYyhQvgluXdeK/cMpPPdmHM5pv6UrsoS1rVFc2VWPf9pzArmiFxpWt0Rg2i4cIaBIEgSA0XQR/7RnAF/8w2h5duT0WZeooU37GWut1wT3zxARMYwsK6UbueO6UBUZliMQUKeW1CqyDMcV5Rv66TMR41kTfSMZTORM5EwbqbwFSZIQ1BS01QUR0pXyTfADl7Z4bzqZQyQICEjlP+csBxN5C5mijYihQpIkBDSlPBZXCOiqPK209/RZl0jA++dXCkeaLGE4VcAVF9XXRK8J7p8hIvIwjPhkLj02Sjfy1wcSaAhpGE0XoYf18oxHpmCjORpAKm+huymMdMELCwFFxmAih0MjWeRNrww4nRcQAnAhkDMdFEwbQU1BQ0hD/3gOj790FJGAhq2Xt05bpukbzeLVY+OQIVC0HdQFp89wWI4LXZXhCnfKksvpvSZ+dzyBnGkjXbRh2i5M20VzNID/fE20Jm6+leyf4WZPIqpmDCM+mOsegdNv5NmiA0WWcDJjIqDJKFoOVEWG6bgYThXgCIFv/7IPAUXGaLqI/kQeqixhRViHabso2C4MzSvHFRDYc3wCYV2F7QqYjotkzppsdiajLjh1n3N7zMBoqojWOgMHhjMwbQeGNr3XSCykoT6oT1tyKXV3/dveQ16gUiUEVAUrIjpCuopfHBjBxStCVb88wf0zRESeOVXTPPLII+ju7oZhGNi4cSNeeeWVsz730UcfxfXXX4+GhgY0NDRgy5Yt53x+tau0suVMpaZR71m1Al2NIaiKhHTBhqrIaAzrsB2BuqCGlY0hrGqKoCGsw3RcjGdM5E1vOcRyBWzXhWkLyJIECRISOQuyJKEhrMPQZBRsB4dGMxjPmtPGENQVmI6L97+jFc3RAIZTRRQsB67wZkrGsyYMTUFIU7GmNTptycV1BQ4MpdEeC+LGd7Zi8+pmXNfThM09Tbi6qx7jWbMm2sjzrBYiIk/Fn3JPPfUUtm/fjl27dmHjxo3YuXMntm7dirfeegstLS3Tnv/iiy/iox/9KK677joYhoG/+qu/wo033og33ngDnZ2d8/JDLBfztUfg9KZRpQ6sIV3BT/cO4vh4fkrX1KihYXVLBEdGs1AkGXnT8WZDBBDQJQhIKNouFFmCokiQJQmqLENXZBQtF4dHM2gINUxZRijdJN/ZUYf/+sE1p81wyNBVGbGQhpCmYuWK0IztvUvLEx31xoybWGtleeLM/TOnX+PSWS1n9mkhIqpGFYeRhx9+GJ/61Kewbds2AMCuXbvw9NNP47HHHsM999wz7fk//OEPp/z5e9/7Hv7pn/4Jvb29uP3222f8HsViEcVisfznVCpV6TCXpPncI3Bm06j+8RzGMiY66qe/d0BVEAtpgADWd8agqzIODKcxlikiW7ShyhKEkLwqGCFQtF00hHVIAMYzRaQLdnlfyJk3ya7GELoag/jJqwM4PJqBK1zUB3WsaY2etb03lyc8PKuFiMhTURgxTRN79uzBvffeW35MlmVs2bIFu3fvntV75HI5WJaFxsbGsz5nx44dePDBBysZ2rKwkDfh09/79PJdb9OpiuZIAMdOZqGrMpqjBhRZwq+PnMTJjANFkhCdDBvjWRMhXcElTXU4PJrByYyJiZyJUODsN8m1rXW45z9EZ70hl+W9p/CsFiKiCsPI2NgYHMdBa2vrlMdbW1tx4MCBWb3HF7/4RXR0dGDLli1nfc69996L7du3l/+cSqXQ1dVVyVCXpIW8CYd1FQFFRt9IGkPJAjJFGxLg7SUJ6YgaKoKagoFEHoamoC6oYVVTGMPJAiBJUGQJBdtFS52BnuYwGsMBqLKEAyKNvOng2Fj2nDfJStp7c3liKp7VQkS1blF/9XzooYfw5JNP4sUXX4RhGGd9XiAQQCAQWMSRLY653oRnUwact2wcH89h/1AagEBAUxDSFUQVCfFUHqYj8O7uRqxqCuPIWBbxVAEhXcVVXQ0o2A7WtEQQUBVEAioyk83QBhMFXNPdiA+tb0Odoc3bqcBcnpiOZ7UQUS2rKIw0NTVBURTE4/Epj8fjcbS1tZ3ztd/61rfw0EMP4ec//zmuuOKKykdaBeZyE55NGXDfSBrff+kYxrImZNnbgKrIErJFGwXLQWhypqUhpOHO9/VgaHIpKKyryJsOfrDb6wAa1BzsH0phIJHDRM6CEMBQqoDBRL58GvB8BQQuTxARUUlFYUTXdWzYsAG9vb24+eabAQCu66K3txef+9znzvq6b37zm/j617+O5557Dtdcc80FDXi5q+QmPJtW4auaInhuXxwDiTyCqoyLGoLIFCzkLReS5FXKhAPAhpUNmMhZGEoV0FkfnDLTcsembjz52+P45YGRyb0mDnRFRkNIAyChfzyHojXzacAXei24PEFERBUv02zfvh133HEHrrnmGlx77bXYuXMnstlsubrm9ttvR2dnJ3bs2AEA+Ku/+ivcf//9eOKJJ9Dd3Y3h4WEAQCQSQSQSmccfZWmYzZLKbG7Csy0D/o9XyJPltzoGJvJoCGuoM9TyOTG2K+A6LiABo5ki/s+hUYxnTRwZzSI/2Ruktc5ArmihqyGERN5EMm+hJRqALMsQQmA8a8J2XZzMFOe9PTmXJ4iIqOIwcsstt2B0dBT3338/hoeHcdVVV+HZZ58tb2o9fvw4ZPlUL7W///u/h2ma+NM//dMp7/PAAw/gq1/96oWN3gfnChuVdFY93014tmXAR8ayKNgOmsKB086rkcvnxGSLNuJZE68eHUfBcXF0LIuQpuDiFSGkCzZGM0XseXsCedNBe8yA7boIBVQUbBeK5J0vEzFUjGdN1Ac1/KpvFM3RAK69pBFdDSHOYhAR0QWThBBLvs1lKpVCLBZDMplEXV2db+M4V9gAcMaSioqcaZf3glS6vHFgOIW/7T2EVU0RKDPc8G3XxbGxLP7zNV346d5BxIIqDgxnMJouoCGkwXIEsqaN0XQRpu2gIaRDliTIsgTXFciYDqKGisbJ9vDHxnKQJAHLdhEMqN5zJQlBTYahKRhNFyFJQMFyEQ2qaI4YeM8ljbj1PSu5v4OIiGY02/t39TdymCfn2r8xkMjDUOV5PX11tmXAlzSFyxU6Pc1hjGWKODyahSuAgmXDdLzZDVWRIcsSYoaGsUwRpu3CdQV0RQYEoMpA3hJwXO+Qu5ihQQBIFWyMpItwXAFDk2FoMlaEA8gWbbywP46RTBF/vmWNb4FkLgcOEhHR0sIwMgvn27/x+xMJjKZNbLykYd5OXz1XGbDrem3aVzVFIAG44fIWDCbzePtkDrbjQsCbOSnaArLkHUCUtxzIkoSAIiNvOV4Vj+WdlKurMgQAVwjoKmA5Aq4AFBlwhQvL8d5HU2REDG9PSp2h4mTWxMF4Gs/tG8aq9y/+MfdzPXCQiIiWFoaRWTjf/o2GkI5DIxk47syvn0tn1TPLgNvqArBdgcFEHodHswAAIYCdPz+EnuYI/uAdzfjBy2+jaLuI6Aomck75OXnLRc4yIQFIFSy4LhAxVAgh4AgB03YhAVAmy4Idx0XO9A7fK1ju5M8JKLLXQO1UGFORLtj49xPJRT9HZjaVRgwkRETLA8PILJyvjXudoZVv9A1hfdrfz7WzaqkM+IlfH8evj5ycDDQOFEXCxQ0hXNQQhKEp2DeYxMF4Groq4YqLYnhzKAUXEiTJCyOlTUECQN50IUtApmDD0GQokgTbdeEIoCGkQ4KAKHrBxLS9ICJLgCp7pwIHdaU8Pk3xNirnLHtRz5GZrwMHiYhoaZDP/xQ631HvigzEghomcibO3A9c6qy6uiUyY2fV/vEcDgyn0D+eg+vOvJc4ni4gZzqwHReSBMjw9km8fPgkTNvFmpYITmaL6J/IYzxbRKZgQ5FEOYhIk1+A92dHAAXbhW07EADSBQeaIqM+qEGRZbTWBbChuwHXr25CW52BkK4gqMkInxZEAG9vCQCENHVRz5Gp5MBBIiJa+jgzMgvna+M+nCriPatWoGA589pZ1XUFnvjNcfz7iaQ3YyF5sxSWA9iujazpoHd/HB98ZyvaY0EcHs0gW7C85ZczloxmijkZS2BgIoeelghcIXDkZBbCFdBUGWMZEzFDRTigIpG3AAnQ1VPZtXQYnyJ7szGLeY4MT/0lIqouDCOzMJs27rduXAkA89JZ9Y5N3QjqCg6OpPCL/XHYjouA6u3fKB1+pyoKTNvFyayJV46OY8PFDdBVGYmcBdf19oKUso8zQxKR4O0DyZoOxtJFnMwUIQQQ0BSEAwocV2AsawJZE5GACkWWEE8VEJvsyprMWXCFwJVd9di6rm1Rl0MW+tRfVugQES0uhpFZWtUUwdbLW/HTvUM4MJSGrgINocC0sFFJZ9XVzWFkig4mciZ0Rcbq5jD2nkjiaz97E7oqYf9wCsPJIjRZghACtgtoioTS4ouqSLAcgXTBwsF4GhfVh1C0MkjkTNi2gMDMMyKK5O0JMTQZiixjJF2Eocm4pMlAMm8jb7kQAghpCgqOi5a6AN7d3YhXjo7jZMYEAMSCOjatasRHNy5+n5GFPPWXFTpERIuPYWQW+kbSeOI33ibSRM6C4wqEAwqaowa2XDb1JjXbzqpBTcaetxMYz3mt1lXZ6+GRyFnIFm1EDRWu623qsV1Rnt0oOgKWI6AqEpTJm7ChyhhKFPB/rW2CZXuNzpxz/DylgBLSVQRUCScmLFzUEETE0BEOaOVW8ookoWg7SOVt/OG6NvzZ5ktwZMyr5LmkKexbB9aFOvWXFTpERP5gGDmPvpE0dv78EH7fn4AiAU1RHRIkJHIWfn1kHHnLrajpV9a0MZYp4mS2iKLlImKo0BQVlu3i+MkcTNuBIntt3euDXht267R1ltK8iO0IWBDQFAkFy0XOcvC74wlvI+x5euq6wluiaY56zcu8niLejVuSpHIreQBQFAkTOQsTOQvvWdWElSvClV7CBTHfp/6yQoeIyD8MI+fgugLP7hvGweE0dEXCikigfJNqrZPn1PQrpCkYyxSRK9poqZtaDSJJXtDIWV51S7ZowXbElKWWUhg5fQnGdFxosheQJElCfVDBRP5ccyOYbPWuIFWwIEuAc5YEky86kOCVAveP55bU/on5PPW3kgodHuxHRDS/GEbOYSCRx+sDSThCIBrUzggO0qyaftm2i9f6J3Aya2JFWMeKiA5AgsDUG57tet1QbVfAdgSyRROuJE3b81EqklElIKDK5UMJW+sM9I/nENS8zacSnLPuF1EVydugmikgXbAR1hVkixZcNzDlkMNs0cLxiRxCuoLe/XHsPnxyye2fmK9Tf1mhQ0TkH4aRc8ia9mRvEQFNllG0nPJeCl2Vy02/sqblldWe8dt57/44vv/SMRw7mYXluNAU2VvmkUT5JNyIocJ2BOKpInKWA9edbE5mAzNvP/UIeEsrBdvBioiBFZEAjoxl4Vo2iqfNpnidVQFn8n0VyXus6Aj0TxQQUGR0NgQxmjFxZCyL1jpv/0UiZ2IwUYAseaW7q1ui0/ZPrGqan1mJpWChK3SIiOjs+Ml6DmFdRUhXYdouTkzkYDoCrhDlJY5IwCuvjSeL+MdXjnsVKpPVF3VBFT/Y/TbSBQsrJjuX5k0H/eN5FC0X6zqjgKFhOJXHyYwJ2xWQgXNuPD1T1nQgSRIuaQpDU2TYjgtbANJpgUDA68KqyIDtemW+lu1FlZihYeOqRrTWGfj9iQQGJgoYz5pAFsiZDkK6iut6GrGq2ZsFOX3/xBO/OY7GkI4jY9mqqDpZyAodIiI6N4aRc+isD6IjZmD3kZOwbRdRQ4Uie8sgqbyJk1kBSZImnxdEOKAiZ9p4/UQCe08kYTkOVjWFy0sfUcPrYrp/OI2D8Sxu2dCBXx9zkDcdmLYD4Uqwzrf7FN7sRiyoIVu0IQDEk0XIsvc6RwDSGe/hCG82JKwCwYCGRN5CQ0jHRzZcBFX1Nqtu7mnCweE0GiI6Lm2Lonf/CFY1hRELTW1vL0kSgpqMXx4YwcoVIfQ0R6qi6mShKnSIiOj82A7+PCRICGlq+dC4gmUjU7SQLTrIWy6KlgNFAizXhSJLiBoawoaCZN6EIkvTNkPKk+3WC5aDl4+MI5nz+nY47qmKltmwXYGgrkAC0DeaQd9o1jt5FzM3ORMCEJKMVMFGUFdweUcdcpY7pX19NKhhJFVASPc6r0ZmWK4QQmAwUUDectBZH0TU0Mo/95qWCMazJp5/I37W1vZLWalCZ11HDImchWNjWSRyFtZ3xpZlwCIiWi44M3IOA4k8EnkL1/U04shYFm+fzJVPvYUESJP32+MTOUzkLGxc1YhLmiLlk25txzsRV1flKb07YkENyZyNhmAAQ8kiskULmqpAVRRkTfccO0U8rgB0RYYjRPkwPNP2zqI5l+LkwXdBVcGJRB7DqSIaQzqaojrG0ibGskWk8hbypoNE3kJQk9HVOLWUN12wMZopIhxQEVCnnlVTDVUn81mhQ0REs8Mwcg6lCotVTd4hd5IYQ/9EDpYjYLti8qA4gaCmIFO08Zsj46gzNAR1BaoswXJcr916poi85Zb3m8iTFS1/ck0niq+4OHoyi+awN1uSyFkzzmycTpW9PSCWJWBoCiTJ6wUyk9IGVgne0k66YAMS0BDUYbkuTiRy2D+cQjSgImKoiAU1dNQHMZY18dtjEwjpClZEjPL7FW0H2aKN7hVhRI3p/3yqoepkvip0iIhodrhMcw6lCots0cJQsoDxnAlJkiDLEsIBLwTIkgRVlhEJKMiaNt4cSqEtaiBqqCjaLk5misiaDjTF22uhykCq4PUD6WmKYF1HHSQBSJJAUJNntVSjKhIKtrfEIssSNEWCDC9wlF4uwQstEk5V0uiqjIawXt6joisyXNebvXFcF0XbxYpIAB31QVzb3QgAeOXoBFJ5r0tsumBhIJFHUFPRUT+9HwfAqhMiIqocw8g5dNYHUR/U8NLhk3j17QmMpItI5q3JzabeEok0OdOhyF6QmMiayBRttMWCkCQJqYKF0vqJ6Qhkig5CmoKOegMvHhzFn7zrIjRHAxhOFSfLdc89JhmAIkkoWA6E5FXEyBIgy17TtNMJ7wgbby+JCwQ1FU2RAGRJwnjOQqZgI2c60FVvL4kqy+hp9rqProgE8O7uBqiKjMFkobx/4truFfiDdzRPnl8jzvh+XtXJ6pYIq06IiGjW+OvrORwZyyCeLiKTt2ELFxK80t6iLWA63vKMKsso2N7mVVkCLMfFvw8kkTcdBDUFOVMgVbAhFW0EVAUrIjqu6qpHUySAvpEMbrqyA//1g2vwt72HMJTMA0KCBDF5FJ5Hlk6V6Ap4e0YCqoKLGoJY1RzB3v4JqLIMx3XLf3/6/wLe/6byJjQ1gMaIjoaQjomsiaLtnQisqTLWtEbQGD5VPdNeH0TBcvCRd69EW8wo7584MpbB4y8dY9UJERHNC4aRs3BdgSd+cxyH4mnomoRs1kXBEuUOqLIk4LguGieXPdJFC7oiw3YF8qYzmSQEwroM0xFwXG/T6RUXxXBJUwS265b3VnzwslZ0NQbx/754BP92cASGJiNd8Mp2NUWCpsgIqDIUScCBjP/73V0o2i76x3NoCuvQFQW6KsF0ZAgBuK6LyT225Q2usgQULBeDiQJ6msPY3LMCQ8kCXn17AqosQZElNEcCU65B3nRgaCp6miNT9lDM97kwRERU2xhGzuLlw2P45YERCCFg6Ao01UFAk1CwvLkGGUDedDEwkfM2pcrenowVYR31IQ2j6SJsV8BQFYRVCbbjIm85+O3RCdSHdOiKPGVvxdrWOvzx1R3494EECpYLWQLSpg3LEXCFAyEE6oIaVq0I45Z3r0TRdvD4S8cwnCqiPqhiIidDFS4s251S6QPhBRpdleG4AsrkbIkkSeioD6J9Io8jJ7NY1TR1Q+r5Gn2x6oSIiOYLw8gMXFfg52+OIGc56GoIYjhZhOMKNIQmK17yFiabmMJ1AWWyXXyqYKNguihYXh/VcEBFKm9BCFFeYhnPmthzdBwXN0VwxUWnbvR9I2k8uy8OCRIKlo287UJMTsMIAWiqgqLlImd6TdLWtp2anfid62Iw6fX+UBUZsuwtG5m2C1d4QSQW1GC7XmlxumAjkbOgKhJUVUadoUGVZWSKdkVLLqw6ISKi+cAwMoOBRB5DyTwiARW5ooO85W3ylCRvg6mMUwfWAV7ICOsqogEFg8kCTkzk0RTRUTAdWI4ob/Qs7eE4OJJFXejUjb50fP1EzsTa1jB6D+Rg2i40VYIuSbBsF5mijUhAhapI+Pn+OFa3RMqzEy8fHsNPXj2B144nMJYtoGgJqAoQ0r0Nqx31QbREAwioMvpGMzgxkffKiSMBvOeSFWiK6tg/mMbARB6KDBiayiUXIiJaNAwjM8iaNmQZaI4EMJDIw3FdBFQVluMiXXRQai4qAQioEmzX2z9iaDpURULedDGcKgI4tenUq7zxlk8EBIZTBa95Gk4dX99WF8DvTyQhSRICqgxXAJYryhU7Qc1rMnYoni43FTsylsH/2jeMouPig5c1I5G1sPvoSZiWA1mWYLveUtKJiTwihoq2aACxdg23vudiqLKEvccT+M2RceQtb59LS52BD17Wis09TVxyISKiRcEwMoOwriKoqQjWK5jImUjkTBRtp9yPo7QdI6BKUGQZgLcMM5Gz4E6emOsI7wwZYHIjKQBJBjRFhiZ5m0N/8lo/7vnDy8rN1SKuiomsCXmyZNh1Tks9kycFpws2EnkTWdMuz6iczJhoqwvAdARiIQ2tdQaOjmXhWC4gOdAVCXnL2zDbF09jVXMER8cy2NufRNFyvL0jmoHRdBF9IxlMZC20Rg2sbeOsCBERLTyGkRmcfoLrNRc34N9MByezRViOOFVuC0BVZNiOgKbKMDQFqYIFWZYgTQYSd/K0XAhvWUdyAVkBDF2FJgN9kzMcpeZqqYKFou3CtB1IkKAqMlRJguN6HV9TeRNBXYUsyQjrKgYSefzu+ASGUwW8NZyCC8BQJCQLNhwhAOGVFRuqDF2VIUsCBcfF0bEsdr5wCLoqY3VLBLoqYyxtYjxnwnIcHBnN4ms/exNfuekyrG2tg+sKblQlIqIFwzAyg9IJrgOJHE4k8ljTEoYz7GIsY0KTJUiSgGUDBdPxZjHgLYeYk/1GFBmwJ7ueOi4mn+PNlliOQM50IAE4etJrxb7l0lb0NEfwm6Mny0FEkqRyEzPXFdAUCabjwspbuKQpDFcIPPXb4/jNkZNwhOudbSNLyEkSsqYNTZJgSxIc24FQvGoeV0gIqApkALbjQlUkHBnN4M2hFOoMDSsiOqKGiqxq4/BoBo/88jD+6MoOHBhK4/BoBgXbgaEq6GmOYOs67ichIqL5wTByhtIswJGxLCxHYDRVRCJnImd55bUCMiQALoS3d0QAZsEB4Ey+gfB6gshec7TSkk1pHiGoypBkb8mlaLl4+vdDWNUUxtZ1rXhrOIWi7UJVZLiui6It4Ewu1diTG1VUWcLxk1l87Wdv4DdHxpE1HRiaDF2RIcsS8qYD2xGQFC8IhQMK2mNBJPMWJMkt9zAxHRdWwfsBHBcQrkB90Dv8LhxQYU72Mfnb3kNojxnoqA8ipAeRM23sG0xiMJnnSbZERDQvGEZO0zeS9kpl+ydwMJ6GPbkHoy6owQWQMx0UrHOfqusI73Rc+Yy27qWOqgXbRSigwtAUdNYHUbRdPP9GHHe+rwf/8aoO/H4giUTORN7xZlFKJOG1fHeEwO8HkogGVLiuQECTYbkCWdOrtjE0GXnLge26sB0gFtRhaArGMmb59GCv5NdbapJlCaoC5G2vPLiz3jt7R5UlmLaD8ayFq7vqETU0AEDU0BAJqDg0ksHzb8SxqinCJRsiIrogDCOT+kbSePylYziZKWIia0KTZQQ1oH88B8t2oave3o3TS3rPLPEtcQQgnOmPCwCYbBkfmNyvoSky+kYyGEjkcVlbHd7VVY94Ko/f9SchO8I7cwbe2TeO43VWFUJgLGNCUSSEVO/EYMsRyJoOoroMTZFQML2zc4K6Cld4bexlSMiaDmRJgqZJKNqu18NEkeG4Xvg5mTVhaMrkCb8WdNULO6eTJAntMaM8bvYaISKiC8GD8gDYtosf/fYE3j6ZRVhXvZ4ehopE3oZpu7BdgZzpwjljSmSmIHK+vxNCQJElhAMqGkI6grqCou0ga9rextmWCIaSRUAIBDSvTbskeXs8HAEosheKTMeZ7PwqIWpo0BWvH0neEtAUGYoMaKq3wbY0lZMpOhACCOkyFFmGpnjt4+3JQ/8UWUIqb0GVZXTUB2FOhiZdkSGEQCpvYSxTRCpvwdDk8riJiIguRM3PjPSNpPGj3/bjf+0bhiJLGJjII5m3sCKilbunApgWROZqssgFY5kiBiZycCbDQEhTIMsSruyqx/+3+xhMR5Q3sApxqmHa6WffqJNdVoOagjpDQ8500FIXgCpLGE0X0RYzkCk6GM14PU8kCGgK4EKCoclorQtgOFlAznSgqd4BffrkgXlNYR2WLdAU8fqr/PbYBCZy5uTGVxlhXUFDWC+3syciIpqrmr6TlJZm3j6ZhSIDKyI68kUHY5kihpMmLMctzypIwDn3isyW7QKZgo1MwcbP83FoioyWuiB+uncQf7i+DSvCOjRZhix5G1ABr1maKk8u/wjvwLtwQIGueEsoecuBIktee3dZxnjOxEUNITz0n67AaKaI3v1xHBrJ4MhoBomchZAuoSUagKpIqA/pkGUbQU1GJKB6SzuaguFUEc3RACCAvf0JFCwHEUODZqiwbBcnEvlTwYiIiOgC1GwYKTUMG8+aWN0cwVjGhDPZMySoKUjmLTjemXOQZS8EzIfJAhwA3rJJOCChoz6AN4ZSGEoVsOHiBgDeUouAgCZ7m0wlTJb2Ot6+FU2V0RDWkC44MG0HGdOBKstI5Ey01Rn4/AfX4NL2OlwKYHNPEwYSebw5mML3/s8RnJjIoWA5UF0ZXY0hNEUCGE0X8PbJHKKGCttxccVFMfzphk783S/6MJopoq0uAE2RYDlea/rmiI66oFZuTc9NrERENFc1G0ZKLdjbY4ZXhaLKOD6RgwRMnpQrysHBPdfmkAsgS151zFjGxPWrm9A3msXvTySgqd5WHk2RTpuNESjd76XJv+tpiWJgIo+hZAF1hoyVjSFc2VWP/7ShE2tb6059n8kD7boaQ7ikOYRHfnkYJzNFtMcMNEcDKFheo7V3X9KID69vx2XtdeisD2IgkUdz1Fv2yZoOcqYJRZbRUmegpzk8ZfMtN7ESEdFc1WwYKbVgD+lBTOS89uqm5cIRLlRJOtUYZIFI8E71FcKr2BlMFBBQZRwdzSJmaBjLmJP9TLxZHK8iBtBVCboiA5AwkTOxsjGEDd0NuKa7EZe11Z23O+ra1jp8/gOr8dy+OA6PZvD2yRwCqoIrLqqfdjBe1rShqzLes2oFcqYD03GhKzKihgpJ8hq9xVMFbmIlIqILUrNhpNSCPVu08fpAEvFkAQXbge0C87M75NwEgEzR9rqmmgK/OTqOgCYjbzpoCOnQFBmByb4gtjRZpqvKk3tMAmiKGPjoxpXoaY5U3J69dNrv+Vq8l65R3nJQF9SmvU/edLwmadzESkREF6Bm7yKl82f+98ERHBxOIW+JRYggU9muN+vhfV+BcMA7lTeky5Alr1S3tS4AWZYgJpupBTUZoYCGK7vq8X+taZ7zXo3S0s25nH5Gj7e59dT3EkJgKFnA+s4YOuuDcxoDERERUMN9RmRZwg3vbEU8VUTOhyBSUtqOYjkuskUHrXUG3rNqBbqbQtBUGYmchWzRhu0K1Ic0NIQDWNkYwo2Xty74ptHSGT2NYR2HRjJIFyzYrot0wcKhkQwaw/qijIOIiKpbzc6MAEBAk5EqWH4PA5oiIVt0EA6oaAzryBQdXNEZQ0NQR3NUx0i6CFcA9UENa1qj0/Z2LKTVLVFs29xd3mMSTxUQUBWs74wt6jiIiKh61XQY+dWhMaRyixtGztavxHZdFG0XB4ZT6JNl1Ac16KqM2zZ1I2po59zbsdBmu8eEiIhoLmo2jLiuwK8OjWIxW3ap0uSyzGlpxNBk2I4LWZYRC2oIB7yOp0PJPGRJwnjWxDs7Yos4ypnNZo8JERHRXNTsnpGBRB5HRtOL+j0FvCWZoC4jrMuIBhS4roAjgKihIhJQIUte6a6qyNBUGb/vT8B1/drRQkREtPBqNoz8fP8wDo/lFuV7KRJgqBJCugJV9ipldFVBXVCD7XrNzMIBFQJA0XYwnjUR0lWs66jD4dEsBhL5RRknERGRH2pymeZgPIXHfnV0sqfIwlEloDkagO0KpAreoXvW5Il7rhBwXBeaIqM+pEFTZEzkTKjlDqcR1AVVHBvLsqkYERFVtZoLI64r8ONXT2AgUVjw71Uf1vCBS1uwfziFI6MCsgy0xXQYmoyc6WAiZ0FTBC7viGJlY2Rah9N0wWJTMSIiqno1d5cbSOTxwpvDWOhtGIoErGmJ4GTWO3CvpzkMXZUxkbNQsF3oqoJLWw0MpgroHy/gne0xyPKpLqdsKkZERLWi5sJIImvixPjC7sGQJK+HSdTQsHJFELbrYmVjCJGAinTBnjIDcmIih98dT+DfB5LoaY4gqCvImw6GkgU2FSMioppQc2Hktf5x2AswK6JI3im8rgDqgirev7YFd9+wFhnTxrd/0YeQ7i29nHnGS3t9EGMZE5c0hZHIWWwqRkRENafmwkjOWpjOIhK8XhyaLOHqlQ246wOrsXJFGP3jORiqgpxpI2rMfNhcUySAbZsvgSxJbCpGREQ1p/bCyAK0f5cloCmiwRESLm2L4p7/cGl5RmO2h811NYQYPoiIqCbVXBgZyxTn/T0vbQ2jMWJgRSSAu96/GmtbTy2tlA6bG0zmcWgkg/aYwX0hREREp6m5MPKLfYPz/p6xYADX9TSddY8HD5sjIiI6u5oLI/F5LqRpqwvgCzeswbXdK845u8HD5oiIiGZWU2HEnueWq4ok4fo1TecNIiU8bI6IiGi6mgoj/+fgyLy8jwRAV7wy3Rsub+PsBhER0QWoqTCy8+cH5uV9ooaKi+qD6GgI4rK2unl5TyIiolo1p1N7H3nkEXR3d8MwDGzcuBGvvPLKOZ//4x//GJdeeikMw8D69evxzDPPzGmwF+r3g9kLfo/6oIobLm3ByhUhvGtlA1u1ExERXaCKw8hTTz2F7du344EHHsBrr72GK6+8Elu3bsXIyMxLIC+//DI++tGP4hOf+AR+97vf4eabb8bNN9+Mffv2XfDgF5siARc1hJC1HKyIBFiSS0RENA8kIURFzdE3btyId7/73fj2t78NAHBdF11dXfj85z+Pe+65Z9rzb7nlFmSzWfzsZz8rP/ae97wHV111FXbt2jXj9ygWiygWT/UDSaVS6OrqQjKZRF3d3JdFuu95es6vBYCgJuO6nhXYcHEjS3KJiIjOI5VKIRaLnff+XdHMiGma2LNnD7Zs2XLqDWQZW7Zswe7du2d8ze7du6c8HwC2bt161ucDwI4dOxCLxcpfXV1dlQxzQcgS8J82XISv/tE63Pm+HgYRIiKieVJRGBkbG4PjOGhtbZ3yeGtrK4aHh2d8zfDwcEXPB4B7770XyWSy/NXf31/JMOedJgPdK0L41PWr0NXItu1ERETzaU4bWBdaIBBAXV3dlK/58I2PrJzT61qiAfzBO1rQ1cAeIURERPOtojDS1NQERVEQj8enPB6Px9HW1jbja9ra2ip6/kK69V3rK35Nc0TD1Rc34qMbV3JGhIiIaAFUFEZ0XceGDRvQ29tbfsx1XfT29mLTpk0zvmbTpk1Tng8AL7zwwlmfv9COPfThWT/3srYIPn7dJfjzLWu4R4SIiGiBVNz0bPv27bjjjjtwzTXX4Nprr8XOnTuRzWaxbds2AMDtt9+Ozs5O7NixAwDwhS98Ae973/vwN3/zN/jwhz+MJ598Eq+++iq++93vzu9PUoFjD30YT7z2Or70o+PT/m5tcwg3v6sD713bgoZggOfHEBERLbCKw8gtt9yC0dFR3H///RgeHsZVV12FZ599trxJ9fjx45DlUxMu1113HZ544gncd999+NKXvoQ1a9bgX//1X7Fu3br5+ynm4NZ3rZ/Tsg0RERHNr4r7jPhhtnXKREREtHQsSJ8RIiIiovnGMEJERES+YhghIiIiXzGMEBERka8YRoiIiMhXDCNERETkK4YRIiIi8hXDCBEREfmq4g6sfij1ZUulUj6PhIiIiGardN8+X3/VZRFG0uk0AKCrq8vnkRAREVGl0uk0YrHYWf9+WbSDd10Xg4ODiEajkKT5O7QulUqhq6sL/f39bDO/yHjt/cXr7x9ee//w2i8+IQTS6TQ6OjqmnFt3pmUxMyLLMi666KIFe/+6ujr+w/QJr72/eP39w2vvH177xXWuGZESbmAlIiIiXzGMEBERka9qOowEAgE88MADCAQCfg+l5vDa+4vX3z+89v7htV+6lsUGViIiIqpeNT0zQkRERP5jGCEiIiJfMYwQERGRrxhGiIiIyFcMI0REROSrqg8jjzzyCLq7u2EYBjZu3IhXXnnlnM//8Y9/jEsvvRSGYWD9+vV45plnFmmk1aeSa//oo4/i+uuvR0NDAxoaGrBly5bz/reic6v0337Jk08+CUmScPPNNy/sAKtYpdc+kUjgrrvuQnt7OwKBANauXcvPnjmq9Nrv3LkT73jHOxAMBtHV1YW7774bhUJhkUZLZaKKPfnkk0LXdfHYY4+JN954Q3zqU58S9fX1Ih6Pz/j8l156SSiKIr75zW+KN998U9x3331C0zTx+uuvL/LIl79Kr/2tt94qHnnkEfG73/1O7N+/X3z84x8XsVhMnDhxYpFHXh0qvf4lR48eFZ2dneL6668Xf/zHf7w4g60ylV77YrEorrnmGvGhD31I/OpXvxJHjx4VL774oti7d+8ij3z5q/Ta//CHPxSBQED88Ic/FEePHhXPPfecaG9vF3ffffcij5yqOoxce+214q677ir/2XEc0dHRIXbs2DHj8z/ykY+ID3/4w1Me27hxo/gv/+W/LOg4q1Gl1/5Mtm2LaDQqfvCDHyzUEKvaXK6/bdviuuuuE9/73vfEHXfcwTAyR5Ve+7//+78Xq1atEqZpLtYQq1al1/6uu+4SH/jAB6Y8tn37drF58+YFHSdNV7XLNKZpYs+ePdiyZUv5MVmWsWXLFuzevXvG1+zevXvK8wFg69atZ30+zWwu1/5MuVwOlmWhsbFxoYZZteZ6/f/yL/8SLS0t+MQnPrEYw6xKc7n2P/3pT7Fp0ybcddddaG1txbp16/CNb3wDjuMs1rCrwlyu/XXXXYc9e/aUl3KOHDmCZ555Bh/60IcWZcx0yrI4tXcuxsbG4DgOWltbpzze2tqKAwcOzPia4eHhGZ8/PDy8YOOsRnO59mf64he/iI6OjmnhkM5vLtf/V7/6Ff7hH/4Be/fuXYQRVq+5XPsjR47gF7/4BT72sY/hmWeeQV9fHz772c/Csiw88MADizHsqjCXa3/rrbdibGwM733veyGEgG3buPPOO/GlL31pMYZMp6namRFavh566CE8+eST+Jd/+RcYhuH3cKpeOp3GbbfdhkcffRRNTU1+D6fmuK6LlpYWfPe738WGDRtwyy234Mtf/jJ27drl99Cq3osvvohvfOMb+M53voPXXnsN//zP/4ynn34aX/va1/weWs2p2pmRpqYmKIqCeDw+5fF4PI62trYZX9PW1lbR82lmc7n2Jd/61rfw0EMP4ec//zmuuOKKhRxm1ar0+h8+fBjHjh3DTTfdVH7MdV0AgKqqeOutt9DT07Owg64Sc/m3397eDk3ToChK+bHLLrsMw8PDME0Tuq4v6JirxVyu/Ve+8hXcdttt+OQnPwkAWL9+PbLZLD796U/jy1/+MmSZv68vlqq90rquY8OGDejt7S0/5rouent7sWnTphlfs2nTpinPB4AXXnjhrM+nmc3l2gPAN7/5TXzta1/Ds88+i2uuuWYxhlqVKr3+l156KV5//XXs3bu3/PVHf/RH+IM/+APs3bsXXV1dizn8ZW0u//Y3b96Mvr6+cgAEgIMHD6K9vZ1BpAJzufa5XG5a4CiFQsEzZBeX3ztoF9KTTz4pAoGA+P73vy/efPNN8elPf1rU19eL4eFhIYQQt912m7jnnnvKz3/ppZeEqqriW9/6lti/f7944IEHWNo7R5Ve+4ceekjoui5+8pOfiKGhofJXOp3260dY1iq9/mdiNc3cVXrtjx8/LqLRqPjc5z4n3nrrLfGzn/1MtLS0iP/+3/+7Xz/CslXptX/ggQdENBoV//iP/yiOHDkinn/+edHT0yM+8pGP+PUj1KyqDiNCCPF3f/d3YuXKlULXdXHttdeKX//61+W/e9/73ifuuOOOKc//0Y9+JNauXSt0XReXX365ePrppxd5xNWjkmt/8cUXCwDTvh544IHFH3iVqPTf/ukYRi5Mpdf+5ZdfFhs3bhSBQECsWrVKfP3rXxe2bS/yqKtDJdfesizx1a9+VfT09AjDMERXV5f47Gc/KyYmJhZ/4DVOEoJzUUREROSfqt0zQkRERMsDwwgRERH5imGEiIiIfMUwQkRERL5iGCEiIiJfMYwQERGRrxhGiIiIyFcMI0REROQrhhEiIiLyFcMIERER+YphhIiIiHz1/wPLsPg4TNj6tAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(all_induction_scores_old, all_induction_scores_new, alpha=0.5)\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "pearsonr(all_induction_scores_old, all_induction_scores_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630b416-d74a-49d0-95b1-5154f13c43c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
